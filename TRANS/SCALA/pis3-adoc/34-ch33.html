<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
    "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="application/xhtml+xml; charset=UTF-8" />
<meta name="generator" content="AsciiDoc 8.6.10" />
<title></title>
<style type="text/css">
/* Shared CSS for AsciiDoc xhtml11 and html5 backends */

/* Default font. */
body {
  font-family: Georgia,serif;
}

/* Title font. */
h1, h2, h3, h4, h5, h6,
div.title, caption.title,
thead, p.table.header,
#toctitle,
#author, #revnumber, #revdate, #revremark,
#footer {
  font-family: Arial,Helvetica,sans-serif;
}

body {
  margin: 1em 5% 1em 5%;
}

a {
  color: blue;
  text-decoration: underline;
}
a:visited {
  color: fuchsia;
}

em {
  font-style: italic;
  color: navy;
}

strong {
  font-weight: bold;
  color: #083194;
}

h1, h2, h3, h4, h5, h6 {
  color: #527bbd;
  margin-top: 1.2em;
  margin-bottom: 0.5em;
  line-height: 1.3;
}

h1, h2, h3 {
  border-bottom: 2px solid silver;
}
h2 {
  padding-top: 0.5em;
}
h3 {
  float: left;
}
h3 + * {
  clear: left;
}
h5 {
  font-size: 1.0em;
}

div.sectionbody {
  margin-left: 0;
}

hr {
  border: 1px solid silver;
}

p {
  margin-top: 0.5em;
  margin-bottom: 0.5em;
}

ul, ol, li > p {
  margin-top: 0;
}
ul > li     { color: #aaa; }
ul > li > * { color: black; }

.monospaced, code, pre {
  font-family: "Courier New", Courier, monospace;
  font-size: inherit;
  color: navy;
  padding: 0;
  margin: 0;
}
pre {
  white-space: pre-wrap;
}

#author {
  color: #527bbd;
  font-weight: bold;
  font-size: 1.1em;
}
#email {
}
#revnumber, #revdate, #revremark {
}

#footer {
  font-size: small;
  border-top: 2px solid silver;
  padding-top: 0.5em;
  margin-top: 4.0em;
}
#footer-text {
  float: left;
  padding-bottom: 0.5em;
}
#footer-badges {
  float: right;
  padding-bottom: 0.5em;
}

#preamble {
  margin-top: 1.5em;
  margin-bottom: 1.5em;
}
div.imageblock, div.exampleblock, div.verseblock,
div.quoteblock, div.literalblock, div.listingblock, div.sidebarblock,
div.admonitionblock {
  margin-top: 1.0em;
  margin-bottom: 1.5em;
}
div.admonitionblock {
  margin-top: 2.0em;
  margin-bottom: 2.0em;
  margin-right: 10%;
  color: #606060;
}

div.content { /* Block element content. */
  padding: 0;
}

/* Block element titles. */
div.title, caption.title {
  color: #527bbd;
  font-weight: bold;
  text-align: left;
  margin-top: 1.0em;
  margin-bottom: 0.5em;
}
div.title + * {
  margin-top: 0;
}

td div.title:first-child {
  margin-top: 0.0em;
}
div.content div.title:first-child {
  margin-top: 0.0em;
}
div.content + div.title {
  margin-top: 0.0em;
}

div.sidebarblock > div.content {
  background: #ffffee;
  border: 1px solid #dddddd;
  border-left: 4px solid #f0f0f0;
  padding: 0.5em;
}

div.listingblock > div.content {
  border: 1px solid #dddddd;
  border-left: 5px solid #f0f0f0;
  background: #f8f8f8;
  padding: 0.5em;
}

div.quoteblock, div.verseblock {
  padding-left: 1.0em;
  margin-left: 1.0em;
  margin-right: 10%;
  border-left: 5px solid #f0f0f0;
  color: #888;
}

div.quoteblock > div.attribution {
  padding-top: 0.5em;
  text-align: right;
}

div.verseblock > pre.content {
  font-family: inherit;
  font-size: inherit;
}
div.verseblock > div.attribution {
  padding-top: 0.75em;
  text-align: left;
}
/* DEPRECATED: Pre version 8.2.7 verse style literal block. */
div.verseblock + div.attribution {
  text-align: left;
}

div.admonitionblock .icon {
  vertical-align: top;
  font-size: 1.1em;
  font-weight: bold;
  text-decoration: underline;
  color: #527bbd;
  padding-right: 0.5em;
}
div.admonitionblock td.content {
  padding-left: 0.5em;
  border-left: 3px solid #dddddd;
}

div.exampleblock > div.content {
  border-left: 3px solid #dddddd;
  padding-left: 0.5em;
}

div.imageblock div.content { padding-left: 0; }
span.image img { border-style: none; vertical-align: text-bottom; }
a.image:visited { color: white; }

dl {
  margin-top: 0.8em;
  margin-bottom: 0.8em;
}
dt {
  margin-top: 0.5em;
  margin-bottom: 0;
  font-style: normal;
  color: navy;
}
dd > *:first-child {
  margin-top: 0.1em;
}

ul, ol {
    list-style-position: outside;
}
ol.arabic {
  list-style-type: decimal;
}
ol.loweralpha {
  list-style-type: lower-alpha;
}
ol.upperalpha {
  list-style-type: upper-alpha;
}
ol.lowerroman {
  list-style-type: lower-roman;
}
ol.upperroman {
  list-style-type: upper-roman;
}

div.compact ul, div.compact ol,
div.compact p, div.compact p,
div.compact div, div.compact div {
  margin-top: 0.1em;
  margin-bottom: 0.1em;
}

tfoot {
  font-weight: bold;
}
td > div.verse {
  white-space: pre;
}

div.hdlist {
  margin-top: 0.8em;
  margin-bottom: 0.8em;
}
div.hdlist tr {
  padding-bottom: 15px;
}
dt.hdlist1.strong, td.hdlist1.strong {
  font-weight: bold;
}
td.hdlist1 {
  vertical-align: top;
  font-style: normal;
  padding-right: 0.8em;
  color: navy;
}
td.hdlist2 {
  vertical-align: top;
}
div.hdlist.compact tr {
  margin: 0;
  padding-bottom: 0;
}

.comment {
  background: yellow;
}

.footnote, .footnoteref {
  font-size: 0.8em;
}

span.footnote, span.footnoteref {
  vertical-align: super;
}

#footnotes {
  margin: 20px 0 20px 0;
  padding: 7px 0 0 0;
}

#footnotes div.footnote {
  margin: 0 0 5px 0;
}

#footnotes hr {
  border: none;
  border-top: 1px solid silver;
  height: 1px;
  text-align: left;
  margin-left: 0;
  width: 20%;
  min-width: 100px;
}

div.colist td {
  padding-right: 0.5em;
  padding-bottom: 0.3em;
  vertical-align: top;
}
div.colist td img {
  margin-top: 0.3em;
}

@media print {
  #footer-badges { display: none; }
}

#toc {
  margin-bottom: 2.5em;
}

#toctitle {
  color: #527bbd;
  font-size: 1.1em;
  font-weight: bold;
  margin-top: 1.0em;
  margin-bottom: 0.1em;
}

div.toclevel0, div.toclevel1, div.toclevel2, div.toclevel3, div.toclevel4 {
  margin-top: 0;
  margin-bottom: 0;
}
div.toclevel2 {
  margin-left: 2em;
  font-size: 0.9em;
}
div.toclevel3 {
  margin-left: 4em;
  font-size: 0.9em;
}
div.toclevel4 {
  margin-left: 6em;
  font-size: 0.9em;
}

span.aqua { color: aqua; }
span.black { color: black; }
span.blue { color: blue; }
span.fuchsia { color: fuchsia; }
span.gray { color: gray; }
span.green { color: green; }
span.lime { color: lime; }
span.maroon { color: maroon; }
span.navy { color: navy; }
span.olive { color: olive; }
span.purple { color: purple; }
span.red { color: red; }
span.silver { color: silver; }
span.teal { color: teal; }
span.white { color: white; }
span.yellow { color: yellow; }

span.aqua-background { background: aqua; }
span.black-background { background: black; }
span.blue-background { background: blue; }
span.fuchsia-background { background: fuchsia; }
span.gray-background { background: gray; }
span.green-background { background: green; }
span.lime-background { background: lime; }
span.maroon-background { background: maroon; }
span.navy-background { background: navy; }
span.olive-background { background: olive; }
span.purple-background { background: purple; }
span.red-background { background: red; }
span.silver-background { background: silver; }
span.teal-background { background: teal; }
span.white-background { background: white; }
span.yellow-background { background: yellow; }

span.big { font-size: 2em; }
span.small { font-size: 0.6em; }

span.underline { text-decoration: underline; }
span.overline { text-decoration: overline; }
span.line-through { text-decoration: line-through; }

div.unbreakable { page-break-inside: avoid; }


/*
 * xhtml11 specific
 *
 * */

div.tableblock {
  margin-top: 1.0em;
  margin-bottom: 1.5em;
}
div.tableblock > table {
  border: 3px solid #527bbd;
}
thead, p.table.header {
  font-weight: bold;
  color: #527bbd;
}
p.table {
  margin-top: 0;
}
/* Because the table frame attribute is overriden by CSS in most browsers. */
div.tableblock > table[frame="void"] {
  border-style: none;
}
div.tableblock > table[frame="hsides"] {
  border-left-style: none;
  border-right-style: none;
}
div.tableblock > table[frame="vsides"] {
  border-top-style: none;
  border-bottom-style: none;
}


/*
 * html5 specific
 *
 * */

table.tableblock {
  margin-top: 1.0em;
  margin-bottom: 1.5em;
}
thead, p.tableblock.header {
  font-weight: bold;
  color: #527bbd;
}
p.tableblock {
  margin-top: 0;
}
table.tableblock {
  border-width: 3px;
  border-spacing: 0px;
  border-style: solid;
  border-color: #527bbd;
  border-collapse: collapse;
}
th.tableblock, td.tableblock {
  border-width: 1px;
  padding: 4px;
  border-style: solid;
  border-color: #527bbd;
}

table.tableblock.frame-topbot {
  border-left-style: hidden;
  border-right-style: hidden;
}
table.tableblock.frame-sides {
  border-top-style: hidden;
  border-bottom-style: hidden;
}
table.tableblock.frame-none {
  border-style: hidden;
}

th.tableblock.halign-left, td.tableblock.halign-left {
  text-align: left;
}
th.tableblock.halign-center, td.tableblock.halign-center {
  text-align: center;
}
th.tableblock.halign-right, td.tableblock.halign-right {
  text-align: right;
}

th.tableblock.valign-top, td.tableblock.valign-top {
  vertical-align: top;
}
th.tableblock.valign-middle, td.tableblock.valign-middle {
  vertical-align: middle;
}
th.tableblock.valign-bottom, td.tableblock.valign-bottom {
  vertical-align: bottom;
}


/*
 * manpage specific
 *
 * */

body.manpage h1 {
  padding-top: 0.5em;
  padding-bottom: 0.5em;
  border-top: 2px solid silver;
  border-bottom: 2px solid silver;
}
body.manpage h2 {
  border-style: none;
}
body.manpage div.sectionbody {
  margin-left: 3em;
}

@media print {
  body.manpage div#toc { display: none; }
}
.highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #808080 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0040D0 } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */


</style>
<script type="text/javascript">
/*<![CDATA[*/
var asciidoc = {  // Namespace.

/////////////////////////////////////////////////////////////////////
// Table Of Contents generator
/////////////////////////////////////////////////////////////////////

/* Author: Mihai Bazon, September 2002
 * http://students.infoiasi.ro/~mishoo
 *
 * Table Of Content generator
 * Version: 0.4
 *
 * Feel free to use this script under the terms of the GNU General Public
 * License, as long as you do not remove or alter this notice.
 */

 /* modified by Troy D. Hanson, September 2006. License: GPL */
 /* modified by Stuart Rackham, 2006, 2009. License: GPL */

// toclevels = 1..4.
toc: function (toclevels) {

  function getText(el) {
    var text = "";
    for (var i = el.firstChild; i != null; i = i.nextSibling) {
      if (i.nodeType == 3 /* Node.TEXT_NODE */) // IE doesn't speak constants.
        text += i.data;
      else if (i.firstChild != null)
        text += getText(i);
    }
    return text;
  }

  function TocEntry(el, text, toclevel) {
    this.element = el;
    this.text = text;
    this.toclevel = toclevel;
  }

  function tocEntries(el, toclevels) {
    var result = new Array;
    var re = new RegExp('[hH]([1-'+(toclevels+1)+'])');
    // Function that scans the DOM tree for header elements (the DOM2
    // nodeIterator API would be a better technique but not supported by all
    // browsers).
    var iterate = function (el) {
      for (var i = el.firstChild; i != null; i = i.nextSibling) {
        if (i.nodeType == 1 /* Node.ELEMENT_NODE */) {
          var mo = re.exec(i.tagName);
          if (mo && (i.getAttribute("class") || i.getAttribute("className")) != "float") {
            result[result.length] = new TocEntry(i, getText(i), mo[1]-1);
          }
          iterate(i);
        }
      }
    }
    iterate(el);
    return result;
  }

  var toc = document.getElementById("toc");
  if (!toc) {
    return;
  }

  // Delete existing TOC entries in case we're reloading the TOC.
  var tocEntriesToRemove = [];
  var i;
  for (i = 0; i < toc.childNodes.length; i++) {
    var entry = toc.childNodes[i];
    if (entry.nodeName.toLowerCase() == 'div'
     && entry.getAttribute("class")
     && entry.getAttribute("class").match(/^toclevel/))
      tocEntriesToRemove.push(entry);
  }
  for (i = 0; i < tocEntriesToRemove.length; i++) {
    toc.removeChild(tocEntriesToRemove[i]);
  }

  // Rebuild TOC entries.
  var entries = tocEntries(document.getElementById("content"), toclevels);
  for (var i = 0; i < entries.length; ++i) {
    var entry = entries[i];
    if (entry.element.id == "")
      entry.element.id = "_toc_" + i;
    var a = document.createElement("a");
    a.href = "#" + entry.element.id;
    a.appendChild(document.createTextNode(entry.text));
    var div = document.createElement("div");
    div.appendChild(a);
    div.className = "toclevel" + entry.toclevel;
    toc.appendChild(div);
  }
  if (entries.length == 0)
    toc.parentNode.removeChild(toc);
},


/////////////////////////////////////////////////////////////////////
// Footnotes generator
/////////////////////////////////////////////////////////////////////

/* Based on footnote generation code from:
 * http://www.brandspankingnew.net/archive/2005/07/format_footnote.html
 */

footnotes: function () {
  // Delete existing footnote entries in case we're reloading the footnodes.
  var i;
  var noteholder = document.getElementById("footnotes");
  if (!noteholder) {
    return;
  }
  var entriesToRemove = [];
  for (i = 0; i < noteholder.childNodes.length; i++) {
    var entry = noteholder.childNodes[i];
    if (entry.nodeName.toLowerCase() == 'div' && entry.getAttribute("class") == "footnote")
      entriesToRemove.push(entry);
  }
  for (i = 0; i < entriesToRemove.length; i++) {
    noteholder.removeChild(entriesToRemove[i]);
  }

  // Rebuild footnote entries.
  var cont = document.getElementById("content");
  var spans = cont.getElementsByTagName("span");
  var refs = {};
  var n = 0;
  for (i=0; i<spans.length; i++) {
    if (spans[i].className == "footnote") {
      n++;
      var note = spans[i].getAttribute("data-note");
      if (!note) {
        // Use [\s\S] in place of . so multi-line matches work.
        // Because JavaScript has no s (dotall) regex flag.
        note = spans[i].innerHTML.match(/\s*\[([\s\S]*)]\s*/)[1];
        spans[i].innerHTML =
          "[<a id='_footnoteref_" + n + "' href='#_footnote_" + n +
          "' title='View footnote' class='footnote'>" + n + "</a>]";
        spans[i].setAttribute("data-note", note);
      }
      noteholder.innerHTML +=
        "<div class='footnote' id='_footnote_" + n + "'>" +
        "<a href='#_footnoteref_" + n + "' title='Return to text'>" +
        n + "</a>. " + note + "</div>";
      var id =spans[i].getAttribute("id");
      if (id != null) refs["#"+id] = n;
    }
  }
  if (n == 0)
    noteholder.parentNode.removeChild(noteholder);
  else {
    // Process footnoterefs.
    for (i=0; i<spans.length; i++) {
      if (spans[i].className == "footnoteref") {
        var href = spans[i].getElementsByTagName("a")[0].getAttribute("href");
        href = href.match(/#.*/)[0];  // Because IE return full URL.
        n = refs[href];
        spans[i].innerHTML =
          "[<a href='#_footnote_" + n +
          "' title='View footnote' class='footnote'>" + n + "</a>]";
      }
    }
  }
},

install: function(toclevels) {
  var timerId;

  function reinstall() {
    asciidoc.footnotes();
    if (toclevels) {
      asciidoc.toc(toclevels);
    }
  }

  function reinstallAndRemoveTimer() {
    clearInterval(timerId);
    reinstall();
  }

  timerId = setInterval(reinstall, 500);
  if (document.addEventListener)
    document.addEventListener("DOMContentLoaded", reinstallAndRemoveTimer, false);
  else
    window.onload = reinstallAndRemoveTimer;
}

}
asciidoc.install();
/*]]>*/
</script>
</head>
<body class="book">
<div id="header">
</div>
<div id="content">
<div class="sect1">
<h2 id="__33">Глава 33</h2>
<div class="sectionbody">
</div>
</div>
<h1 id="__">Парсинг комбінатора</h1>
<div class="paragraph"><p>Occasionally, you may need to process a small, special-purpose language. For example, you may need
to read configuration files for your software, and you want to make them easier to modify by hand than
XML. Alternatively, maybe you want to support an input language in your program, such as search
terms with boolean operators (computer, find me a movie "with &#8216;space ships&#8217; and without &#8216;love
stories"<em>). Whatever the reason, you are going to need aparser. You need a way to convert the input
language into some data structure your software can process.
Essentially, you have only a few choices. One choice is to roll your own parser (and lexical analyzer).
If you are not an expert, this is hard. If you are an expert, it is still time consuming.
An alternative choice is to use a parser generator. There exist quite a few of these generators. Some of
the better known are Yacc and Bison for parsers written in C and ANTLR for parsers written in
Java. You&#8217;ll probably also need a scanner generator such as Lex, Flex, or JFlex to go with it. This might
be the best solution, except for a couple of inconveniences. You need to learn new tools, including their
—sometimes obscure—error messages. You also need to figure out how to connect the output of these
tools to your program. This might limit the choice of your programming language, and complicate your
tool chain.
This chapter presents a third alternative. Instead of using the standalone domain specific language of a
parser generator, you will use an internal domain specific language, or internal DSL for short. The
internal DSL will consist of a library of parser combinators—functions and operators defined in Scala
that will serve as building blocks for parsers. These building blocks will map one to one to the
constructions of a context-free grammar, to make them easy to understand.
This chapter introduces only one language feature that was not explained before: thisaliasing,
in Section 33.6. The chapter does, however, heavily use several other features that were explained in
previous chapters. Among others, parameterized types, abstract types, functions as objects, operator
overloading, by-name parameters, and implicit conversions all play important roles. The chapter shows
how these language elements can be combined in the design of a very high-level library.
The concepts explained in this chapter tend to be a bit more advanced than previous chapters. If you
have a good grounding in compiler construction, you&#8217;ll profit from it reading this chapter, because it
will help you put things better in perspective. However, the only prerequisite for understanding this
chapter is that you know about regular and context-free grammars. If you don&#8217;t, the material in this
chapter can also safely be skipped.33.1 EXAMPLE: ARITHMETIC EXPRESSIONS
We&#8217;ll start with an example. Say you want to construct a parser for arithmetic expressions consisting of
floating-point numbers, parentheses, and the binary operators <code>, -, <strong>, and /. The first step is always to
write down a grammar for the language to be parsed. Here&#8217;s the grammar for arithmetic expressions:
expr ::= term {"</code>" term | "-" term}.
term ::= factor {"</strong>" factor | "/" factor}.
factor ::= floatingPointNumber | "(" expr ")".
Here, | denotes alternative productions, and { &#8230; } denotes repetition (zero or more times). And
although there&#8217;s no use of it in this example, [ &#8230; ] denotes an optional occurrence.
This context-free grammar defines formally a language of arithmetic expressions. Every expression
(represented by expr) is a term, which can be followed by a sequence of + or -operators and
further terms. A term is a factor, possibly followed by a sequence of * or /operators and further factors.
A factor is either a numeric literal or an expression in parentheses. Note that the grammar already
encodes the relative precedence of operators. For instance, * binds more tightly than <code>, because
a * operation gives a term, whereas a +operation gives an expr, and exprs can contain terms but
a term can contain an expr only when the latter is enclosed in parentheses.
Now that you have defined the grammar, what&#8217;s next? If you use Scala&#8217;s combinator parsers, you are
basically done! You only need to perform some systematic text replacements and wrap the parser in a
class, as shown in Listing 33.1:
import scala.util.parsing.combinator._
class
def
def
def
}
Arith extends JavaTokenParsers {
expr: Parser[Any] = term<sub>rep("</code>"</sub>term | "-"<sub>term)
term: Parser[Any] = factor</sub>rep("<strong>"<sub>factor | "/"</sub>factor)
factor: Parser[Any] = floatingPointNumber | "("<sub>expr</sub>")"
Listing 33.1 - An arithmetic expression parser.
The parsers for arithmetic expressions are contained in a class that inherits from the
traitJavaTokenParsers. This trait provides the basic machinery for writing a parser and also provides
some primitive parsers that recognize some word classes: identifiers, string literals and numbers. In the
example in Listing 33.1 you need only the primitive floatingPointNumberparser, which is inherited
from this trait.
The three definitions in class Arith represent the productions for arithmetic expressions. As you can
see, they follow very closely the productions of the context-free grammar. In fact, you could generate
this part automatically from the context-free grammar, by performing a number of simple text
replacements:
1. Every production becomes a method, so you need to prefix it with def.2. The result type of each method is Parser[Any], so you need to change the ::= symbol to
": Parser[Any] =". You&#8217;ll find out later in this chapter what the type Parser[Any] signifies, and
also how to make it more precise.
3. In the grammar, sequential composition was implicit, but in the program it is expressed by an
explicit operator: <sub>. So you need to insert a </sub> between every two consecutive symbols of a
production. In the example in Listing 33.1 we chose not to write any spaces around
the <sub> operator. That way, the parser code keeps closely to the visual appearance of the grammar
—it just replaces spaces by </sub> characters.
4. Repetition is expressed rep( &#8230; ) instead of { &#8230; }. Analogously (though not shown in the
example), option is expressed opt( &#8230; ) instead of [ &#8230; ].
5. The period (.) at the end of each production is omitted—you can, however, write a semicolon (;)
if you prefer.
That&#8217;s all there is to it. The resulting class Arith defines three parsers, expr, term and factor, which can
be used to parse arithmetic expressions and their parts.
33.2 RUNNING YOUR PARSER
You can exercise your parser with the following small program:
object ParseExpr extends Arith {
def main(args: Array[String]) = {
println("input : " + args(0))
println(parseAll(expr, args(0)))
}
}
The ParseExpr object defines a main method that parses the first command-line argument passed to it.
It prints the original input argument, and then prints its parsed version. Parsing is done by the
expression:
parseAll(expr, input)
This expression applies the parser, expr, to the given input. It expects that all of the input matches, i.e.,
that there are no characters trailing a parsed expression. There&#8217;s also a methodparse, which allows you
to parse an input prefix, leaving some remainder unread.
You can run the arithmetic parser with the following command:
$ scala ParseExpr "2 * (3 + 7)"
input: 2 * (3 + 7)
[1.12] parsed: 2<sub>List((</strong></sub></sub>)))<sub>List())
The output tells you that the parser successfully analyzed the input string up to position [1.12]. That
means the first line and the twelfth column—in other words, the whole input string—was parsed.
Disregard for the moment the result after "parsed:". It is not very useful, and you will find out later how
to get more specific parser results.You can also try to introduce some input string that is not a legal expression. For instance, you could
write one closing parenthesis too many:
$ scala ParseExpr "2 * (3 + 7))"
input: 2 * (3 + 7))
[1.12] failure: `-</em> expected but `)&#8217; found
2 * (3 + 7))
<sup>
Here, the expr parser parsed everything until the final closing parenthesis, which does not form part of
the arithmetic expression. The parseAll method then issued an error message, which said that it
expected a - operator at the point of the closing parenthesis. You&#8217;ll find out later in this chapter why it
produced this particular error message, and how you can improve it.
33.3 BASIC REGULAR EXPRESSION PARSERS
The parser for arithmetic expressions made use of another parser, named floatingPointNumber. This
parser, which was inherited from Arith&#8217;s supertrait, JavaTokenParsers, recognizes a floating point
number in the format of Java. But what do you do if you need to parse numbers in a format that&#8217;s a bit
different from Java&#8217;s? In this situation, you can use a regular expression parser.
The idea is that you can use any regular expression as a parser. The regular expression parses all strings
that it can match. Its result is the parsed string. For instance, the regular expression parser shown
in Listing 33.2 describes Java&#8217;s identifiers:
object MyParsers extends RegexParsers {
val ident: Parser[String] = """[a-zA-Z_]\w*""".r
}
Listing 33.2 - A regular expression parser for Java identifiers.
The MyParsers object of Listing 33.2 inherits from trait RegexParsers, whereas Arith inherited
from JavaTokenParsers. Scala&#8217;s parsing combinators are arranged in a hierarchy of traits, which are all
contained in package scala.util.parsing.combinator. The top-level trait is Parsers, which defines a very
general parsing framework for all sorts of input. One level below is traitRegexParsers, which requires
that the input is a sequence of characters and provides for regular expression parsing. Even more
specialized is trait JavaTokenParsers, which implements parsers for basic classes of words (or tokens)
as they are defined in Java.
33.4 ANOTHER EXAMPLE: JSON
JSON, the JavaScript Object Notation, is a popular data interchange format. In this section, we&#8217;ll show
you how to write a parser for it. Here&#8217;s a grammar that describes the syntax of JSON:
value
::= obj | arr | stringLiteral |
floatingPointNumber |
"null" | "true" | "false".obj
::= "{" [members] "}".
arr
::= "[" [values] "]".
members ::= member {"," member}.
member ::= stringLiteral ":" value.
values
::= value {"," value}.
A JSON value is an object, array, string, number, or one of the three reserved words null, true, or false.
A JSON object is a (possibly empty) sequence of members separated by commas and enclosed in
braces. Each member is a string/value pair where the string and the value are separated by a colon.
Finally, a JSON array is a sequence of values separated by commas and enclosed in square brackets. As
an example, Listing 33.3 contains an address-book formatted as a JSON object.
{
"address book": {
"name": "John Smith",
"address": {
"street": "10 Market Street",
"city" : "San Francisco, CA",
"zip"
: 94111
},
"phone numbers": [
"408 338-4238",
"408 111-6892"
]
}
}
Listing 33.3 - Data in JSON format.
Parsing such data is straightforward when using Scala&#8217;s parser combinators. The complete parser is
shown in Listing 33.4. This parser follows the same structure as the arithmetic expression parser. It is
again a straightforward mapping of the productions of the JSON grammar. The productions use one
shortcut that simplifies the grammar: The repsepcombinator parses a (possibly empty) sequence of
terms that are separated by a given separator string. For instance, in the example in Listing
33.4, repsep(member, ",") parses a comma-separated sequence of member terms. Otherwise, the
productions in the parser correspond exactly to the productions in the grammar, as was the case for the
arithmetic expression parsers.
import scala.util.parsing.combinator._
class JSON extends JavaTokenParsers {
def value : Parser[Any] = obj | arr |
stringLiteral |
floatingPointNumber |
"null" | "true" | "false"
}
def obj : Parser[Any] = "{"</sub>repsep(member, ",")<sub>"}"
def arr : Parser[Any] = "["</sub>repsep(value, ",")<sub>"]"
def member: Parser[Any] = stringLiteral</sub>":"<sub>valueListing 33.4 - A simple JSON parser.
To try out the JSON parsers, we&#8217;ll change the framework a bit, so that the parser operates on a file
instead of on the command line:
import java.io.FileReader
object ParseJSON extends JSON {
def main(args: Array[String]) = {
val reader = new FileReader(args(0))
println(parseAll(value, reader))
}
}
The main method in this program first creates a FileReader object. It then parses the characters returned
by that reader according to the value production of the JSON grammar. Note
thatparseAll and parse exist in overloaded variants: both can take a character sequence or alternatively
an input reader as second argument.
If you store the "address book" object shown in Listing 33.3 into a file named address-book.jsonand
run the ParseJSON program on it, you should get:
$ scala ParseJSON address-book.json
[13.4] parsed: {</sub>List<sub>}, (("phone numbers"</sub>:)<sub>(([</sub>
List("408 338-4238", "408 111-6892"))<sub>]))))</sub>}))))<sub>})
33.5 PARSER OUTPUT
The ParseJSON program successfully parsed the JSON address book. However, the parser output looks
strange. It seems to be a sequence composed of bits and pieces of the input glued together with lists
and </sub> combinations. This output is not very useful. It is less readable for humans than the input, but it is
also too disorganized to be easily analyzable by a computer. It&#8217;s time to do something about this.
To figure out what to do, you need to know first what the individual parsers in the combinator
frameworks return as a result (provided they succeed in parsing the input). Here are the rules:
1. Each parser written as a string (such as: "{" or ":" or "null") returns the parsed string itself.
2. Regular expression parsers such as """[a-zA-Z_]\w*""".r also return the parsed string itself. The
same holds for regular expression parsers such as stringLiteral or floatingPointNumber, which
are inherited from trait JavaTokenParsers.
3. A sequential composition P<sub>Q returns the results of both P and of Q. These results are returned
in an instance of a case class that is also written </sub>. So if P returns "true" and Qreturns "?", then
the sequential composition P<sub>Q returns </sub>("true", "?"), which prints as(true<sub>?).
4. An alternative composition P | Q returns the result of either P or Q, whichever one succeeds.
5. A repetition rep(P) or repsep(P, separator) returns a list of the results of all runs of P.
6. An option opt(P) returns an instance of Scala&#8217;s Option type. It returns Some&#174; if P succeeds
with result R and None if P fails.With these rules you can now deduce why the parser output appeared as it did in the previous
examples. However, the output is still not very convenient. It would be much better to map a JSON
object into an internal Scala representation that represents the meaning of the JSON value. A more
natural representation would be as follows:
• A JSON object is represented as a Scala map of type Map[String, Any]. Every member is
represented as a key/value binding in the map.
• A JSON array is represented as a Scala list of type List[Any].
• A JSON string is represented as a Scala String.
• A JSON numeric literal is represented as a Scala Double.
• The values true, false, and null are represented as the Scala values with the same names.
To produce this representation, you need to make use of one more combination form for parsers: </sup>^.
The <sup>^ operator transforms the result of a parser. Expressions using this operator have the
form P </sup>^ f where P is a parser and f is a function. P <sup>^ f parses the same sentences as just P.
Whenever P returns with some result R, the result of P </sup>^ f is f&#174;.
As an example, here is a parser that parses a floating point number and converts it to a Scala value of
type Double:
floatingPointNumber <sup>^ (<em>.toDouble)
And here is a parser that parses the string "true" and returns Scala&#8217;s boolean true value:
"true" </sup>^ (x &#8658; true)
Now for more advanced transformations. Here&#8217;s a new version of a parser for JSON objects that returns
a Scala Map:
def obj: Parser[Map[String, Any]] = // Can be improved
"{"</sub>repsep(member, ",")<sub>"}" <sup>^
{ case "{"</sub>ms<sub>"}" &#8658; Map() <code> ms }
Remember that the </sub> operator produces as its result an instance of a case class with the same name: <sub>.
Here&#8217;s a definition of that class—it&#8217;s an inner class of trait Parsers:
case class </sub>[<code>A, +B](x: A, y: B) {
override def toString = "(" + x + "<sub>" + y + ")"
}
The name of the class is intentionally the same as the name of the sequence combinator method, </sub>.
That way, you can match parser results with patterns that follow the same structure as the parsers
themselves. For instance, the pattern "{"<sub>ms</sub>"}" matches a result string "{" followed by a result
variable ms, which is followed in turn by a result string "}". This pattern corresponds exactly to what is
returned by the parser on the left of the </sup>^. In its desugared versions where the <sub> operator comes first,
the same pattern reads </sub>(<sub>("{", ms), "}"), but this is much less legible.The purpose of the "{"</sub>ms<sub>"}" pattern is to strip off the braces so that you can get at the list of
members resulting from the repsep(member, ",") parser. In cases like these there is also an alternative
that avoids producing unnecessary parser results that are immediately discarded by the pattern match.
The alternative makes use of the </sub>&gt; and &lt;<sub> parser combinators. Both express sequential composition
like </sub>, but <sub>&gt; keeps only the result of its right operand, whereas &lt;</sub> keeps only the result of its left
operand. Using these combinators, the JSON object parser can be expressed more succinctly:
def obj: Parser[Map[String, Any]] =
"{"<sub>&gt; repsep(member, ",") &lt;</sub>"}" <sup>^ (Map() </code> _)
Listing 33.5 shows a full JSON parser that returns meaningful results. If you run this parser on
the address-book.json file, you will get the following result (after adding some newlines and
indentation):
$ scala JSON1Test address-book.json
[14.1] parsed: Map(
address book &#8594; Map(
name &#8594; John Smith,
address &#8594; Map(
street &#8594; 10 Market Street,
city &#8594; San Francisco, CA,
zip &#8594; 94111),
phone numbers &#8594; List(408 338-4238, 408 111-6892)
)
)
This is all you need to know in order to get started writing your own parsers. As an aide to
memory, Table 33.1 lists the parser combinators that were discussed so far.
import scala.util.parsing.combinator.</em>
class JSON1 extends JavaTokenParsers {
def obj: Parser[Map[String, Any]] =
"{"<sub>&gt; repsep(member, ",") &lt;</sub>"}" </sup>^ (Map() +</code> <em>)
def arr: Parser[List[Any]] =
"["<sub>&gt; repsep(value, ",") &lt;</sub>"]"
def member: Parser[(String, Any)] =
stringLiteral<sub>":"</sub>value <sup>^
{ case name<sub>":"</sub>value &#8658; (name, value) }
}
def value: Parser[Any] = (
obj
| arr
| stringLiteral
| floatingPointNumber </sup>^ (</em>.toDouble)
| "null" <sup>^ (x &#8658; null)
| "true" </sup>^ (x &#8658; true)
| "false" <sup>^ (x &#8658; false)
)Listing 33.5 - A full JSON parser that returns meaningful results.
Table 33.1 - Summary of parser combinators
"&#8230;"
"&#8230;".r
P<sub>Q
P &lt;</sub> Q, P <sub>&gt; Q
P | Q
opt(P)
rep(P)
repsep(P, Q)
P </sup>^ f
literal
regular expression
sequential composition
sequential composition; keep left/right only
alternative
option
repetition
interleaved repetition
result conversion
TURNING OFF SEMICOLON INFERENCE
Note that the body of the value parser in Listing 33.5 is enclosed in parentheses. This is a little trick to
disable semicolon inference in parser expressions. You saw in Section 4.2 that Scala assumes there&#8217;s a
semicolon between any two lines that can be separate statements syntactically, unless the first line ends
in an infix operator, or the two lines are enclosed in parentheses or square brackets. Now, you could
have written the |operator at the end of the each alternative instead of at the beginning of the following
one, like this:
def value: Parser[Any] =
obj |
arr |
stringLiteral |
&#8230;
In that case, no parentheses around the body of the value parser would have been required. However,
some people prefer to see the | operator at the beginning of the second alternative rather than at the end
of the first. Normally, this would lead to an unwanted semicolon between the two lines, like this:
obj;
| arr

The semicolon changes the structure of the code, causing it to fail compilation. Putting the whole
expression in parentheses avoids the semicolon and makes the code compile correctly.
Symbolic versus alphanumeric names
Many of the parser combinators in Table 33.1 use symbolic names. This has both advantages and
disadvantages. On the minus side, symbolic names take time to learn. Users who are unfamiliar with
Scala&#8217;s combinator parsing libraries are probably mystified what </sub>, <sub>&gt;, or <sup>^mean. On the plus side,
symbolic names are short, and can be chosen to have the "right" precedences and associativities. For
instance, the parser combinators </sub>, </sup>^, and | are chosen intentionally in decreasing order of precedence.
A typical grammar production is composed of alternatives that have a parsing part and a transformation
part. The parsing part usually contains several sequential items separated by <sub> operators. With thechosen precedences of</sub>, <sup>^, and | you can write such a grammar production without needing any
parentheses.
Furthermore, symbolic operators take less visual real estate than alphabetic ones. That&#8217;s important for a
parser because it lets you concentrate on the grammar at hand, instead of the combinators themselves.
To see the difference, imagine for a moment that sequential composition (<sub>) was called andThen and
alternative (|) was called orElse. The arithmetic expression parsers in Listing 33.1 here would look as
follows:
class ArithHypothetical extends JavaTokenParsers {
def expr: Parser[Any]
=
term andThen rep(("<code>" andThen term) orElse
("-" andThen term))
def term: Parser[Any]
=
factor andThen rep(("<strong>" andThen factor) orElse
("/" andThen factor))
def factor: Parser[Any] =
floatingPointNumber orElse
("(" andThen expr andThen ")")
}
You notice that the code becomes much longer, and that it&#8217;s hard to "see" the grammar among all those
operators and parentheses. On the other hand, somebody new to combinator parsing could probably
figure out better what the code is supposed to do.
CHOOSING BETWEEN SYMBOLIC AND ALPHABETIC NAMES
As guidelines for choosing between symbolic and alphabetic names we recommend the following:
• Use symbolic names in cases where they already have a universally established meaning. For
instance, nobody would recommend writing add instead of + for numeric addition.
• Otherwise, give preference to alphabetic names if you want your code to be understandable to
casual readers.
• You can still choose symbolic names for domain-specific libraries, if this gives clear advantages
in legibility and you do not expect anyway that a casual reader without a firm grounding in the
domain would be able to understand the code immediately.
In the case of parser combinators we are looking at a highly domain-specific language, which casual
readers may have trouble understanding even with alphabetic names. Furthermore, symbolic names
give clear advantages in legibility for the expert. So we believe their use is warranted in this
application.
33.6 IMPLEMENTING COMBINATOR PARSERS
The previous sections have shown that Scala&#8217;s combinator parsers provide a convenient means for
constructing your own parsers. Since they are nothing more than a Scala library, they fit seamlessly into
your Scala programs. So it&#8217;s very easy to combine a parser with some code that processes the results itdelivers, or to rig a parser so that it takes its input from some specific source (say, a file, a string, or a
character array).
How is this achieved? In the rest of this chapter you&#8217;ll take a look "under the hood" of the combinator
parser library. You&#8217;ll see what a parser is, and how the primitive parsers and parser combinators
encountered in previous sections are implemented. You can safely skip these parts if all you want to do
is write some simple combinator parsers. On the other hand, reading the rest of this chapter should give
you a deeper understanding of combinator parsers in particular, and of the design principles of a
combinator domain-specific language in general.
The core of Scala&#8217;s combinator parsing framework is contained in the
traitscala.util.parsing.combinator.Parsers. This trait defines the Parser type as well as all fundamental
combinators. Except where stated explicitly otherwise, the definitions explained in the following two
subsections all reside in this trait. That is, they are assumed to be contained in a trait definition that
starts as follows:
package scala.util.parsing.combinator
trait Parsers {
&#8230; // code goes here unless otherwise stated
}
A Parser is in essence just a function from some input type to a parse result. As a first approximation,
the type could be written as follows:
type Parser[T] = Input &#8658; ParseResult[T]
Parser input
Sometimes, a parser reads a stream of tokens instead of a raw sequence of characters. A separate lexical
analyzer is then used to convert a stream of raw characters into a stream of tokens. The type of parser
inputs is defined as follows:
type Input = Reader[Elem]
The class Reader comes from the package scala.util.parsing.input. It is similar to a Stream, but also
keeps track of the positions of all the elements it reads. The type Elem represents individual input
elements. It is an abstract type member of the Parsers trait:
type Elem
This means that subclasses and subtraits of Parsers need to instantiate class Elem to the type of input
elements that are being parsed. For instance, RegexParsers and JavaTokenParsers fix Elem to be equal
to Char. But it would also be possible to set Elem to some other type, such as the type of tokens
returned from a separate lexer.Parser results
A parser might either succeed or fail on some given input. Consequently class ParseResult has two
subclasses for representing success and failure:
sealed abstract class ParseResult[+T]
case class Success[T](result: T, in: Input)
extends ParseResult[T]
case class Failure(msg: String, in: Input)
extends ParseResult[Nothing]
The Success case carries the result returned from the parser in its result parameter. The type of parser
results is arbitrary; that&#8217;s why ParseResult, Success, and Parser are all parameterized with a type
parameter T. The type parameter represents the kinds of results returned by a given parser. Success also
takes a second parameter, in, which refers to the input immediately following the part that the parser
consumed. This field is needed for chaining parsers, so that one parser can operate after another. Note
that this is a purely functional approach to parsing. Input is not read as a side effect, but it is kept in a
stream. A parser analyzes some part of the input stream, and then returns the remaining part in its
result.
The other subclass of ParseResult is Failure. This class takes as a parameter a message that describes
why the parser failed. Like Success, Failure also takes the remaining input stream as a second
parameter. This is needed not for chaining (the parser won&#8217;t continue after a failure), but to position the
error message at the correct place in the input stream.
Note that parse results are defined to be covariant in the type parameter T. That is, a parser
returning Strings as result, say, is compatible with a parser returning AnyRefs.
The Parser class
The previous characterization of parsers as functions from inputs to parse results was a bit
oversimplified. The previous examples showed that parsers also implement methods such as</sub> for
sequential composition of two parsers and | for their alternative composition. So Parseris in reality a
class that inherits from the function type Input &#8658; ParseResult[T] and additionally defines these
methods:
abstract class Parser[+T] extends (Input &#8658; ParseResult[T])
{ p &#8658;


def apply(in: Input): ParseResult[T]
def <sub> &#8230;
def | &#8230;
&#8230;
}
Since parsers are (i.e., inherit from) functions, they need to define an apply method. You see an
abstract apply method in class Parser, but this is just for documentation, as the same method is in any
case inherited from the parent type Input &#8658; ParseResult[T] (recall that this type is an abbreviationfor scala.Function1[Input, ParseResult[T]]). The apply method still needs to be implemented in the
individual parsers that inherit from the abstract Parser class. These parsers will be discussed after the
following section on this aliasing.
Aliasing this
The body of the Parser class starts with a curious expression:
abstract class Parser[+T] extends &#8230; { p &#8658;
A clause such as "id &#8658;" immediately after the opening brace of a class template defines the
identifier id as an alias for this in the class. It&#8217;s as if you had written:
val id = this
in the class body, except that the Scala compiler knows that id is an alias for this. For instance, you
could access an object-private member m of the class using either id.m or this.m; the two are
completely equivalent. The first expression would not compile if id were just defined as
a val with this as its right hand side, because in that case the Scala compiler would treat id as a normal
identifier.
You saw syntax like this in Section 29.4, where it was used to give a self type to a trait. Aliasing can
also be a good abbreviation when you need to access the this of an outer class. Here&#8217;s an example:
class Outer { outer &#8658;
class Inner {
println(Outer.this eq outer) // prints: true
}
}
The example defines two nested classes, Outer and Inner. Inside Inner the this value of the Outerclass is
referred to twice, using different expressions. The first expression shows the Java way of doing things:
You can prefix the reserved word this with the name of an outer class and a period; such an expression
then refers to the this of the outer class. The second expression shows the alternative that Scala gives
you. By introducing an alias named outer for this in class Outer, you can refer to this alias directly also
in inner classes. The Scala way is more concise, and can also improve clarity, if you choose the name
of the alias well. You&#8217;ll see examples of this here and here.
Single-token parsers
Trait Parsers defines a generic parser elem that can be used to parse any single token:
def elem(kind: String, p: Elem &#8658; Boolean) =
new Parser[Elem] {
def apply(in: Input) =
if (p(in.first)) Success(in.first, in.rest)
else Failure(kind + " expected", in)
}This parser takes two parameters: a kind string describing what kind of token should be parsed and a
predicate p on Elems, which indicates whether an element fits the class of tokens to be parsed.
When applying the parser elem(kind, p) to some input in, the first element of the input stream is tested
with predicate p. If p returns true, the parser succeeds. Its result is the element itself, and its remaining
input is the input stream starting just after the element that was parsed. On the other hand,
if p returns false, the parser fails with an error message that indicates what kind of token was expected.
Sequential composition
The elem parser only consumes a single element. To parse more interesting phrases, you can string
parsers together with the sequential composition operator </sub>. As you have seen before,P<sub>Q is a parser
that applies first the P parser to a given input string. Then, if P succeeds, the Qparser is applied to the
input that&#8217;s left after P has done its job.
The </sub> combinator is implemented as a method in class Parser. Its definition is shown inListing 33.6.
The method is a member of the Parser class. Inside this class, p is specified by the "p &#8658;" part as an
alias of this, so p designates the left operand (or: receiver) of <sub>. Its right operand is represented by
parameter q. Now, if p</sub>q is run on some input in, first p is run on inand the result is analyzed in a
pattern match. If p succeeds, q is run on the remaining inputin1. If q also succeeds, the parser as a
whole succeeds. Its result is a <sub> object containing both the result of p (i.e., x) and the result
of q (i.e., y). On the other hand, if either p or q fails the result of p</sub>q is the Failure object returned
by p or q.
abstract class Parser[+T] &#8230; { p &#8658;
&#8230;
def <sub> [U](q: &#8658; Parser[U]) = new Parser[T</sub>U] {
def apply(in: Input) = p(in) match {
case Success(x, in1) &#8658;
q(in1) match {
case Success(y, in2) &#8658; Success(new <sub>(x, y), in2)
case failure &#8658; failure
}
case failure &#8658; failure
}
}
Listing 33.6 - The </sub> combinator method.
The result type of <sub> is a parser that returns an instance of the case class </sub> with elements of
types T and U. The type expression T<sub>U is just a more legible shorthand for the parameterized
type </sub>[T, U]. Generally, Scala always interprets a binary type operation such as A op B, as the
parameterized type op[A, B]. This is analogous to the situation for patterns, where a binary
pattern P op Q is also interpreted as an application, i.e., op(P, Q).
The other two sequential composition operators, &lt;<sub> and </sub>&gt;, could be defined just like <sub>, only with
some small adjustment in how the result is computed. A more elegant technique, though, is to define
them in terms of </sub> as follows:def &lt;<sub> [U](q: &#8658; Parser[U]): Parser[T] =
(p</sub>q) </sup>^ { case x<sub>y &#8658; x }
def </sub>&gt; [U](q: &#8658; Parser[U]): Parser[U] =
(p<sub>q) <sup>^ { case x</sub>y &#8658; y }
Alternative composition
An alternative composition P | Q applies either P or Q to a given input. It first tries P. If Psucceeds, the
whole parser succeeds with the result of P. Otherwise, if P fails, then Q is tried on the same input as P.
The result of Q is then the result of the whole parser.
Here is a definition of | as a method of class Parser:
def | (q: &#8658; Parser[T]) = new Parser[T] {
def apply(in: Input) = p(in) match {
case s1 @ Success(<em>, _) &#8658; s1
case failure &#8658; q(in)
}
}
Note that if P and Q both fail, then the failure message is determined by Q. This subtle choice is
discussed later, in Section 33.9.
Dealing with recursion
Note that the q parameter in methods <sub> and | is by-name—its type is preceded by &#8658;. This means that
the actual parser argument will be evaluated only when q is needed, which should only be the case
after p has run. This makes it possible to write recursive parsers like the following one which parses a
number enclosed by arbitrarily many parentheses:
def parens = floatingPointNumber | "("</sub>parens<sub>")"
If | and </sub> took by-value parameters, this definition would immediately cause a stack overflow without
reading anything, because the value of parens occurs in the middle of its right-hand side.
Result conversion
The last method of class Parser converts a parser&#8217;s result. The parser P </sup>^ f succeeds exactly
when P succeeds. In that case it returns P&#8217;s result converted using the function f. Here is the
implementation of this method:
def <sup>^ [U](f: T &#8658; U): Parser[U] = new Parser[U] {
def apply(in: Input) = p(in) match {
case Success(x, in1) &#8658; Success(f(x), in1)
case failure &#8658; failure
}
}
} // end ParserParsers that don&#8217;t read any input
There are also two parsers that do not consume any input: success and failure. The
parsersuccess(result) always succeeds with the given result. The parser failure(msg) always fails with
error message msg. Both are implemented as methods in trait Parsers, the outer trait that also contains
class Parser:
def success[T](v: T) = new Parser[T] {
def apply(in: Input) = Success(v, in)
}
def failure(msg: String) = new Parser[Nothing] {
def apply(in: Input) = Failure(msg, in)
}
Option and repetition
Also defined in trait Parsers are the option and repetition combinators opt, rep, and repsep.They are all
implemented in terms of sequential composition, alternative, and result conversion:
def opt[T](p: &#8658; Parser[T]): Parser[Option[T]] = (
p </sup>^ Some(</em>)
| success(None)
)
def rep[T](p: &#8658; Parser[T]): Parser[List[T]] = (
p<sub>rep(p) <sup>^ { case x</sub>xs &#8658; x :: xs }
| success(List())
)
def repsep[T](p: &#8658; Parser[T],
q: &#8658; Parser[Any]): Parser[List[T]] = (
p<sub>rep(q</sub>&gt; p) </sup>^ { case r<sub>rs &#8658; r :: rs }
| success(List())
)
} // end Parsers
33.7 STRING LITERALS AND REGULAR EXPRESSIONS
The parsers you saw so far made use of string literals and regular expressions to parse single words.
The support for these comes from RegexParsers, a subtrait of Parsers:
trait RegexParsers extends Parsers {
This trait is more specialized than trait Parsers in that it only works for inputs that are sequences of
characters:
type Elem = Char
It defines two methods, literal and regex, with the following signatures:
implicit def literal(s: String): Parser[String] = &#8230;
implicit def regex(r: Regex): Parser[String] = &#8230;Note that both methods have an implicit modifier, so they are automatically applied whenever
a String or Regex is given but a Parser is expected. That&#8217;s why you can write string literals and regular
expressions directly in a grammar, without having to wrap them with one of these methods. For
instance, the parser "("</sub>expr<sub>")" will be automatically expanded toliteral("(")</sub>expr<sub>literal(")").
The RegexParsers trait also takes care of handling white space between symbols. To do this, it calls a
method named handleWhiteSpace before running a literal or regex parser.
ThehandleWhiteSpace method skips the longest input sequence that conforms to the whiteSpaceregular
expression, which is defined by default as follows:
protected val whiteSpace = """\s</code>""".r
} // end RegexParsers
If you prefer a different treatment of white space, you can override the whiteSpace val. For instance, if
you want white space not to be skipped at all, you can override whiteSpace with the empty regular
expression:
object MyParsers extends RegexParsers {
override val whiteSpace = "".r
&#8230;
}
33.8 LEXING AND PARSING
The task of syntax analysis is often split into two phases. The lexer phase recognizes individual words
in the input and classifies them into some token classes. This phase is also called lexical analysis. This
is followed by a syntactical analysis phase that analyzes sequences of tokens. Syntactical analysis is
also sometimes just called parsing, even though this is slightly imprecise, as lexical analysis can also be
regarded as a parsing problem.
The Parsers trait as described in the previous section can be used for either phase, because its input
elements are of the abstract type Elem. For lexical analysis, Elem would be instantiated toChar,
meaning the individual characters that make up a word are being parsed. The syntactical analyzer
would in turn instantiate Elem to the type of token returned by the lexer.
Scala&#8217;s parsing combinators provide several utility classes for lexical and syntactic analysis. These are
contained in two sub-packages, one for each kind of analysis:
scala.util.parsing.combinator.lexical
scala.util.parsing.combinator.syntactical
If you want to split your parser into a separate lexer and syntactical analyzer, you should consult the
Scaladoc documentation for these packages. But for simple parsers, the regular expression based
approach shown previously in this chapter is usually sufficient.33.9 ERROR REPORTING
There&#8217;s one final topic that was not covered yet: how does the parser issue an error message? Error
reporting for parsers is somewhat of a black art. One problem is that when a parser rejects some input,
it generally has encountered many different failures. Each alternative parse must have failed, and
recursively so at each choice point. Which of the usually numerous failures should be emitted as error
message to the user?
Scala&#8217;s parsing library implements a simple heuristic: among all failures, the one that occurred at the
latest position in the input is chosen. In other words, the parser picks the longest prefix that is still valid
and issues an error message that describes why parsing the prefix could not be continued further. If
there are several failure points at that latest position, the one that was visited last is chosen.
For instance, consider running the JSON parser on a faulty address book which starts with the line:
{ "name": John,
The longest legal prefix of this phrase is "{ "name": ". So the JSON parser will flag the word Johnas an
error. The JSON parser expects a value at this point, but John is an identifier, which does not count as a
value (presumably, the author of the document had forgotten to enclose the name in quotation marks).
The error message issued by the parser for this document is:
[1.13] failure: "false" expected but identifier John found
{ "name": John,
<sup>
The part that "false" was expected comes from the fact that "false" is the last alternative of the
production for value in the JSON grammar. So this was the last failure at this point. Users who know
the JSON grammar in detail can reconstruct the error message, but for non-experts this error message is
probably surprising and can also be quite misleading.
A better error message can be engineered by adding a "catch-all" failure point as last alternative of
a value production:
def value: Parser[Any] =
obj | arr | stringLit | floatingPointNumber | "null" |
"true" | "false" | failure("illegal start of value")
This addition does not change the set of inputs that are accepted as valid documents. What it does is
improve the error messages, because now it will be the explicitly added failure that comes as last
alternative and therefore gets reported:
[1.13] failure: illegal start of value
{ "name": John,
</sup>
The implementation of the "latest possible" scheme of error reporting uses a field namedlastFailure in
trait Parsers to mark the failure that occurred at the latest position in the input:var lastFailure: Option[Failure] = None
The field is initialized to None. It is updated in the constructor of the Failure class:
case class Failure(msg: String, in: Input)
extends ParseResult[Nothing] {
}
if (lastFailure.isDefined &amp;&amp;
lastFailure.get.in.pos &#8656; in.pos)
lastFailure = Some(this)
The field is read by the phrase method, which emits the final error message if the parser failed. Here is
the implementation of phrase in trait Parsers:
def phrase[T](p: Parser[T]) = new Parser[T] {
lastFailure = None
def apply(in: Input) = p(in) match {
case s @ Success(out, in1) &#8658;
if (in1.atEnd) s
else Failure("end of input expected", in1)
case f : Failure &#8658;
lastFailure
}
}
The phrase method runs its argument parser p. If p succeeds with a completely consumed input, the
success result of p is returned. If p succeeds but the input is not read completely, a failure with message
"end of input expected" is returned. If p fails, the failure or error stored in lastFailure is returned. Note
that the treatment of lastFailure is non-functional; it is updated as a side effect by the constructor
of Failure and by the phrase method itself. A functional version of the same scheme would be possible,
but it would require threading thelastFailure value through every parser result, no matter whether this
result is a Success or aFailure.
33.10 BACKTRACKING VERSUS LL(1)
The parser combinators employ backtracking to choose between different parsers in an alternative. In
an expression P | Q, if P fails, then Q is run on the same input as P. This happens even if P has parsed
some tokens before failing. In this case the same tokens will be parsed again by Q.
Backtracking imposes only a few restrictions on how to formulate a grammar so that it can be parsed.
Essentially, you just need to avoid left-recursive productions. A production such as:
expr ::= expr "<code>" term | term.
will always fail because expr immediately calls itself and thus never progresses any further.<span class="footnote"><br />[There are ways to avoid stack overflows even in the presence of left-recursion, but this requires a more refined parsing combinator framework, which to date has not been implemented.]<br /></span>On the
other hand, backtracking is potentially costly because the same input can be parsed several times.
Consider for instance the production:
expr ::= term "</code>" expr | term.What happens if the expr parser is applied to an input such as (1 + 2) * 3 which constitutes a legal
term? The first alternative would be tried, and would fail when matching the + sign. Then the second
alternative would be tried on the same term and this would succeed. In the end the term ended up being
parsed twice.
It is often possible to modify the grammar so that backtracking can be avoided. For instance, in the case
of arithmetic expressions, either one of the following productions would work:
expr ::= term ["<code>" expr].
expr ::= term {"</code>" term}.
Many languages admit so-called "LL(1)" grammars.<span class="footnote"><br />[Aho, et. al., Compilers: Principles, Techniques, and Tools. [Aho86]]<br /></span> When a combinator parser is formed from such
a grammar, it will never backtrack, i.e., the input position will never be reset to an earlier value. For
instance, the grammars for arithmetic expressions and JSON terms earlier in this chapter are both
LL(1), so the backtracking capabilities of the parser combinator framework are never exercised for
inputs from these languages.
The combinator parsing framework allows you to express the expectation that a grammar is LL(1)
explicitly, using a new operator </sub>!. This operator is like sequential composition <sub> but it will never
backtrack to "un-read" input elements that have already been parsed. Using this operator, the
productions in the arithmetic expression parser could alternatively be written as follows:
def expr : Parser[Any] =
term </sub>! rep("+" <sub>! term | "-" </sub>! term)
def term : Parser[Any] =
factor <sub>! rep("</strong>" </sub>! factor | "/" <sub>! factor)
def factor: Parser[Any] =
"(" </sub>! expr <sub>! ")" | floatingPointNumber
One advantage of an LL(1) parser is that it can use a simpler input technique. Input can be read
sequentially, and input elements can be discarded once they are read. That&#8217;s another reason why LL(1)
parsers are usually more efficient than backtracking parsers.
33.11 CONCLUSION
You have now seen all the essential elements of Scala&#8217;s combinator parsing framework. It&#8217;s surprisingly
little code for something that&#8217;s genuinely useful. With the framework you can construct parsers for a
large class of context-free grammars. The framework lets you get started quickly, but it is also
customizable to new kinds of grammars and input methods. Being a Scala library, it integrates
seamlessly with the rest of the language. So it&#8217;s easy to integrate a combinator parser in a larger Scala
program.
One downside of combinator parsers is that they are not very efficient, at least not when compared with
parsers generated from special purpose tools such as Yacc or Bison. There are two reasons for this.
First, the backtracking method used by combinator parsing is itself not very efficient. Depending on the
grammar and the parse input, it might yield an exponential slow-down due to repeated backtracking.This can be fixed by making the grammar LL(1) and by using the committed sequential composition
operator, </sub>!.
The second problem affecting the performance of combinator parsers is that they mix parser
construction and input analysis in the same set of operations. In effect, a parser is generated anew for
each input that&#8217;s parsed.
This problem can be overcome, but it requires a different implementation of the parser combinator
framework. In an optimizing framework, a parser would no longer be represented as a function from
inputs to parse results. Instead, it would be represented as a tree, where every construction step was
represented as a case class. For instance, sequential composition could be represented by a case
class Seq, alternative by Alt, and so on. The "outermost" parser method, phrase, could then take this
symbolic representation of a parser and convert it to highly efficient parsing tables, using standard
parser generator algorithms.
What&#8217;s nice about all this is that from a user perspective nothing changes compared to plain combinator
parsers. Users still write parsers in terms of ident, floatingPointNumber, ~, |, and so on. They need not
be aware that these methods generate a symbolic representation of a parser instead of a parser function.
Since the phrase combinator converts these representations into real parsers, everything works as
before.
The advantage of this scheme with respect to performance is two-fold. First, you can now factor out
parser construction from input analysis. If you were to write:
val jsonParser = phrase(value)
and then apply jsonParser to several different inputs, the jsonParser would be constructed only once,
not every time an input is read.
Second, the parser generation can use efficient parsing algorithms such as LALR(1).<span class="footnote"><br />[Aho, et. al., Compilers: Principles, Techniques, and Tools. [Aho86]]<br /></span> These
algorithms usually lead to much faster parsers than parsers that operate with backtracking.
At present, such an optimizing parser generator has not yet been written for Scala. But it would be
perfectly possible to do so. If someone contributes such a generator, it will be easy to integrate into the
standard Scala library. Even postulating that such a generator will exist at some point in the future,
however, there are reasons for keeping the current parser combinator framework around. It is much
easier to understand and to adapt than a parser generator, and the difference in speed would often not
matter in practice, unless you want to parse very large inputs.</p></div>
</div>
<div id="footnotes"><hr /></div>
<div id="footer">
<div id="footer-text">
Last updated
 2019-02-18 00:43:37 EET
</div>
</div>
</body>
</html>
