<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
    "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="application/xhtml+xml; charset=UTF-8" />
<meta name="generator" content="AsciiDoc 8.6.10" />
<title></title>
<style type="text/css">
/* Shared CSS for AsciiDoc xhtml11 and html5 backends */

/* Default font. */
body {
  font-family: Georgia,serif;
}

/* Title font. */
h1, h2, h3, h4, h5, h6,
div.title, caption.title,
thead, p.table.header,
#toctitle,
#author, #revnumber, #revdate, #revremark,
#footer {
  font-family: Arial,Helvetica,sans-serif;
}

body {
  margin: 1em 5% 1em 5%;
}

a {
  color: blue;
  text-decoration: underline;
}
a:visited {
  color: fuchsia;
}

em {
  font-style: italic;
  color: navy;
}

strong {
  font-weight: bold;
  color: #083194;
}

h1, h2, h3, h4, h5, h6 {
  color: #527bbd;
  margin-top: 1.2em;
  margin-bottom: 0.5em;
  line-height: 1.3;
}

h1, h2, h3 {
  border-bottom: 2px solid silver;
}
h2 {
  padding-top: 0.5em;
}
h3 {
  float: left;
}
h3 + * {
  clear: left;
}
h5 {
  font-size: 1.0em;
}

div.sectionbody {
  margin-left: 0;
}

hr {
  border: 1px solid silver;
}

p {
  margin-top: 0.5em;
  margin-bottom: 0.5em;
}

ul, ol, li > p {
  margin-top: 0;
}
ul > li     { color: #aaa; }
ul > li > * { color: black; }

.monospaced, code, pre {
  font-family: "Courier New", Courier, monospace;
  font-size: inherit;
  color: navy;
  padding: 0;
  margin: 0;
}
pre {
  white-space: pre-wrap;
}

#author {
  color: #527bbd;
  font-weight: bold;
  font-size: 1.1em;
}
#email {
}
#revnumber, #revdate, #revremark {
}

#footer {
  font-size: small;
  border-top: 2px solid silver;
  padding-top: 0.5em;
  margin-top: 4.0em;
}
#footer-text {
  float: left;
  padding-bottom: 0.5em;
}
#footer-badges {
  float: right;
  padding-bottom: 0.5em;
}

#preamble {
  margin-top: 1.5em;
  margin-bottom: 1.5em;
}
div.imageblock, div.exampleblock, div.verseblock,
div.quoteblock, div.literalblock, div.listingblock, div.sidebarblock,
div.admonitionblock {
  margin-top: 1.0em;
  margin-bottom: 1.5em;
}
div.admonitionblock {
  margin-top: 2.0em;
  margin-bottom: 2.0em;
  margin-right: 10%;
  color: #606060;
}

div.content { /* Block element content. */
  padding: 0;
}

/* Block element titles. */
div.title, caption.title {
  color: #527bbd;
  font-weight: bold;
  text-align: left;
  margin-top: 1.0em;
  margin-bottom: 0.5em;
}
div.title + * {
  margin-top: 0;
}

td div.title:first-child {
  margin-top: 0.0em;
}
div.content div.title:first-child {
  margin-top: 0.0em;
}
div.content + div.title {
  margin-top: 0.0em;
}

div.sidebarblock > div.content {
  background: #ffffee;
  border: 1px solid #dddddd;
  border-left: 4px solid #f0f0f0;
  padding: 0.5em;
}

div.listingblock > div.content {
  border: 1px solid #dddddd;
  border-left: 5px solid #f0f0f0;
  background: #f8f8f8;
  padding: 0.5em;
}

div.quoteblock, div.verseblock {
  padding-left: 1.0em;
  margin-left: 1.0em;
  margin-right: 10%;
  border-left: 5px solid #f0f0f0;
  color: #888;
}

div.quoteblock > div.attribution {
  padding-top: 0.5em;
  text-align: right;
}

div.verseblock > pre.content {
  font-family: inherit;
  font-size: inherit;
}
div.verseblock > div.attribution {
  padding-top: 0.75em;
  text-align: left;
}
/* DEPRECATED: Pre version 8.2.7 verse style literal block. */
div.verseblock + div.attribution {
  text-align: left;
}

div.admonitionblock .icon {
  vertical-align: top;
  font-size: 1.1em;
  font-weight: bold;
  text-decoration: underline;
  color: #527bbd;
  padding-right: 0.5em;
}
div.admonitionblock td.content {
  padding-left: 0.5em;
  border-left: 3px solid #dddddd;
}

div.exampleblock > div.content {
  border-left: 3px solid #dddddd;
  padding-left: 0.5em;
}

div.imageblock div.content { padding-left: 0; }
span.image img { border-style: none; vertical-align: text-bottom; }
a.image:visited { color: white; }

dl {
  margin-top: 0.8em;
  margin-bottom: 0.8em;
}
dt {
  margin-top: 0.5em;
  margin-bottom: 0;
  font-style: normal;
  color: navy;
}
dd > *:first-child {
  margin-top: 0.1em;
}

ul, ol {
    list-style-position: outside;
}
ol.arabic {
  list-style-type: decimal;
}
ol.loweralpha {
  list-style-type: lower-alpha;
}
ol.upperalpha {
  list-style-type: upper-alpha;
}
ol.lowerroman {
  list-style-type: lower-roman;
}
ol.upperroman {
  list-style-type: upper-roman;
}

div.compact ul, div.compact ol,
div.compact p, div.compact p,
div.compact div, div.compact div {
  margin-top: 0.1em;
  margin-bottom: 0.1em;
}

tfoot {
  font-weight: bold;
}
td > div.verse {
  white-space: pre;
}

div.hdlist {
  margin-top: 0.8em;
  margin-bottom: 0.8em;
}
div.hdlist tr {
  padding-bottom: 15px;
}
dt.hdlist1.strong, td.hdlist1.strong {
  font-weight: bold;
}
td.hdlist1 {
  vertical-align: top;
  font-style: normal;
  padding-right: 0.8em;
  color: navy;
}
td.hdlist2 {
  vertical-align: top;
}
div.hdlist.compact tr {
  margin: 0;
  padding-bottom: 0;
}

.comment {
  background: yellow;
}

.footnote, .footnoteref {
  font-size: 0.8em;
}

span.footnote, span.footnoteref {
  vertical-align: super;
}

#footnotes {
  margin: 20px 0 20px 0;
  padding: 7px 0 0 0;
}

#footnotes div.footnote {
  margin: 0 0 5px 0;
}

#footnotes hr {
  border: none;
  border-top: 1px solid silver;
  height: 1px;
  text-align: left;
  margin-left: 0;
  width: 20%;
  min-width: 100px;
}

div.colist td {
  padding-right: 0.5em;
  padding-bottom: 0.3em;
  vertical-align: top;
}
div.colist td img {
  margin-top: 0.3em;
}

@media print {
  #footer-badges { display: none; }
}

#toc {
  margin-bottom: 2.5em;
}

#toctitle {
  color: #527bbd;
  font-size: 1.1em;
  font-weight: bold;
  margin-top: 1.0em;
  margin-bottom: 0.1em;
}

div.toclevel0, div.toclevel1, div.toclevel2, div.toclevel3, div.toclevel4 {
  margin-top: 0;
  margin-bottom: 0;
}
div.toclevel2 {
  margin-left: 2em;
  font-size: 0.9em;
}
div.toclevel3 {
  margin-left: 4em;
  font-size: 0.9em;
}
div.toclevel4 {
  margin-left: 6em;
  font-size: 0.9em;
}

span.aqua { color: aqua; }
span.black { color: black; }
span.blue { color: blue; }
span.fuchsia { color: fuchsia; }
span.gray { color: gray; }
span.green { color: green; }
span.lime { color: lime; }
span.maroon { color: maroon; }
span.navy { color: navy; }
span.olive { color: olive; }
span.purple { color: purple; }
span.red { color: red; }
span.silver { color: silver; }
span.teal { color: teal; }
span.white { color: white; }
span.yellow { color: yellow; }

span.aqua-background { background: aqua; }
span.black-background { background: black; }
span.blue-background { background: blue; }
span.fuchsia-background { background: fuchsia; }
span.gray-background { background: gray; }
span.green-background { background: green; }
span.lime-background { background: lime; }
span.maroon-background { background: maroon; }
span.navy-background { background: navy; }
span.olive-background { background: olive; }
span.purple-background { background: purple; }
span.red-background { background: red; }
span.silver-background { background: silver; }
span.teal-background { background: teal; }
span.white-background { background: white; }
span.yellow-background { background: yellow; }

span.big { font-size: 2em; }
span.small { font-size: 0.6em; }

span.underline { text-decoration: underline; }
span.overline { text-decoration: overline; }
span.line-through { text-decoration: line-through; }

div.unbreakable { page-break-inside: avoid; }


/*
 * xhtml11 specific
 *
 * */

div.tableblock {
  margin-top: 1.0em;
  margin-bottom: 1.5em;
}
div.tableblock > table {
  border: 3px solid #527bbd;
}
thead, p.table.header {
  font-weight: bold;
  color: #527bbd;
}
p.table {
  margin-top: 0;
}
/* Because the table frame attribute is overriden by CSS in most browsers. */
div.tableblock > table[frame="void"] {
  border-style: none;
}
div.tableblock > table[frame="hsides"] {
  border-left-style: none;
  border-right-style: none;
}
div.tableblock > table[frame="vsides"] {
  border-top-style: none;
  border-bottom-style: none;
}


/*
 * html5 specific
 *
 * */

table.tableblock {
  margin-top: 1.0em;
  margin-bottom: 1.5em;
}
thead, p.tableblock.header {
  font-weight: bold;
  color: #527bbd;
}
p.tableblock {
  margin-top: 0;
}
table.tableblock {
  border-width: 3px;
  border-spacing: 0px;
  border-style: solid;
  border-color: #527bbd;
  border-collapse: collapse;
}
th.tableblock, td.tableblock {
  border-width: 1px;
  padding: 4px;
  border-style: solid;
  border-color: #527bbd;
}

table.tableblock.frame-topbot {
  border-left-style: hidden;
  border-right-style: hidden;
}
table.tableblock.frame-sides {
  border-top-style: hidden;
  border-bottom-style: hidden;
}
table.tableblock.frame-none {
  border-style: hidden;
}

th.tableblock.halign-left, td.tableblock.halign-left {
  text-align: left;
}
th.tableblock.halign-center, td.tableblock.halign-center {
  text-align: center;
}
th.tableblock.halign-right, td.tableblock.halign-right {
  text-align: right;
}

th.tableblock.valign-top, td.tableblock.valign-top {
  vertical-align: top;
}
th.tableblock.valign-middle, td.tableblock.valign-middle {
  vertical-align: middle;
}
th.tableblock.valign-bottom, td.tableblock.valign-bottom {
  vertical-align: bottom;
}


/*
 * manpage specific
 *
 * */

body.manpage h1 {
  padding-top: 0.5em;
  padding-bottom: 0.5em;
  border-top: 2px solid silver;
  border-bottom: 2px solid silver;
}
body.manpage h2 {
  border-style: none;
}
body.manpage div.sectionbody {
  margin-left: 3em;
}

@media print {
  body.manpage div#toc { display: none; }
}


</style>
<script type="text/javascript">
/*<![CDATA[*/
var asciidoc = {  // Namespace.

/////////////////////////////////////////////////////////////////////
// Table Of Contents generator
/////////////////////////////////////////////////////////////////////

/* Author: Mihai Bazon, September 2002
 * http://students.infoiasi.ro/~mishoo
 *
 * Table Of Content generator
 * Version: 0.4
 *
 * Feel free to use this script under the terms of the GNU General Public
 * License, as long as you do not remove or alter this notice.
 */

 /* modified by Troy D. Hanson, September 2006. License: GPL */
 /* modified by Stuart Rackham, 2006, 2009. License: GPL */

// toclevels = 1..4.
toc: function (toclevels) {

  function getText(el) {
    var text = "";
    for (var i = el.firstChild; i != null; i = i.nextSibling) {
      if (i.nodeType == 3 /* Node.TEXT_NODE */) // IE doesn't speak constants.
        text += i.data;
      else if (i.firstChild != null)
        text += getText(i);
    }
    return text;
  }

  function TocEntry(el, text, toclevel) {
    this.element = el;
    this.text = text;
    this.toclevel = toclevel;
  }

  function tocEntries(el, toclevels) {
    var result = new Array;
    var re = new RegExp('[hH]([1-'+(toclevels+1)+'])');
    // Function that scans the DOM tree for header elements (the DOM2
    // nodeIterator API would be a better technique but not supported by all
    // browsers).
    var iterate = function (el) {
      for (var i = el.firstChild; i != null; i = i.nextSibling) {
        if (i.nodeType == 1 /* Node.ELEMENT_NODE */) {
          var mo = re.exec(i.tagName);
          if (mo && (i.getAttribute("class") || i.getAttribute("className")) != "float") {
            result[result.length] = new TocEntry(i, getText(i), mo[1]-1);
          }
          iterate(i);
        }
      }
    }
    iterate(el);
    return result;
  }

  var toc = document.getElementById("toc");
  if (!toc) {
    return;
  }

  // Delete existing TOC entries in case we're reloading the TOC.
  var tocEntriesToRemove = [];
  var i;
  for (i = 0; i < toc.childNodes.length; i++) {
    var entry = toc.childNodes[i];
    if (entry.nodeName.toLowerCase() == 'div'
     && entry.getAttribute("class")
     && entry.getAttribute("class").match(/^toclevel/))
      tocEntriesToRemove.push(entry);
  }
  for (i = 0; i < tocEntriesToRemove.length; i++) {
    toc.removeChild(tocEntriesToRemove[i]);
  }

  // Rebuild TOC entries.
  var entries = tocEntries(document.getElementById("content"), toclevels);
  for (var i = 0; i < entries.length; ++i) {
    var entry = entries[i];
    if (entry.element.id == "")
      entry.element.id = "_toc_" + i;
    var a = document.createElement("a");
    a.href = "#" + entry.element.id;
    a.appendChild(document.createTextNode(entry.text));
    var div = document.createElement("div");
    div.appendChild(a);
    div.className = "toclevel" + entry.toclevel;
    toc.appendChild(div);
  }
  if (entries.length == 0)
    toc.parentNode.removeChild(toc);
},


/////////////////////////////////////////////////////////////////////
// Footnotes generator
/////////////////////////////////////////////////////////////////////

/* Based on footnote generation code from:
 * http://www.brandspankingnew.net/archive/2005/07/format_footnote.html
 */

footnotes: function () {
  // Delete existing footnote entries in case we're reloading the footnodes.
  var i;
  var noteholder = document.getElementById("footnotes");
  if (!noteholder) {
    return;
  }
  var entriesToRemove = [];
  for (i = 0; i < noteholder.childNodes.length; i++) {
    var entry = noteholder.childNodes[i];
    if (entry.nodeName.toLowerCase() == 'div' && entry.getAttribute("class") == "footnote")
      entriesToRemove.push(entry);
  }
  for (i = 0; i < entriesToRemove.length; i++) {
    noteholder.removeChild(entriesToRemove[i]);
  }

  // Rebuild footnote entries.
  var cont = document.getElementById("content");
  var spans = cont.getElementsByTagName("span");
  var refs = {};
  var n = 0;
  for (i=0; i<spans.length; i++) {
    if (spans[i].className == "footnote") {
      n++;
      var note = spans[i].getAttribute("data-note");
      if (!note) {
        // Use [\s\S] in place of . so multi-line matches work.
        // Because JavaScript has no s (dotall) regex flag.
        note = spans[i].innerHTML.match(/\s*\[([\s\S]*)]\s*/)[1];
        spans[i].innerHTML =
          "[<a id='_footnoteref_" + n + "' href='#_footnote_" + n +
          "' title='View footnote' class='footnote'>" + n + "</a>]";
        spans[i].setAttribute("data-note", note);
      }
      noteholder.innerHTML +=
        "<div class='footnote' id='_footnote_" + n + "'>" +
        "<a href='#_footnoteref_" + n + "' title='Return to text'>" +
        n + "</a>. " + note + "</div>";
      var id =spans[i].getAttribute("id");
      if (id != null) refs["#"+id] = n;
    }
  }
  if (n == 0)
    noteholder.parentNode.removeChild(noteholder);
  else {
    // Process footnoterefs.
    for (i=0; i<spans.length; i++) {
      if (spans[i].className == "footnoteref") {
        var href = spans[i].getElementsByTagName("a")[0].getAttribute("href");
        href = href.match(/#.*/)[0];  // Because IE return full URL.
        n = refs[href];
        spans[i].innerHTML =
          "[<a href='#_footnote_" + n +
          "' title='View footnote' class='footnote'>" + n + "</a>]";
      }
    }
  }
},

install: function(toclevels) {
  var timerId;

  function reinstall() {
    asciidoc.footnotes();
    if (toclevels) {
      asciidoc.toc(toclevels);
    }
  }

  function reinstallAndRemoveTimer() {
    clearInterval(timerId);
    reinstall();
  }

  timerId = setInterval(reinstall, 500);
  if (document.addEventListener)
    document.addEventListener("DOMContentLoaded", reinstallAndRemoveTimer, false);
  else
    window.onload = reinstallAndRemoveTimer;
}

}
asciidoc.install();
/*]]>*/
</script>
</head>
<body class="article">
<div id="header">
</div>
<div id="content">
<div class="paragraph"><p><a href="https://datatracker.ietf.org/doc/rfc6386/?include_text=1">RFC 6386</a></p></div>
<h1 id="_посібник_із_формату_даних_та_декодування_vp8">Посібник із формату даних та декодування VP8</h1>
<div class="sect1">
<h2 id="_анотація">Анотація</h2>
<div class="sectionbody">
<div class="paragraph"><p>This document describes the VP8 compressed video data format, together with a discussion of the decoding procedure for the format.</p></div>
</div>
</div>
<div class="sect1">
<h2 id="_status_of_this_memo">Status of This Memo</h2>
<div class="sectionbody">
<div class="paragraph"><p>This document is not an Internet Standards Track specification; it is published for informational purposes.</p></div>
<div class="paragraph"><p>This is a contribution to the RFC Series, independently of any other RFC stream.  The RFC Editor has chosen to publish this document at its discretion and makes no statement about its value for implementation or deployment.  Documents approved for publication by the RFC Editor are not a candidate for any level of Internet Standard; see Section 2 of RFC 5741.</p></div>
<div class="paragraph"><p>Information about the current status of this document, any errata, and how to provide feedback on it may be obtained at <a href="http://www.rfc-editor.org/info/rfc6386">http://www.rfc-editor.org/info/rfc6386</a>.</p></div>
</div>
</div>
<div class="sect1">
<h2 id="_copyright_notice">Copyright Notice</h2>
<div class="sectionbody">
<div class="paragraph"><p>Copyright (c) 2011 IETF Trust and the persons identified as the document authors.  All rights reserved.</p></div>
<div class="paragraph"><p>This document is subject to BCP 78 and the IETF Trust&#8217;s Legal Provisions Relating to IETF Documents (<a href="http://trustee.ietf.org/license-info">http://trustee.ietf.org/license-info</a>) in effect on the date of publication of this document.  Please review these documents carefully, as they describe your rights and restrictions with respect to this document.</p></div>
</div>
</div>
<div class="sect1">
<h2 id="_1_introduction">1. Introduction</h2>
<div class="sectionbody">
<div class="paragraph"><p>This document describes the VP8 compressed video data format, together with a discussion of the decoding procedure for the format. It is intended to be used in conjunction with, and as a guide to, the reference decoder source code provided in Attachment One.  If there are any conflicts between this narrative and the reference source code, the reference source code should be considered correct.  The bitstream is defined by the reference source code and not this narrative.</p></div>
<div class="paragraph"><p>Like many modern video compression schemes, VP8 is based on decomposition of frames into square subblocks of pixels, prediction of such subblocks using previously constructed blocks, and adjustment of such predictions (as well as synthesis of unpredicted blocks) using a discrete cosine transform (hereafter abbreviated as DCT).  In one special case, however, VP8 uses a Walsh-Hadamard transform (hereafter abbreviated as WHT) instead of a DCT.</p></div>
<div class="paragraph"><p>Roughly speaking, such systems reduce datarate by exploiting the temporal and spatial coherence of most video signals.  It is more efficient to specify the location of a visually similar portion of a prior frame than it is to specify pixel values.  The frequency segregation provided by the DCT and WHT facilitates the exploitation of both spatial coherence in the original signal and the tolerance of the human visual system to moderate losses of fidelity in the reconstituted signal.</p></div>
<div class="paragraph"><p>VP8 augments these basic concepts with, among other things, sophisticated usage of contextual probabilities.  The result is a significant reduction in datarate at a given quality.</p></div>
<div class="paragraph"><p>Unlike some similar schemes (the older MPEG formats, for example), VP8 specifies exact values for reconstructed pixels.  Specifically, the specification for the DCT and WHT portions of the reconstruction does not allow for any "drift" caused by truncation of fractions. Rather, the algorithm is specified using fixed-precision integer operations exclusively.  This greatly facilitates the verification of the correctness of a decoder implementation and also avoids difficult-to-predict visual incongruities between such implementations.</p></div>
<div class="paragraph"><p>It should be remarked that, in a complete video playback system, the displayed frames may or may not be identical to the reconstructed frames.  Many systems apply a final level of filtering (commonly referred to as postprocessing) to the reconstructed frames prior to viewing. Such postprocessing has no effect on the decoding and reconstruction of subsequent frames (which are predicted using the completely specified reconstructed frames) and is beyond the scope of this document.  In practice, the nature and extent of this sort of postprocessing is dependent on both the taste of the user and on the computational facilities of the playback environment.</p></div>
<div class="paragraph"><p>The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and "OPTIONAL" in this document are to be interpreted as described in RFC 2119 [RFC2119].</p></div>
</div>
</div>
<div class="sect1">
<h2 id="_2_format_overview">2. Format Overview</h2>
<div class="sectionbody">
<div class="paragraph"><p>VP8 works exclusively with an 8-bit YUV 4:2:0 image format. In this format, each 8-bit pixel in the two chroma planes (U and V) corresponds positionally to a 2x2 block of 8-bit luma pixels in the Y plane; coordinates of the upper left corner of the Y block are of course exactly twice the coordinates of the corresponding chroma pixels.  When we refer to pixels or pixel distances without specifying a plane, we are implicitly referring to the Y plane or to the complete image, both of which have the same (full) resolution.</p></div>
<div class="paragraph"><p>As is usually the case, the pixels are simply a large array of bytes stored in rows from top to bottom, each row being stored from left to right.  This "left to right" then "top to bottom" raster-scan order is reflected in the layout of the compressed data as well.</p></div>
<div class="paragraph"><p>Provision has been made in the VP8 bitstream header for the support of a secondary YUV color format, in the form of a reserved bit.</p></div>
<div class="paragraph"><p>Occasionally, at very low datarates, a compression system may decide to reduce the resolution of the input signal to facilitate efficient compression.  The VP8 data format supports this via optional upscaling of its internal reconstruction buffer prior to output (this is completely distinct from the optional postprocessing discussed earlier, which has nothing to do with decoding per se).  This upsampling restores the video frames to their original resolution. In other words, the compression/decompression system can be viewed as a "black box", where the input and output are always at a given resolution.  The compressor might decide to "cheat" and process the signal at a lower resolution.  In that case, the decompressor needs the ability to restore the signal to its original resolution.</p></div>
<div class="paragraph"><p>Internally, VP8 decomposes each output frame into an array of macroblocks.  A macroblock is a square array of pixels whose Y dimensions are 16x16 and whose U and V dimensions are 8x8. Macroblock-level data in a compressed frame occurs (and must be processed) in a raster order similar to that of the pixels comprising the frame.</p></div>
<div class="paragraph"><p>Macroblocks are further decomposed into 4x4 subblocks.  Every macroblock has 16 Y subblocks, 4 U subblocks, and 4 V subblocks.  Any subblock-level data (and processing of such data) again occurs in raster order, this time in raster order within the containing macroblock.</p></div>
<div class="paragraph"><p>As discussed in further detail below, data can be specified at the levels of both macroblocks and their subblocks.</p></div>
<div class="paragraph"><p>Pixels are always treated, at a minimum, at the level of subblocks, which may be thought of as the "atoms" of the VP8 algorithm.  In particular, the 2x2 chroma blocks corresponding to 4x4 Y subblocks are never treated explicitly in the data format or in the algorithm specification.</p></div>
<div class="paragraph"><p>The DCT and WHT always operate at a 4x4 resolution. The DCT is used for the 16Y, 4U, and 4V subblocks.  The WHT is used (with some but not all prediction modes) to encode a 4x4 array comprising the average intensities of the 16 Y subblocks of a macroblock.  These average intensities are, up to a constant normalization factor, nothing more than the 0th DCT coefficients of the Y subblocks.  This "higher-level" WHT is a substitute for the explicit specification of those coefficients, in exactly the same way as the DCT of a subblock substitutes for the specification of the pixel values comprising the subblock.  We consider this 4x4 array as a second-order subblock called Y2, and think of a macroblock as containing 24 "real" subblocks and, sometimes, a 25th "virtual" subblock.  This is dealt with further in Section 13.</p></div>
<div class="paragraph"><p>The frame layout used by the reference decoder may be found in the file vpx_image.h (Section 20.23).</p></div>
</div>
</div>
<div class="sect1">
<h2 id="_3_compressed_frame_types">3. Compressed Frame Types</h2>
<div class="sectionbody">
<div class="paragraph"><p>There are only two types of frames in VP8.</p></div>
<div class="paragraph"><p>Intraframes (also called key frames and, in MPEG terminology, I-frames) are decoded without reference to any other frame in a sequence; that is, the decompressor reconstructs such frames beginning from its "default" state.  Key frames provide random access (or seeking) points in a video stream.</p></div>
<div class="paragraph"><p>Interframes (also called prediction frames and, in MPEG terminology, P-frames) are encoded with reference to prior frames, specifically all prior frames up to and including the most recent key frame. Generally speaking, the correct decoding of an interframe depends on the correct decoding of the most recent key frame and all ensuing frames.  Consequently, the decoding algorithm is not tolerant of dropped frames: In an environment in which frames may be dropped or corrupted, correct decoding will not be possible until a key frame is correctly received.</p></div>
<div class="paragraph"><p>In contrast to MPEG, there is no use of bidirectional prediction. No frame is predicted using frames temporally subsequent to it; there is no analog to an MPEG B-frame.</p></div>
<div class="paragraph"><p>Secondly, VP8 augments these notions with that of alternate prediction frames, called golden frames and altref frames (alternative reference frames).  Blocks in an interframe may be predicted using blocks in the immediately previous frame as well as the most recent golden frame or altref frame.  Every key frame is automatically golden and altref, and any interframe may optionally replace the most recent golden or altref frame.</p></div>
<div class="paragraph"><p>Golden frames and altref frames may also be used to partially overcome the intolerance to dropped frames discussed above: If a compressor is configured to code golden frames only with reference to the prior golden frame (and key frame), then the "substream" of key and golden frames may be decoded regardless of loss of other interframes.  Roughly speaking, the implementation requires (on the compressor side) that golden frames subsume and recode any context updates effected by the intervening interframes.  A typical application of this approach is video conferencing, in which retransmission of a prior golden frame and/or a delay in playback until receipt of the next golden frame is preferable to a larger retransmit and/or delay until the next key frame.</p></div>
</div>
</div>
<div class="sect1">
<h2 id="_4_overview_of_compressed_data_format">4. Overview of Compressed Data Format</h2>
<div class="sectionbody">
<div class="paragraph"><p>The input to a VP8 decoder is a sequence of compressed frames whose order matches their order in time.  Issues such as the duration of frames, the corresponding audio, and synchronization are generally provided by the playback environment and are irrelevant to the decoding process itself; however, to aid in fast seeking, a start code is included in the header of each key frame.</p></div>
<div class="paragraph"><p>The decoder is simply presented with a sequence of compressed frames and produces a sequence of decompressed (reconstructed) YUV frames corresponding to the input sequence.  As stated in the Introduction, the exact pixel values in the reconstructed frame are part of VP8&#8217;s specification. This document specifies the layout of the compressed frames and gives unambiguous algorithms for the correct production of reconstructed frames.</p></div>
<div class="paragraph"><p>The first frame presented to the decompressor is of course a key frame.  This may be followed by any number of interframes; the correct reconstruction of each frame depends on all prior frames up to the key frame.  The next key frame restarts this process: The decompressor resets to its default initial condition upon reception of a key frame, and the decoding of a key frame (and its ensuing interframes) is completely independent of any prior decoding.</p></div>
<div class="paragraph"><p>At the highest level, every compressed frame has three or more pieces. It begins with an uncompressed data chunk comprising 10 bytes in the case of key frames and 3 bytes for interframes.  This is followed by two or more blocks of compressed data (called partitions).  These compressed data partitions begin and end on byte boundaries.</p></div>
<div class="paragraph"><p>The first compressed partition has two subsections:</p></div>
<div class="olist arabic"><ol class="arabic">
<li>
<p>
Header information that applies to the frame as a whole.
</p>
</li>
<li>
<p>
Per-macroblock information specifying how each macroblock is predicted from the already-reconstructed data that is available to the decompressor.
</p>
</li>
</ol></div>
<div class="paragraph"><p>As stated above, the macroblock-level information occurs in raster- scan order.</p></div>
<div class="paragraph"><p>The rest of the partitions contain, for each block, the DCT/WHT coefficients (quantized and logically compressed) of the residue signal to be added to the predicted block values.  It typically accounts for roughly 70% of the overall datarate.  VP8 supports packing the compressed DCT/WHT coefficients' data from macroblock rows into separate partitions.  If there is more than one partition for these coefficients, the sizes of the partitions&#8201;&#8212;&#8201;except the last partition&#8201;&#8212;&#8201;in bytes are also present in the bitstream right after the above first partition.  Each of the sizes is a 3-byte data item written in little endian format.  These sizes provide the decoder direct access to all DCT/WHT coefficient partitions, which enables parallel processing of the coefficients in a decoder.</p></div>
<div class="paragraph"><p>The separate partitioning of the prediction data and coefficient data also allows flexibility in the implementation of a decompressor: An implementation may decode and store the prediction information for the whole frame and then decode, transform, and add the residue signal to the entire frame, or it may simultaneously decode both partitions, calculating prediction information and adding in the residue signal for each block in order.  The length field in the frame tag, which allows decoding of the second partition to begin before the first partition has been completely decoded, is necessary for the second "block-at-a-time" decoder implementation.</p></div>
<div class="paragraph"><p>All partitions are decoded using separate instances of the boolean entropy decoder described in Section 7.  Although some of the data represented within the partitions is conceptually "flat" (a bit is just a bit with no probabilistic expectation one way or the other), because of the way such coders work, there is never a direct correspondence between a "conceptual bit" and an actual physical bit in the compressed data partitions.  Only in the 3- or 10-byte uncompressed chunk described above is there such a physical correspondence.</p></div>
<div class="paragraph"><p>A related matter is that seeking within a partition is not supported. The data must be decompressed and processed (or at least stored) in the order in which it occurs in the partition.</p></div>
<div class="paragraph"><p>While this document specifies the ordering of the partition data correctly, the details and semantics of this data are discussed in a more logical fashion to facilitate comprehension.  For example, the frame header contains updates to many probability tables used in decoding per-macroblock data.  The per-macroblock data is often described before the layouts of the probabilities and their updates, even though this is the opposite of their order in the bitstream.</p></div>
<div class="olist arabic"><ol class="arabic">
<li>
<p>
Overview of the Decoding Process
</p>
</li>
</ol></div>
<div class="paragraph"><p>A VP8 decoder needs to maintain four YUV frame buffers whose resolutions are at least equal to that of the encoded image.  These buffers hold the current frame being reconstructed, the immediately previous reconstructed frame, the most recent golden frame, and the most recent altref frame.</p></div>
<div class="paragraph"><p>Most implementations will wish to "pad" these buffers with "invisible" pixels that extend a moderate number of pixels beyond all four edges of the visible image.  This simplifies interframe prediction by allowing all (or most) prediction blocks&#8201;&#8212;&#8201;which are not guaranteed to lie within the visible area of a prior frame&#8201;&#8212;&#8201;to address usable image data.</p></div>
<div class="paragraph"><p>Regardless of the amount of padding chosen, the invisible rows above (or below) the image are filled with copies of the top (or bottom) row of the image; the invisible columns to the left (or right) of the image are filled with copies of the leftmost (or rightmost) visible row; and the four invisible corners are filled with copies of the corresponding visible corner pixels.  The use of these prediction buffers (and suggested sizes for the halo) will be elaborated on in the discussion of motion vectors, interframe prediction, and sub-pixel interpolation later in this document.</p></div>
<div class="paragraph"><p>As will be seen in the description of the frame header, the image dimensions are specified (and can change) with every key frame. These buffers (and any other data structures whose size depends on the size of the image) should be allocated (or re-allocated) immediately after the dimensions are decoded.</p></div>
<div class="paragraph"><p>Leaving most of the details for later elaboration, the following is an outline of the decoding process.</p></div>
<div class="paragraph"><p>First, the frame header (the beginning of the first data partition) is decoded.  Altering or augmenting the maintained state of the decoder, this provides the context in which the per-macroblock data can be interpreted.</p></div>
<div class="paragraph"><p>The macroblock data occurs (and must be processed) in raster-scan order.  This data comes in two or more parts.  The first (prediction or mode) part comes in the remainder of the first data partition. The other parts comprise the data partition(s) for the DCT/WHT coefficients of the residue signal.  For each macroblock, the prediction data must be processed before the residue.</p></div>
<div class="paragraph"><p>Each macroblock is predicted using one (and only one) of four possible frames.  All macroblocks in a key frame, and all intra-coded macroblocks in an interframe, are predicted using the already-decoded macroblocks in the current frame.  Macroblocks in an interframe may also be predicted using the previous frame, the golden frame, or the altref frame.  Such macroblocks are said to be inter-coded.</p></div>
<div class="paragraph"><p>The purpose of prediction is to use already-constructed image data to approximate the portion of the original image being reconstructed. The effect of any of the prediction modes is then to write a macroblock-sized prediction buffer containing this approximation.</p></div>
<div class="paragraph"><p>Regardless of the prediction method, the residue DCT signal is decoded, dequantized, reverse-transformed, and added to the prediction buffer to produce the (almost final) reconstruction value of the macroblock, which is stored in the correct position of the current frame buffer.</p></div>
<div class="paragraph"><p>The residue signal consists of 24 (sixteen Y, four U, and four V) 4x4 quantized and losslessly compressed DCT transforms approximating the difference between the original macroblock in the uncompressed source and the prediction buffer.  For most prediction modes, the 0th coefficients of the sixteen Y subblocks are expressed via a 25th WHT of the second-order virtual Y2 subblock discussed above.</p></div>
<div class="paragraph"><p>Intra-prediction exploits the spatial coherence of frames.  The 16x16 luma (Y) and 8x8 chroma (UV) components are predicted independently of each other using one of four simple means of pixel propagation, starting from the already-reconstructed (16-pixel-long luma, 8-pixel- long chroma) row above, and column to the left of, the current macroblock.  The four methods are:</p></div>
<div class="olist arabic"><ol class="arabic">
<li>
<p>
Copying the row from above throughout the prediction buffer.
</p>
</li>
<li>
<p>
Copying the column from the left throughout the prediction buffer.
</p>
</li>
<li>
<p>
Copying the average value of the row and column throughout the prediction buffer.
</p>
</li>
<li>
<p>
Extrapolation from the row and column using the (fixed) second difference (horizontal and vertical) from the upper left corner.
</p>
</li>
</ol></div>
<div class="paragraph"><p>Additionally, the sixteen Y subblocks may be predicted independently of each other using one of ten different modes, four of which are 4x4 analogs of those described above, augmented with six "diagonal" prediction methods.  There are two types of predictions, one intra and one prediction (among all the modes), for which the residue signal does not use the Y2 block to encode the DC portion of the sixteen 4x4 Y subblock DCTs. This "independent Y subblock" mode has no effect on the 8x8 chroma prediction.</p></div>
<div class="paragraph"><p>Inter-prediction exploits the temporal coherence between nearby frames.  Except for the choice of the prediction frame itself, there is no difference between inter-prediction based on the previous frame and that based on the golden frame or altref frame.</p></div>
<div class="paragraph"><p>Inter-prediction is conceptually very simple. While, for reasons of efficiency, there are several methods of encoding the relationship between the current macroblock and corresponding sections of the prediction frame, ultimately each of the sixteen Y subblocks is related to a 4x4 subblock of the prediction frame, whose position in that frame differs from the current subblock position by a (usually small) displacement. These two-dimensional displacements are called motion vectors.</p></div>
<div class="paragraph"><p>The motion vectors used by VP8 have quarter-pixel precision. Prediction of a subblock using a motion vector that happens to have integer (whole number) components is very easy: The 4x4 block of pixels from the displaced block in the previous, golden, or altref frame is simply copied into the correct position of the current macroblock&#8217;s prediction buffer.</p></div>
<div class="paragraph"><p>Fractional displacements are conceptually and implementationally more complex.  They require the inference (or synthesis) of sample values that, strictly speaking, do not exist.  This is one of the most basic problems in signal processing, and readers conversant with that subject will see that the approach taken by VP8 provides a good balance of robustness, accuracy, and efficiency.</p></div>
<div class="paragraph"><p>Leaving the details for the implementation discussion below, the pixel interpolation is calculated by applying a kernel filter (using reasonable-precision integer math) three pixels on either side, both horizontally and vertically, of the pixel to be synthesized.  The resulting 4x4 block of synthetic pixels is then copied into position exactly as in the case of integer displacements.</p></div>
<div class="paragraph"><p>Each of the eight chroma subblocks is handled similarly.  Their motion vectors are never specified explicitly; instead, the motion vector for each chroma subblock is calculated by averaging the vectors of the four Y subblocks that occupy the same area of the frame.  Since chroma pixels have twice the diameter (and four times the area) of luma pixels, the calculated chroma motion vectors have 1/8-pixel resolution, but the procedure for copying or generating pixels for each subblock is essentially identical to that done in the luma plane.</p></div>
<div class="paragraph"><p>After all the macroblocks have been generated (predicted and corrected with the DCT/WHT residue), a filtering step (the loop filter) is applied to the entire frame.  The purpose of the loop filter is to reduce blocking artifacts at the boundaries between macroblocks and between subblocks of the macroblocks.  The term "loop filter" is used because this filter is part of the "coding loop"; that is, it affects the reconstructed frame buffers that are used to predict ensuing frames.  This is distinguished from the postprocessing filters discussed earlier, which affect only the viewed video and do not "feed into" subsequent frames.</p></div>
<div class="paragraph"><p>Next, if signaled in the data, the current frame may replace the golden frame prediction buffer and/or the altref frame buffer.</p></div>
<div class="paragraph"><p>The halos of the frame buffers are next filled as specified above. Finally, at least as far as decoding is concerned, the (references to) the "current" and "last" frame buffers should be exchanged in preparation for the next frame.</p></div>
<div class="paragraph"><p>Various processes may be required (or desired) before viewing the generated frame.  As discussed in the frame dimension information below, truncation and/or upscaling of the frame may be required. Some playback systems may require a different frame format (RGB, YUY2, etc.).  Finally, as mentioned in the Introduction, further postprocessing or filtering of the image prior to viewing may be desired.  Since the primary purpose of this document is a decoding specification, the postprocessing is not specified in this document.</p></div>
<div class="paragraph"><p>While the basic ideas of prediction and correction used by VP8 are straightforward, many of the details are quite complex.  The management of probabilities is particularly elaborate.  Not only do the various modes of intra-prediction and motion vector specification have associated probabilities, but they, together with the coding of DCT coefficients and motion vectors, often base these probabilities on a variety of contextual information (calculated from what has been decoded so far), as well as on explicit modification via the frame header.</p></div>
<div class="paragraph"><p>The "top-level" of decoding and frame reconstruction is implemented in the reference decoder file dixie.c (Section 20.4).</p></div>
<div class="paragraph"><p>This concludes our summary of decoding and reconstruction; we continue by discussing the individual aspects in more depth.</p></div>
<div class="paragraph"><p>A reasonable "divide and conquer" approach to implementation of a decoder is to begin by decoding streams composed exclusively of key frames.  After that works reliably, interframe handling can be added more easily than if complete functionality were attempted immediately.  In accordance with this, we first discuss components needed to decode key frames (most of which are also used in the decoding of interframes) and conclude with topics exclusive to interframes.</p></div>
<div class="olist arabic"><ol class="arabic">
<li>
<p>
Description of Algorithms
</p>
</li>
</ol></div>
<div class="paragraph"><p>As the intent of this document, together with the reference decoder source code, is to specify a platform-independent procedure for the decoding and reconstruction of a VP8 video stream, many (small) algorithms must be described exactly.</p></div>
<div class="paragraph"><p>Due to its near-universality, terseness, ability to easily describe calculation at specific precisions, and the fact that On2&#8217;s reference VP8 decoder is written in C, these algorithm fragments are written using the C programming language, augmented with a few simple definitions below.</p></div>
<div class="paragraph"><p>The standard (and best) reference for C is [Kernighan].</p></div>
<div class="paragraph"><p>Many code fragments will be presented in this document.  Some will be nearly identical to corresponding sections of the reference decoder; others will differ.  Roughly speaking, there are three reasons for such differences:</p></div>
<div class="olist arabic"><ol class="arabic">
<li>
<p>
For reasons of efficiency, the reference decoder version may be less obvious.
</p>
</li>
<li>
<p>
The reference decoder often uses large data structures to maintain context that need not be described or used here.
</p>
</li>
<li>
<p>
The authors of this document felt that a different expression of the same algorithm might facilitate exposition.
</p>
</li>
</ol></div>
<div class="paragraph"><p>Regardless of the chosen presentation, the calculation effected by any of the algorithms described here is identical to that effected by the corresponding portion of the reference decoder.</p></div>
<div class="paragraph"><p>All VP8 decoding algorithms use integer math.  To facilitate specification of arithmetic precision, we define the following types.</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>We occasionally need to discuss mathematical functions involving
honest-to-goodness "infinite precision" real numbers.  The DCT is
first described via the cosine function cos; the ratio of the lengths
of the circumference and diameter of a circle is denoted pi; at one
point, we take a (base 1/2) logarithm, denoted log; and pow(x, y)
denotes x raised to the power y.  If x = 2 and y is a small
non-negative integer, pow(2, y) may be expressed in C as 1 &lt;&lt; y.</p></div>
<div class="paragraph"><p>Finally, we sometimes need to divide signed integers by powers of
two; that is, we occasionally right-shift signed numbers.  The
behavior of such shifts (i.e., the propagation of the sign bit) is,
perhaps surprisingly, not defined by the C language itself and is
left up to individual compilers.  Because of the utility of this
frequently needed operation, it is at least arguable that it should
be defined by the language (to naturally propagate the sign bit) and,
at a minimum, should be correctly implemented by any reasonable
compiler.  In the interest of strict portability, we attempt to call
attention to these shifts when they arise.</p></div>
<div class="olist arabic"><ol class="arabic">
<li>
<p>
Boolean Entropy Decoder
</p>
</li>
</ol></div>
<div class="paragraph"><p>As discussed in the overview above, essentially the entire VP8 data
stream is encoded using a boolean entropy coder.</p></div>
<div class="paragraph"><p>An understanding of the bool_decoder is critical to the
implementation of a VP8 decompressor, so we discuss the bool_decoder
in detail.  It is easier to comprehend the bool_decoder in
conjunction with the bool_encoder used by the compressor to write the
compressed data partitions.</p></div>
<div class="paragraph"><p>The bool_encoder encodes (and the bool_decoder decodes) one bool
(zero-or-one boolean value) at a time.  Its purpose is to losslessly
compress a sequence of bools for which the probability of their being
zero or one can be well-estimated (via constant or previously coded
information) at the time they are written, using identical
corresponding probabilities at the time they are read.</p></div>
<div class="paragraph"><p>As the reader is probably aware, if a bool is much more likely to be
zero than one (for instance), it can, on average, be faithfully
encoded using much less than one bit per value.  The bool_encoder
exploits this.</p></div>
<div class="paragraph"><p>In the 1940s, [Shannon] proved that there is a lower bound for the
average datarate of a faithful encoding of a sequence of bools (whose
probability distributions are known and are independent of each
other) and also that there are encoding algorithms that approximate
this lower bound as closely as one wishes.</p></div>
<div class="paragraph"><p>If we encode a sequence of bools whose probability of being zero is p
(and whose probability of being 1 is 1-p), the lowest possible
datarate per value is</p></div>
<div class="paragraph"><p>plog(p) + (1-p)log(1-p);</p></div>
<div class="paragraph"><p>taking the logarithms to the base 1/2 expresses the datarate in bits/
value.</p></div>
<div class="paragraph"><p>We give two simple examples.  At one extreme, if p = 1/2, then log(p)
= log(1-p) = 1, and the lowest possible datarate per bool is 1/2<br />
1/2 = 1; that is, we cannot do any better than simply literally
writing out bits.  At another extreme, if p is very small, say p =
1/1024, then log(p)=10, log(1-p) is roughly .0014, and the lowest
possible datarate is approximately 10/1024 + .0014, roughly 1/100 of
a bit per bool.</p></div>
<div class="paragraph"><p>Because most of the bools in the VP8 datastream have zero-
probabilities nowhere near 1/2, the compression provided by the
bool_encoder is critical to the performance of VP8.</p></div>
<div class="paragraph"><p>The boolean coder used by VP8 is a variant of an arithmetic coder.
An excellent discussion of arithmetic coding (and other lossless
compression techniques) can be found in [Bell].</p></div>
<div class="paragraph"><p>7.1.  Underlying Theory of Coding</p></div>
<div class="paragraph"><p>The basic idea used by the boolean coder is to consider the entire
data stream (either of the partitions in our case) as the binary
expansion of a single number x with 0 &#8656; x &lt; 1.  The bits (or bytes)
in x are of course written from high to low order, and if b[j] (B[j])
is the j^(th) bit (byte) in the partition, the value x is simply the
sum (starting with j = 1) of pow(2, -j) * b[j] or pow(256, -j) *
B[j].</p></div>
<div class="paragraph"><p>Before the first bool is coded, all values of x are possible.</p></div>
<div class="paragraph"><p>The coding of each bool restricts the possible values of x in
proportion to the probability of what is coded.  If p1 is the
probability of the first bool being zero and a zero is coded, the
range of possible values of x is restricted to 0 &#8656; x &lt; p1.  If a one
is coded, the range becomes p1 &#8656; x &lt; 1.</p></div>
<div class="paragraph"><p>The coding continues by repeating the same idea.  At every stage,
there is an interval a &#8656; x &lt; b of possible values of x.  If p is the
probability of a zero being coded at this stage and a zero is coded,
the interval becomes a &#8656; x &lt; a + (p(b-a)).  If a one is coded, the
possible values of x are restricted to a + (p(b-a)) &#8656; x &lt; b.</p></div>
<div class="paragraph"><p>Assuming that only finitely many values are to be coded, after the
encoder has received the last bool, it can write as its output any
value x that lies in the final interval.  VP8 simply writes the left
endpoint of the final interval.  Consequently, the output it would
make if encoding were to stop at any time either increases or stays
the same as each bool is encoded.</p></div>
<div class="paragraph"><p>Decoding parallels encoding.  The decoder is presented with the
number x, which has only the initial restriction 0 &#8656; x &lt; 1.  To
decode the first bool, the decoder is given the first probability p1.
If x &lt; p1, a zero is decoded; if x &gt;= p1, a one is decoded.  In
either case, the new restriction on x&#8201;&#8212;&#8201;that is, the interval of
possible values of x&#8201;&#8212;&#8201;is remembered.</p></div>
<div class="paragraph"><p>Decoding continues in exactly the same way: If a &#8656; x &lt; b is the
current interval and we are to decode a bool with zero-probability p,
we return a zero if a &#8656; x &lt; a + (p(b-a)) and a one if a + (p(b-a))
&#8656; x &lt; b.  In either case, the new restriction is remembered in
preparation for decoding the next bool.</p></div>
<div class="paragraph"><p>The process outlined above uses real numbers of infinite precision to
express the probabilities and ranges.  It is true that, if one could
actualize this process and coded a large number of bools whose
supplied probabilities matched their value distributions, the
datarate achieved would approach the theoretical minimum as the
number of bools encoded increased.</p></div>
<div class="paragraph"><p>Unfortunately, computers operate at finite precision, and an
approximation to the theoretically perfect process described above is
necessary.  Such approximation increases the datarate but, at quite
moderate precision and for a wide variety of data sets, this increase
is negligible.</p></div>
<div class="paragraph"><p>The only conceptual limitations are, first, that coder probabilities
must be expressed at finite precision and, second, that the decoder
be able to detect each individual modification to the value interval
via examination of a fixed amount of input.  As a practical matter,
many of the implementation details stem from the fact that the coder
can function using only a small "window" to incrementally read or
write the arbitrarily precise number x.</p></div>
<div class="paragraph"><p>7.2.  Practical Algorithm Description</p></div>
<div class="paragraph"><p>VP8&#8217;s boolean coder works with 8-bit probabilities p.  The range of
such p is 0 &#8656; p &#8656; 255; the actual probability represented by p is
p/256.  Also, the coder is designed so that decoding of a bool
requires no more than an 8-bit comparison, and so that the state of
both the encoder and decoder can be easily represented using a small
number of unsigned 16-bit integers.</p></div>
<div class="paragraph"><p>The details are most easily understood if we first describe the
algorithm using bit-at-a-time input and output.  Aside from the
ability to maintain a position in this bitstream and write/read bits,
the encoder also needs the ability to add 1 to the bits already
output; after writing n bits, adding 1 to the existing output is the
same thing as adding pow(2, -n) to x.</p></div>
<div class="paragraph"><p>Together with the bit position, the encoder must maintain two
unsigned 8-bit numbers, which we call "bottom" and "range".  Writing
w for the n bits already written and S = pow(2, - n - 8) for the
scale of the current bit position one byte out, we have the following
constraint on all future values v of w (including the final value
v = x):</p></div>
<div class="paragraph"><p>w + ( S * bottom ) &#8656; v &lt; w + ( S * ( bottom + range ) )</p></div>
<div class="paragraph"><p>Thus, appending bottom to the already-written bits w gives the left
endpoint of the interval of possible values, appending bottom + range
gives the right endpoint, and range itself (scaled to the current
output position) is the length of the interval.</p></div>
<div class="paragraph"><p>So that our probabilistic encodings are reasonably accurate, we do
not let range vary by more than a factor of two: It stays within the
bounds 128 &#8656; range &#8656; 255.</p></div>
<div class="paragraph"><p>The process for encoding a boolean value val whose probability of
being zero is prob / 256&#8201;&#8212;&#8201;and whose probability of being one is
( 256 - prob ) / 256&#8201;&#8212;&#8201;with 1 &#8656; prob &#8656; 255 is as follows.</p></div>
<div class="paragraph"><p>Using an unsigned 16-bit multiply followed by an unsigned right
shift, we calculate an unsigned 8-bit split value:</p></div>
<div class="paragraph"><p>split = 1 + (((range - 1) * probability)]] &gt;&gt; 8)</p></div>
<div class="paragraph"><p>split is approximately ( prob / 256 ) * range and lies within the
bounds 1 &#8656; split &#8656; range - 1.  These bounds ensure the correctness
of the decoding procedure described below.</p></div>
<div class="paragraph"><p>If the incoming boolean val to be encoded is false, we leave the left
interval endpoint bottom alone and reduce range, replacing it by
split.  If the incoming val is true, we move up the left endpoint to
bottom + split, propagating any carry to the already-written value w
(this is where we need the ability to add 1 to w), and reduce range
to range - split.</p></div>
<div class="paragraph"><p>Regardless of the value encoded, range has been reduced and now has
the bounds 1 &#8656; range &#8656; 254.  If range &lt; 128, the encoder doubles it
and shifts the high-order bit out of bottom to the output as it also
doubles bottom, repeating this process one bit at a time until 128 &#8656;
range &#8656; 255.  Once this is completed, the encoder is ready to accept
another bool, maintaining the constraints described above.</p></div>
<div class="paragraph"><p>After encoding the last bool, the partition may be completed by
appending bottom to the bitstream.</p></div>
<div class="paragraph"><p>The decoder mimics the state of the encoder.  It maintains, together
with an input bit position, two unsigned 8-bit numbers, a range
identical to that maintained by the encoder and a value.  Decoding
one bool at a time, the decoder (in effect) tracks the same left
interval endpoint as does the encoder and subtracts it from the
remaining input.  Appending the unread portion of the bitstream to
the 8-bit value gives the difference between the actual value encoded
and the known left endpoint.</p></div>
<div class="paragraph"><p>The decoder is initialized by setting range = 255 and reading the
first 16 input bits into value.  The decoder maintains range and
calculates split in exactly the same way as does the encoder.</p></div>
<div class="paragraph"><p>To decode a bool, it compares value to split; if value &lt; split, the
bool is zero, and range is replaced with split.  If value &gt;= split,
the bool is one, range is replaced with range - split, and value is
replaced with value - split.</p></div>
<div class="paragraph"><p>Again, range is doubled one bit at a time until it is at least 128.
The value is doubled in parallel, shifting a new input bit into the
bottom each time.</p></div>
<div class="paragraph"><p>Writing Value for value together with the unread input bits and Range
for range extended indefinitely on the right by zeros, the condition
Value &lt; Range is maintained at all times by the decoder.  In
particular, the bits shifted out of value as it is doubled are always
zero.</p></div>
<div class="paragraph"><p>7.3.  Actual Implementation</p></div>
<div class="paragraph"><p>The C code below gives complete implementations of the encoder and
decoder described above.  While they are logically identical to the
"bit-at-a-time" versions, they internally buffer a couple of extra
bytes of the bitstream.  This allows I/O to be done (more
practically) a byte at a time and drastically reduces the number of
carries the encoder has to propagate into the already-written data.</p></div>
<div class="paragraph"><p>Another (logically equivalent) implementation may be found in the
reference decoder file bool_decoder.h (Section 20.2).</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="olist arabic"><ol class="arabic">
<li>
<p>
Compressed Data Components
</p>
</li>
</ol></div>
<div class="paragraph"><p>At the lowest level, VP8&#8217;s compressed data is simply a sequence of
probabilistically encoded bools.  Most of this data is composed of
(slightly) larger semantic units fashioned from bools, which we
describe here.</p></div>
<div class="paragraph"><p>We sometimes use these descriptions in C expressions within data
format specifications.  In this context, they refer to the return
value of a call to an appropriate bool_decoder d, reading (as always)
from its current reference point.</p></div>
<div class="paragraph"><p><code>--------------</code>-------<code>--------------------------------------------</code>
| Call| Alt.  | Return |
<code>--------------</code>-------<code>--------------------------------------------</code>
| Bool(p)| B(p)  | Bool with probability p/256 of being 0. |
|  | | Return value of read_bool(d, p).  |
|  | |  |
| Flag| F  | A one-bit flag (same thing as a B(128) or  |
|  | | an L(1)).  Abbreviated F.  Return value of |
|  | | read_bool(d, 128). |
|  | |  |
| Lit(n) | L(n)  | Unsigned n-bit number encoded as n flags|
|  | | (a "literal").  Abbreviated L(n).  The  |
|  | | bits are read from high to low order.|
|  | | Return value of read_literal(d, n).  |
|  | |  |
| SignedLit(n) | | Signed n-bit number encoded similarly to|
|  | | an L(n).  Return value of|
|  | | read_signed_literal(d, n).  These are|
|  | | rare.  |
|  | |  |
| P(8)| | An 8-bit probability.  No different from|
|  | | an L(8), but we sometimes use this|
|  | | notation to emphasize that a probability|
|  | | is being coded. |
|  | |  |
| P(7)| | A 7-bit specification of an 8-bit |
|  | | probability.  Coded as an L(7) number x;|
|  | | the resulting 8-bit probability is x ? x|
|  | | &lt;&lt; 1 : 1. |
|  | |  |
| F?  X  | | A flag that, if true, is followed by a  |
|  | | piece of data X.|
|  | |  |
| F?  X:Y| | A flag that, if true, is followed by X  |
|  | | and, if false, is followed by Y.  Also  |
|  | | used to express a value where Y is an|
|  | | implicit default (not encoded in the data  |
|  | | stream), as in F?  P(8):255, which|
|  | | expresses an optional probability: If the  |
|  | | flag is true, the probability is specified |
|  | | as an 8-bit literal, while if the flag is  |
|  | | false, the probability defaults to 255. |
|  | |  |
| B(p)?  X  | B(p)? | Variants of the above using a boolean|
|  | X:Y| indicator whose probability is not|
|  | | necessarily 128.|
|  | |  |
| T| | Tree-encoded value from small alphabet. |
<code>--------------</code>-------<code>--------------------------------------------</code></p></div>
<div class="paragraph"><p>The last type requires elaboration.  We often wish to encode
something whose value is restricted to a small number of
possibilities (the alphabet).</p></div>
<div class="paragraph"><p>This is done by representing the alphabet as the leaves of a small
binary tree.  The (non-leaf) nodes of the tree have associated
probabilities p and correspond to calls to read_bool(d, p).  We think
of a zero as choosing the left branch below the node and a one as
choosing the right branch.</p></div>
<div class="paragraph"><p>Thus, every value (leaf) whose tree depth is x is decoded after
exactly x calls to read_bool.</p></div>
<div class="paragraph"><p>A tree representing an encoding of an alphabet of n possible values
always contains n-1 non-leaf nodes, regardless of its shape (this is
easily seen by induction on n).</p></div>
<div class="paragraph"><p>There are many ways that a given alphabet can be so represented.  The
choice of tree has little impact on datarate but does affect decoder
performance.  The trees used by VP8 are chosen to (on average)
minimize the number of calls to read_bool.  This amounts to shaping
the tree so that values that are more probable have smaller tree
depth than do values that are less probable.</p></div>
<div class="paragraph"><p>Readers familiar with Huffman coding will notice that, given an
alphabet together with probabilities for each value, the associated
Huffman tree minimizes the expected number of calls to read_bool.</p></div>
<div class="paragraph"><p>Such readers will also realize that the coding method described here never results in higher datarates than does the Huffman method and, indeed, often results in much lower datarates.  Huffman coding is, in fact, nothing more than a special case of this method in which each node probability is fixed at 128 (i.e., 1/2).</p></div>
<div class="paragraph"><p>8.1.  Tree Coding Implementation</p></div>
<div class="paragraph"><p>We give a suggested implementation of a tree data structure followed by a couple of actual examples of its usage by VP8.</p></div>
<div class="paragraph"><p>It is most convenient to represent the values using small positive integers, typically an enum counting up from zero.  The largest alphabet (used to code DCT coefficients, described in Section 13) that is tree-coded by VP8 has only 12 values.  The tree for this alphabet adds 11 interior nodes and so has a total of 23 positions. Thus, an 8-bit number easily accommodates both a tree position and a return value.</p></div>
<div class="paragraph"><p>A tree may then be compactly represented as an array of (pairs of) 8-bit integers.  Each (even) array index corresponds to an interior node of the tree; the 0th index of course corresponds to the root of the tree.  The array entries come in pairs corresponding to the left (0) and right (1) branches of the subtree below the interior node. We use the convention that a positive (even) branch entry is the index of a deeper interior node, while a nonpositive entry v corresponds to a leaf whose value is -v.</p></div>
<div class="paragraph"><p>The node probabilities associated to a tree-coded value are stored in an array whose indices are half the indices of the corresponding tree positions.  The length of the probability array is one less than the size of the alphabet.</p></div>
<div class="paragraph"><p>Here is C code implementing the foregoing.  The advantages of our data structure should be noted.  Aside from the smallness of the structure itself, the tree-directed reading algorithm is essentially a single line of code.</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>Tree-based decoding is implemented in the reference decoder file
bool_decoder.h (Section 20.2).</p></div>
<div class="paragraph"><p>8.2.  Tree Coding Example</p></div>
<div class="paragraph"><p>As a multi-part example, without getting too far into the semantics
of macroblock decoding (which is of course taken up below), we look
at the "mode" coding for intra-predicted macroblocks.</p></div>
<div class="paragraph"><p>It so happens that, because of a difference in statistics, the Y (or
luma) mode encoding uses two different trees: one for key frames and
another for interframes.  This is the only instance in VP8 of the
same dataset being coded by different trees under different
circumstances.  The UV (or chroma) modes are a proper subset of the Y
modes and, as such, have their own decoding tree.</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>Since it greatly facilitates re-use of reference code, and since
there is no real reason to do otherwise, it is strongly suggested
that any decoder implementation use exactly the same enumeration
values and probability table layouts as those described in this
document (and in the reference code) for all tree-coded data in VP8.</p></div>
<div class="olist arabic"><ol class="arabic">
<li>
<p>
Frame Header
</p>
</li>
</ol></div>
<div class="paragraph"><p>The uncompressed data chunk at the start of each frame and at the
first part of the first data partition contains information
pertaining to the frame as a whole.  We list the fields in the order
of occurrence.  Most of the header decoding occurs in the reference
decoder file dixie.c (Section 20.4).</p></div>
<div class="paragraph"><p>9.1.  Uncompressed Data Chunk</p></div>
<div class="paragraph"><p>The uncompressed data chunk comprises a common (for key frames and
interframes) 3-byte frame tag that contains four fields, as follows:</p></div>
<div class="olist arabic"><ol class="arabic">
<li>
<p>
A 1-bit frame type (0 for key frames, 1 for interframes).
</p>
</li>
<li>
<p>
A 3-bit version number (0 - 3 are defined as four different
 profiles with different decoding complexity; other values may be
 defined for future variants of the VP8 data format).
</p>
</li>
<li>
<p>
A 1-bit show_frame flag (0 when current frame is not for display,
 1 when current frame is for display).
</p>
</li>
<li>
<p>
A 19-bit field containing the size of the first data partition in
 bytes.
</p>
</li>
</ol></div>
<div class="paragraph"><p>The version number setting enables or disables certain features in
the bitstream, as follows:</p></div>
<div class="paragraph"><p><code>---------</code>-------------------------<code>-------------</code>
| Version | Reconstruction Filter| Loop Filter |
<code>---------</code>-------------------------<code>-------------</code>
| 0 | Bicubic  | Normal|
|| | |
| 1 | Bilinear | Simple|
|| | |
| 2 | Bilinear | None  |
|| | |
| 3 | None  | None  |
|| | |
| Other| Reserved for future use | |
<code>---------</code>-------------------------<code>-------------</code></p></div>
<div class="paragraph"><p>The reference software also adjusts the loop filter based on version
number, as per the table above.  Version number 1 implies a "simple"
loop filter, and version numbers 2 and 3 imply no loop filter.
However, the "simple" filter setting in this context has no effect
whatsoever on the decoding process, and the "no loop filter" setting
only forces the reference encoder to set filter level equal to 0.
Neither affect the decoding process.  In decoding, the only loop
filter settings that matter are those in the frame header.</p></div>
<div class="paragraph"><p>For key frames, the frame tag is followed by a further 7 bytes of
uncompressed data, as follows:</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>The following source code segment illustrates validation of the start
code and reading the width, height, and scale factors for a key
frame.</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>Where pbi&#8594;source points to the beginning of the frame.</p></div>
<div class="paragraph"><p>The following code reads the image dimension from the bitstream:</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>Where the swap2 macro takes care of the endian on a different
platform:</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>While each frame is encoded as a raster scan of 16x16 macroblocks,
the frame dimensions are not necessarily evenly divisible by 16.  In
this case, write ew = 16 - (width &amp; 15) and eh = 16 - (height &amp; 15)
for the excess width and height, respectively.  Although they are encoded, the last ew columns and eh rows are not actually part of the
image and should be discarded before final output.  However, these
"excess pixels" should be maintained in the internal reconstruction
buffer used to predict ensuing frames.</p></div>
<div class="paragraph"><p>The scaling specifications for each dimension are encoded as follows.</p></div>
<div class="literalblock">
<div class="content">
<pre><code>+-------+--------------------------------------+
| Value | Scaling|
+-------+--------------------------------------+
| 0  | No upscaling (the most common case). |
| |  |
| 1  | Upscale by 5/4. |
| |  |
| 2  | Upscale by 5/3. |
| |  |
| 3  | Upscale by 2.|
+-------+--------------------------------------+</code></pre>
</div></div>
<div class="paragraph"><p>Upscaling does not affect the reconstruction buffer, which should be
maintained at the encoded resolution.  Any reasonable method of
upsampling (including any that may be supported by video hardware in
the playback environment) may be used.  Since scaling has no effect
on decoding, we do not discuss it any further.</p></div>
<div class="paragraph"><p>As discussed in Section 5, allocation (or re-allocation) of data
structures (such as the reconstruction buffer) whose size depends on
dimension will be triggered here.</p></div>
<div class="paragraph"><p>9.2.  Color Space and Pixel Type (Key Frames Only)</p></div>
<div class="literalblock">
<div class="content">
<pre><code>+-------+------------------------------------------+
| Field | Value|
+-------+------------------------------------------+
| L(1)  | 1-bit color space type specification  |
| ||
| L(1)  | 1-bit pixel value clamping specification |
+-------+------------------------------------------+</code></pre>
</div></div>
<div class="paragraph"><p>The color space type bit is encoded as follows:</p></div>
<div class="paragraph"><p>o  0 - YUV color space similar to the YCrCb color space defined in</p></div>
<div class="paragraph"><p>o  1 - Reserved for future use</p></div>
<div class="paragraph"><p>The pixel value clamping type bit is encoded as follows:</p></div>
<div class="paragraph"><p>o  0 - Decoders are required to clamp the reconstructed pixel values
to between 0 and 255 (inclusive).</p></div>
<div class="paragraph"><p>o  1 - Reconstructed pixel values are guaranteed to be between 0 and
255; no clamping is necessary.</p></div>
<div class="paragraph"><p>Information in this subsection does not appear in interframes.</p></div>
<div class="paragraph"><p>9.3.  Segment-Based Adjustments</p></div>
<div class="paragraph"><p>This subsection contains probability and value information for implementing segment adaptive adjustments to default decoder behavior.  The data in this subsection is used in the decoding of the ensuing per-segment information and applies to the entire frame. When segment adaptive adjustments are enabled, each macroblock will be assigned a segment ID.  Macroblocks with the same segment ID belong to the same segment and have the same adaptive adjustments over default baseline values for the frame.  The adjustments can be quantizer level or loop filter strength.</p></div>
<div class="paragraph"><p>The context for decoding this feature at the macroblock level is
provided by a subsection in the frame header, which contains:</p></div>
<div class="olist arabic"><ol class="arabic">
<li>
<p>
A segmentation_enabled flag that enables the feature for this
 frame if set to 1, and disables it if set to 0.  The following
 fields occur if the feature is enabled.
</p>
</li>
<li>
<p>
L(1) indicates if the segment map is updated for the current
 frame (update_mb_segmentation_map).
</p>
</li>
<li>
<p>
L(1) indicates if the segment feature data items are updated for
 the current frame (update_segment_feature_data).
</p>
</li>
<li>
<p>
If Item 3 above (update_segment_feature_data) is 1, the following
 fields occur:
</p>
<div class="olist loweralpha"><ol class="loweralpha">
<li>
<p>
L(1), the mode of segment feature data
  (segment_feature_mode), can be absolute-value mode (0) or
  delta value mode (1).
</p>
</li>
<li>
<p>
Segment feature data items are decoded segment by segment for
  each segment feature.  For every data item, a one-bit flag
  indicates whether the item is 0, or a non-zero value to be
  decoded.  If the value is non-zero, then the value is decoded
  as a magnitude L(n), followed by a one-bit sign (L(1)&#8201;&#8212;&#8201;0
  for positive and 1 for negative).  The length n can be looked
  up from a pre-defined length table for all feature data.
</p>
</li>
</ol></div>
</li>
<li>
<p>
If the L(1) flag as noted in Item 2 above is set to 1, the
 probabilities of the decoding tree for the segment map are
 decoded from the bitstream.  Each probability is decoded with a
 one-bit flag indicating whether the probability is the default
 value of 255 (flag is set to 0), or an 8-bit value, L(8), from
 the bitstream.
</p>
</li>
</ol></div>
<div class="paragraph"><p>The layout and semantics supporting this feature at the macroblock
level are described in Section 10.</p></div>
<div class="paragraph"><p>9.4.  Loop Filter Type and Levels</p></div>
<div class="paragraph"><p>VP8 supports two types of loop filters having different computational
complexity.  The following bits occur in the header to support the
selection of the baseline type, strength, and sharpness behavior of
the loop filter used for the current frame.</p></div>
<div class="literalblock">
<div class="content">
<pre><code>+-------+-------------------+
| Index | Description |
+-------+-------------------+
| L(1)  | filter_type |
| | |
| L(6)  | loop_filter_level |
| | |
| L(3)  | sharpness_level|
+-------+-------------------+</code></pre>
</div></div>
<div class="paragraph"><p>The meaning of these numbers will be further explained in Section 15.</p></div>
<div class="paragraph"><p>VP8 has a feature in the bitstream that enables adjustment of the
loop filter level based on a macroblock&#8217;s prediction mode and
reference frame.  The per-macroblock adjustment is done through delta
values against the default loop filter level for the current frame.
This subsection contains flag and value information for implementing
per-macroblock loop filter level adjustment to default decoder
behavior.  The data in this section is used in the decoding of the
ensuing per-macroblock information and applies to the entire frame.</p></div>
<div class="paragraph"><p>L(1) is a one-bit flag indicating if the macroblock loop filter
adjustment is on for the current frame.  0 means that such a feature
is not supported in the current frame, and 1 means this feature is
enabled for the current frame.</p></div>
<div class="paragraph"><p>Whether the adjustment is based on a reference frame or encoding
mode, the adjustment of the loop filter level is done via a delta
value against a baseline loop filter value.  The delta values are
updated for the current frame if an L(1) bit,
mode_ref_lf_delta_update, takes the value 1.  There are two groups of
delta values: One group of delta values is for reference frame-based
adjustments, and the other group is for mode-based adjustments.  The
number of delta values in the two groups is MAX_REF_LF_DELTAS and
MAX_MODE_LF_DELTAS, respectively.  For every value within the two
groups, there is a one-bit L(1) to indicate if the particular value
is updated.  When one is updated (1), it is transmitted as a six-bit-
magnitude L(6) followed by a one-bit sign flag (L(1)&#8201;&#8212;&#8201;0 for
positive and 1 for negative).</p></div>
<div class="paragraph"><p>9.5.  Token Partition and Partition Data Offsets</p></div>
<div class="paragraph"><p>VP8 allows DCT coefficients to be packed into multiple partitions,
besides the first partition with header and per-macroblock prediction
information, so the decoder can perform parallel decoding in an
efficient manner.  A two-bit L(2) is used to indicate the number of
coefficient data partitions within a compressed frame.  The two bits
are defined in the following table:</p></div>
<div class="literalblock">
<div class="content">
<pre><code>+-------+-------+----------------------+
| Bit 1 | Bit 0 | Number of Partitions |
+-------+-------+----------------------+
| 0  | 0  | 1  |
| | | |
| 0  | 1  | 2  |
| | | |
| 1  | 0  | 4  |
| | | |
| 1  | 1  | 8  |
+-------+-------+----------------------+</code></pre>
</div></div>
<div class="paragraph"><p>Offsets are embedded in the bitstream to provide the decoder direct
access to token partitions.  If the number of data partitions is
greater than 1, the size of each partition (except the last) is
written in 3 bytes (24 bits).  The size of the last partition is the
remainder of the data not used by any of the previous partitions.</p></div>
<div class="paragraph"><p>The partitioned data are consecutive in the bitstream, so the size
can also be used to calculate the offset of each partition.  The
following pseudocode illustrates how the size/offset is defined by
the three bytes in the bitstream.</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>9.6.  Dequantization Indices</p></div>
<div class="paragraph"><p>All residue signals are specified via a quantized 4x4 DCT applied to
the Y, U, V, or Y2 subblocks of a macroblock.  As detailed in
Section 14, before inverting the transform, each decoded coefficient
is multiplied by one of six dequantization factors, the choice of
which depends on the plane (Y, chroma = U or V, Y2) and coefficient
position (DC = coefficient 0, AC = coefficients 1-15).  The six
values are specified using 7-bit indices into six corresponding fixed
tables (the tables are given in Section 14).</p></div>
<div class="paragraph"><p>The first 7-bit index gives the dequantization table index for
Y-plane AC coefficients, called yac_qi.  It is always coded and acts
as a baseline for the other 5 quantization indices, each of which is
represented by a delta from this baseline index.  Pseudocode for
reading the indices follows:</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>Where delta() is the process to read 5 bits from the bitstream to
determine a signed delta value:</p></div>
<div class="literalblock">
<div class="content">
<pre><code>+-------+--------------------------------------------------+
| Index | Description  |
+-------+--------------------------------------------------+
| L(4)  | Magnitude of delta |
| |  |
| L(1)  | Sign of delta, 0 for positive and 1 for negative |
+-------+--------------------------------------------------+</code></pre>
</div></div>
<div class="paragraph"><p>9.7.  Refresh Golden Frame and Altref Frame</p></div>
<div class="paragraph"><p>For key frames, both the golden frame and the altref frame are
refreshed/ replaced by the current reconstructed frame, by default.
For non-key frames, VP8 uses two bits to indicate whether the two
frame buffers are refreshed, using the reconstructed current frame:</p></div>
<div class="paragraph"><p><code>-------</code>----------------------------------------------------------+
| Index | Description |
<code>-------</code>----------------------------------------------------------+
| L(1)  | Whether golden frame is refreshed (0 for no, 1 for yes). |
| | |
| L(1)  | Whether altref frame is refreshed (0 for no, 1 for yes). |
<code>-------</code>----------------------------------------------------------+</p></div>
<div class="paragraph"><p>When the flag for the golden frame is 0, VP8 uses 2 more bits in the
bitstream to indicate whether the buffer (and which buffer) is copied
to the golden frame, or if no buffer is copied:</p></div>
<div class="literalblock">
<div class="content">
<pre><code>+-------+------------------------------------------+
| Index | Description|
+-------+------------------------------------------+
| L(2)  | Buffer copy flag for golden frame buffer |
+-------+------------------------------------------+</code></pre>
</div></div>
<div class="paragraph"><p>Where:</p></div>
<div class="paragraph"><p>o  0 means no buffer is copied to the golden frame</p></div>
<div class="paragraph"><p>o  1 means last_frame is copied to the golden frame</p></div>
<div class="paragraph"><p>o  2 means alt_ref_frame is copied to the golden frame</p></div>
<div class="paragraph"><p>Similarly, when the flag for altref is 0, VP8 uses 2 bits in the
bitstream to indicate which buffer is copied to alt_ref_frame.</p></div>
<div class="literalblock">
<div class="content">
<pre><code>+-------+------------------------------------------+
| Index | Description|
+-------+------------------------------------------+
| L(2)  | Buffer copy flag for altref frame buffer |
+-------+------------------------------------------+</code></pre>
</div></div>
<div class="paragraph"><p>Where:</p></div>
<div class="paragraph"><p>o  0 means no buffer is copied to the altref frame</p></div>
<div class="paragraph"><p>o  1 means last_frame is copied to the altref frame</p></div>
<div class="paragraph"><p>o  2 means golden_frame is copied to the altref frame</p></div>
<div class="paragraph"><p>Two bits are transmitted for ref_frame_sign_bias for golden_frame and
alt_ref_frame, respectively.</p></div>
<div class="literalblock">
<div class="content">
<pre><code>+-------+---------------------------------+
| Index | Description|
+-------+---------------------------------+
| L(1)  | Sign bias flag for golden frame |
| ||
| L(1)  | Sign bias flag for altref frame |
+-------+---------------------------------+</code></pre>
</div></div>
<div class="paragraph"><p>These values are used to control the sign of the motion vectors when
a golden frame or an altref frame is used as the reference frame for
a macroblock.</p></div>
<div class="paragraph"><p>9.8.  Refresh Last Frame Buffer</p></div>
<div class="paragraph"><p>VP8 uses one bit, L(1), to indicate if the last frame reference buffer is refreshed using the constructed current frame.  On a key frame, this bit is overridden, and the last frame buffer is always refreshed.</p></div>
<div class="paragraph"><p>9.9.  DCT Coefficient Probability Update</p></div>
<div class="paragraph"><p>This field contains updates to the probability tables used to decode DCT coefficients.  For each of the probabilities in the tables, there is an L(1) flag indicating if the probability is updated for the current frame, and if the L(1) flag is set to 1, there follows an additional 8-bit value representing the new probability value.  These tables are maintained across interframes but are of course replaced with their defaults at the beginning of every key frame.</p></div>
<div class="paragraph"><p>The layout and semantics of this field will be taken up in Section 13.</p></div>
<div class="paragraph"><p>9.10.  Remaining Frame Header Data (Non-Key Frame)</p></div>
<div class="paragraph"><p><code>-------</code>-----------------------------------------------------------+
| Index | Description  |
<code>-------</code>-----------------------------------------------------------+
| L(1)  | mb_no_skip_coeff.  This flag indicates at the frame level |
| | if skipping of macroblocks with no non-zero coefficients  |
| | is enabled.  If it is set to 0, then prob_skip_false is|
| | not read and mb_skip_coeff is forced to 0 for all|
| | macroblocks (see Sections 11.1 and 12.1).  |
| |  |
| L(8)  | prob_skip_false = probability used for decoding a|
| | macroblock-level flag, which indicates if a macroblock |
| | has any non-zero coefficients.  Only read if  |
| | mb_no_skip_coeff is 1.|
| |  |
| L(8)  | prob_intra = probability that a macroblock is "intra"  |
| | predicted (that is, predicted from the already-encoded |
| | portions of the current frame), as opposed to "inter"  |
| | predicted (that is, predicted from the contents of a|
| | prior frame).|
| |  |
| L(8)  | prob_last = probability that an inter-predicted  |
| | macroblock is predicted from the immediately previous  |
| | frame, as opposed to the most recent golden frame or|
| | altref frame.|
| |  |
| L(8)  | prob_gf = probability that an inter-predicted macroblock  |
| | is predicted from the most recent golden frame, as  |
| | opposed to the altref frame.|
| |  |
| F  | If true, followed by four L(8)s updating the  |
| | probabilities for the different types of intra-prediction |
| | for the Y plane.  These probabilities correspond to the|
| | four interior nodes of the decoding tree for intra-Y|
| | modes in an interframe, that is, the even positions in |
| | the ymode_tree array given above. |
| |  |
| F  | If true, followed by three L(8)s updating the |
| | probabilities for the different types of intra-prediction |
| | for the chroma planes.  These probabilities correspond to |
| | the even positions in the uv_mode_tree array given above. |
| |  |
| X  | Motion vector probability update.  Details are given in|
| | Section 17.2, "Probability Updates". |
<code>-------</code>-----------------------------------------------------------+</p></div>
<div class="paragraph"><p>Decoding of this portion of the frame header is handled in the
reference decoder file dixie.c (Section 20.4).</p></div>
<div class="paragraph"><p>9.11.  Remaining Frame Header Data (Key Frame)</p></div>
<div class="paragraph"><p><code>-------</code>-----------------------------------------------------------+
| Index | Description  |
<code>-------</code>-----------------------------------------------------------+
| L(1)  | mb_no_skip_coeff.  This flag indicates at the frame level |
| | if skipping of macroblocks with no non-zero coefficients  |
| | is enabled.  If it is set to 0, then prob_skip_false is|
| | not read and mb_skip_coeff is forced to 0 for all|
| | macroblocks (see Sections 11.1 and 12.1).  |
| |  |
| L(8)  | prob_skip_false = Probability used for decoding a|
| | macroblock-level flag, which indicates if a macroblock |
| | has any non-zero coefficients.  Only read if  |
| | mb_no_skip_coeff is 1.|
<code>-------</code>-----------------------------------------------------------+</p></div>
<div class="paragraph"><p>Decoding of this portion of the frame header is handled in the
reference decoder file modemv.c (Section 20.11).</p></div>
<div class="paragraph"><p>This completes the layout of the frame header.  The remainder of the
first data partition consists of macroblock-level prediction data.</p></div>
<div class="paragraph"><p>After the frame header is processed, all probabilities needed to
decode the prediction and residue data are known and will not change
until the next frame.</p></div>
<div class="olist arabic"><ol class="arabic">
<li>
<p>
Segment-Based Feature Adjustments
</p>
</li>
</ol></div>
<div class="paragraph"><p>Every macroblock may optionally override some of the default
behaviors of the decoder.  Specifically, VP8 uses segment-based
adjustments to support changing quantizer level and loop filter level
for a macroblock.  When the segment-based adjustment feature is
enabled for a frame, each macroblock within the frame is coded with a
segment_id.  This effectively segments all the macroblocks in the
current frame into a number of different segments.  Macroblocks
within the same segment behave exactly the same for quantizer and
loop filter level adjustments.</p></div>
<div class="paragraph"><p>If both the segmentation_enabled and update_mb_segmentation_map flags
in subsection B of the frame header take a value of 1, the prediction
data for each (intra- or inter-coded) macroblock begins with a
specification of segment_id for the current macroblock.  It is
decoded using this simple tree &#8230;</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="olist lowerroman"><ol class="lowerroman">
<li>
<p>
combined with a 3-entry probability table,
mb_segment_tree_probs[3].  The macroblock&#8217;s segment_id is used later
in the decoding process to look into the segment_feature_data table
and determine how the quantizer and loop filter levels are adjusted.
</p>
</li>
</ol></div>
<div class="paragraph"><p>The decoding of segment_id, together with the parsing of
intra-prediction modes (which is taken up next), is implemented in
the reference decoder file modemv.c.</p></div>
<div class="olist arabic"><ol class="arabic">
<li>
<p>
Key Frame Macroblock Prediction Records
</p>
</li>
</ol></div>
<div class="paragraph"><p>After specifying the features described above, the macroblock
prediction record next specifies the prediction mode used for the
macroblock.</p></div>
<div class="paragraph"><p>11.1.  mb_skip_coeff</p></div>
<div class="paragraph"><p>The single bool flag is decoded using prob_skip_false if and only if
mb_no_skip_coeff is set to 1 (see Sections 9.10 and 9.11).  If
mb_no_skip_coeff is set to 0, then this value defaults to 0.</p></div>
<div class="paragraph"><p>11.2.  Luma Modes</p></div>
<div class="paragraph"><p>First comes the luma specification of type intra_mbmode, coded using
the kf_ymode_tree, as described in Section 8 and repeated here for
convenience:</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>For key frames, the Y mode is decoded using a fixed probability array
as follows:</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>d is of course the bool_decoder being used to read the first data
partition.</p></div>
<div class="paragraph"><p>If the Ymode is B_PRED, it is followed by a (tree-coded) mode for
each of the 16 Y subblocks.  The 10 subblock modes and their coding
tree are as follows:</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>The first four modes are smaller versions of the similarly named
16x16 modes above, albeit with slightly different numbering.  The
last six "diagonal" modes are unique to luma subblocks.</p></div>
<div class="paragraph"><p>11.3.  Subblock Mode Contexts</p></div>
<div class="paragraph"><p>The coding of subblock modes in key frames uses the modes already
coded for the subblocks to the left of and above the subblock to
select a probability array for decoding the current subblock mode.
This is our first instance of contextual prediction, and there are
several caveats associated with it:</p></div>
<div class="olist arabic"><ol class="arabic">
<li>
<p>
The adjacency relationships between subblocks are based on the
 normal default raster placement of the subblocks.
</p>
</li>
<li>
<p>
The adjacent subblocks need not lie in the current macroblock.
 The subblocks to the left of the left-edge subblocks 0, 4, 8, and
 12 are the right-edge subblocks 3, 7, 11, and 15, respectively,
 of the (already coded) macroblock immediately to the left.
 Similarly, the subblocks above the top-edge subblocks 0, 1, 2,
 and 3 are the bottom-edge subblocks 12, 13, 14, and 15 of the
 already-coded macroblock immediately above us.
</p>
</li>
<li>
<p>
For macroblocks on the top row or left edge of the image, some of
 the predictors will be non-existent.  Such predictors are taken
 to have had the value B_DC_PRED, which, perhaps conveniently,
 takes the value 0 in the enumeration above.  A simple management
 scheme for these contexts might maintain a row of above
 predictors and four left predictors.  Before decoding the frame,
 the entire row is initialized to B_DC_PRED; before decoding each
 row of macroblocks, the four left predictors are also set to
 B_DC_PRED.  After decoding a macroblock, the bottom four subblock
 modes are copied into the row predictor (at the current position,
 which then advances to be above the next macroblock), and the
 right four subblock modes are copied into the left predictor.
</p>
</li>
<li>
<p>
Many macroblocks will of course be coded using a 16x16 luma
 prediction mode.  For the purpose of predicting ensuing subblock
 modes (only), such macroblocks derive a subblock mode, constant
 throughout the macroblock, from the 16x16 luma mode as follows:
 DC_PRED uses B_DC_PRED, V_PRED uses B_VE_PRED, H_PRED uses
 B_HE_PRED, and TM_PRED uses B_TM_PRED.
</p>
</li>
<li>
<p>
Although we discuss interframe modes in Section 16, we remark
 here that, while interframes do use all the intra-coding modes
 described here and below, the subblock modes in an interframe are
 coded using a single constant probability array that does not
 depend on any context.
</p>
</li>
</ol></div>
<div class="paragraph"><p>The dependence of subblock mode probability on the nearby subblock
mode context is most easily handled using a three-dimensional
constant array:</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>The outer two dimensions of this array are indexed by the already-
coded subblock modes above and to the left of the current block,
respectively.  The inner dimension is a typical tree probability list
whose indices correspond to the even indices of the bmode_tree above.
The mode for the j^(th) luma subblock is then</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>Where the 4x4 Y subblock index j varies from 0 to 15 in raster order,
and A and L are the modes used above and to the left of the j^(th)
subblock.</p></div>
<div class="paragraph"><p>The contents of the kf_bmode_prob array are given at the end of this
section.</p></div>
<div class="paragraph"><p>11.4.  Chroma Modes</p></div>
<div class="paragraph"><p>After the Y mode (and optional subblock mode) specification comes the
chroma mode.  The chroma modes are a subset of the Y modes and are
coded using the uv_mode_tree, as described in Section 8 and repeated
here for convenience:</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>As for the Y modes (in a key frame), the chroma modes are coded using
a fixed, contextless probability table:</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>This completes the description of macroblock prediction coding for
key frames.  As will be discussed in Section 16, the coding of intra
modes within interframes is similar, but not identical, to that
described here (and in the reference code) for prediction modes and,
indeed, for all tree-coded data in VP8.</p></div>
<div class="paragraph"><p>11.5.  Subblock Mode Probability Table</p></div>
<div class="paragraph"><p>Finally, here is the fixed probability table used to decode subblock
modes in key frames.</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="olist arabic"><ol class="arabic">
<li>
<p>
Intraframe Prediction
</p>
</li>
</ol></div>
<div class="paragraph"><p>Intraframe prediction uses already-coded macroblocks within the
current frame to approximate the contents of the current macroblock.
It applies to intra-coded macroblocks in an interframe and to all
macroblocks in a key frame.</p></div>
<div class="paragraph"><p>Relative to the current macroblock "M", the already-coded macroblocks
include all macroblocks above M together with the macroblocks on the
same row as, and to the left of, M, though at most four of these
macroblocks are actually used: the block "A" directly above M, the
blocks immediately to the left and right of A, and the block
immediately to the left of M.</p></div>
<div class="paragraph"><p>Each of the prediction modes (i.e., means of extrapolation from
already-calculated values) uses fairly simple arithmetic on pixel
values whose positions, relative to the current position, are defined
by the mode.</p></div>
<div class="paragraph"><p>The chroma (U and V) and luma (Y) predictions are independent of each
other.</p></div>
<div class="paragraph"><p>The relative addressing of pixels applied to macroblocks on the upper
row or left column of the frame will sometimes cause pixels outside
the visible frame to be referenced.  Usually such out-of-bounds
pixels have an assumed value of 129 for pixels to the left of the
leftmost column of the visible frame and 127 for pixels above the top
row of the visible frame (including the special case of the pixel
above and to the left of the top-left pixel in the visible frame).
Exceptions to this (associated to certain modes) will be noted below.</p></div>
<div class="paragraph"><p>The already-coded macroblocks referenced by intra-prediction have
been "reconstructed", that is, have been predicted and residue-
adjusted (as described in Section 14), but have not been loop-
filtered.  While it does process the edges between individual
macroblocks and individual subblocks, loop filtering (described in
Section 15) is applied to the frame as a whole, after all of the
macroblocks have been reconstructed.</p></div>
<div class="paragraph"><p>12.1.  mb_skip_coeff</p></div>
<div class="paragraph"><p>The single bool flag is decoded using prob_skip_false if and only if
mb_no_skip_coeff is set to 1 (see Sections 9.10 and 9.11).  If
mb_no_skip_coeff is set to 0, then this value defaults to 0.</p></div>
<div class="paragraph"><p>12.2.  Chroma Prediction</p></div>
<div class="paragraph"><p>The chroma prediction is a little simpler than the luma prediction,
so we treat it first.  Each of the chroma modes treats U and V
identically; that is, the U and V prediction values are calculated in
parallel, using the same relative addressing and arithmetic in each
of the two planes.</p></div>
<div class="paragraph"><p>The modes extrapolate prediction values using the 8-pixel row "A"
lying immediately above the block (that is, the bottom chroma row of
the macroblock immediately above the current macroblock) and the
8-pixel column "L" immediately to the left of the block (that is, the
rightmost chroma column of the macroblock immediately to the left of
the current macroblock).</p></div>
<div class="paragraph"><p>Vertical prediction (chroma mode V_PRED) simply fills each 8-pixel
row of the 8x8 chroma block with a copy of the "above" row (A).  If
the current macroblock lies on the top row of the frame, all 8 of the
pixel values in A are assigned the value 127.</p></div>
<div class="paragraph"><p>Similarly, horizontal prediction (H_PRED) fills each 8-pixel column
of the 8x8 chroma block with a copy of the "left" column (L).  If the
current macroblock is in the left column of the frame, all 8 pixel
values in L are assigned the value 129.</p></div>
<div class="paragraph"><p>DC prediction (DC_PRED) fills the 8x8 chroma block with a single
value.  In the generic case of a macroblock lying below the top row
and right of the leftmost column of the frame, this value is the
average of the 16 (genuinely visible) pixels in the (union of the)
above row A and left column L.</p></div>
<div class="paragraph"><p>Otherwise, if the current macroblock lies on the top row of the
frame, the average of the 8 pixels in L is used; if it lies in the
left column of the frame, the average of the 8 pixels in A is used.</p></div>
<div class="paragraph"><p>Note that the averages used in these exceptional cases are not the
same as those that would be arrived at by using the out-of-bounds A
and L values defined for V_PRED and H_PRED.  In the case of the
leftmost macroblock on the top row of the frame, the 8x8 block is
simply filled with the constant value 128.</p></div>
<div class="paragraph"><p>For DC_PRED, apart from the exceptional case of the top-left
macroblock, we are averaging either 16 or 8 pixel values to get a
single prediction value that fills the 8x8 block.  The rounding is
done as follows:</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>Because the summands are all valid pixels, no "clamp" is necessary in
the calculation of DCvalue.</p></div>
<div class="paragraph"><p>The remaining "True Motion" (TM_PRED) chroma mode gets its name from
an older technique of video compression used by On2 Technologies, to
which it bears some relation.  In addition to the row "A" and column
"L", TM_PRED uses the pixel "P" above and to the left of the chroma
block.</p></div>
<div class="paragraph"><p>The following figure gives an example of how TM_PRED works:</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>Where P, As, and Ls represent reconstructed pixel values from
previously coded blocks, and X00 through X77 represent predicted
values for the current block.  TM_PRED uses the following equation to
calculate X_ij:</p></div>
<div class="paragraph"><p>X_ij = L_i + A_j - P (i, j=0, 1, 2, 3)</p></div>
<div class="paragraph"><p>The exact algorithm is as follows:</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>Note that the process could equivalently be described as propagating
the vertical differences between pixels in L (starting from P), using
the pixels from A to start each column.</p></div>
<div class="paragraph"><p>An implementation of chroma intra-prediction may be found in the
reference decoder file predict.c (Section 20.14).</p></div>
<div class="paragraph"><p>Unlike DC_PRED, for macroblocks on the top row or left edge, TM_PRED
does use the out-of-bounds values of 127 and 129 (respectively)
defined for V_PRED and H_PRED.</p></div>
<div class="paragraph"><p>12.3.  Luma Prediction</p></div>
<div class="paragraph"><p>The prediction processes for the first four 16x16 luma modes
(DC_PRED, V_PRED, H_PRED, and TM_PRED) are essentially identical to
the corresponding chroma prediction processes described above, the
only difference being that we are predicting a single 16x16 luma
block instead of two 8x8 chroma blocks.</p></div>
<div class="paragraph"><p>Thus, the row "A" and column "L" here contain 16 pixels, the DC
prediction is calculated using 16 or 32 pixels (and shf is 4 or 5),
and we of course fill the entire prediction buffer, that is, 16 rows
(or columns) containing 16 pixels each.  The reference implementation
of 16x16 luma prediction is also in predict.c.</p></div>
<div class="paragraph"><p>In the remaining luma mode (B_PRED), each 4x4 Y subblock is
independently predicted using one of ten modes (listed, along with
their encodings, in Section 11).</p></div>
<div class="paragraph"><p>Also, unlike the full-macroblock modes already described, some of the
subblock modes use prediction pixels above and to the right of the
current subblock.  In detail, each 4x4 subblock "B" is predicted
using (at most) the 4-pixel column "L" immediately to the left of B
and the 8-pixel row "A" immediately above B, consisting of the 4
pixels above B followed by the 4 adjacent pixels above and to the
right of B, together with the single pixel "P" immediately to the
left of A (and immediately above L).</p></div>
<div class="paragraph"><p>For the purpose of subblock intra-prediction, the pixels immediately
to the left and right of a pixel in a subblock are the same as the
pixels immediately to the left and right of the corresponding pixel
in the frame buffer "F".  Vertical offsets behave similarly: The
above row A lies immediately above B in F, and the adjacent pixels in
the left column L are separated by a single row in F.</p></div>
<div class="paragraph"><p>Because entire macroblocks (as opposed to their constituent
subblocks) are reconstructed in raster-scan order, for subblocks
lying along the right edge (and not along the top row) of the current
macroblock, the four "extra" prediction pixels in A above and to the
right of B have not yet actually been constructed.</p></div>
<div class="paragraph"><p>Subblocks 7, 11, and 15 are affected.  All three of these subblocks
use the same extra pixels as does subblock 3 (at the upper right
corner of the macroblock), namely the 4 pixels immediately above and
to the right of subblock 3.  Writing (R,C) for a frame buffer
position offset from the upper left corner of the current macroblock
by R rows and C columns, the extra pixels for all the right-edge
subblocks (3, 7, 11, and 15) are at positions (-1,16), (-1,17),
(-1,18), and (-1,19).  For the rightmost macroblock in each
macroblock row except the top row, the extra pixels shall use the
same value as the pixel at position (-1,15), which is the rightmost
visible pixel on the line immediately above the macroblock row.  For
the top macroblock row, all the extra pixels assume a value of 127.</p></div>
<div class="paragraph"><p>The details of the prediction modes are most easily described in
code.</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>The reference decoder implementation of subblock intra-prediction may
be found in predict.c (Section 20.14).</p></div>
<div class="olist arabic"><ol class="arabic">
<li>
<p>
DCT Coefficient Decoding
</p>
</li>
</ol></div>
<div class="paragraph"><p>The second data partition consists of an encoding of the quantized
DCT (and WHT) coefficients of the residue signal.  As discussed in
the format overview (Section 2), for each macroblock, the residue is
added to the (intra- or inter-generated) prediction buffer to produce
the final (except for loop filtering) reconstructed macroblock.</p></div>
<div class="paragraph"><p>VP8 works exclusively with 4x4 DCTs and WHTs, applied to the 24 (or
25 with the Y2 subblock) 4x4 subblocks of a macroblock.  The ordering
of macroblocks within any of the "residue" partitions in general
follows the same raster scan as used in the first "prediction"
partition.</p></div>
<div class="paragraph"><p>For all intra- and inter-prediction modes apart from B_PRED (intra:
whose Y subblocks are independently predicted) and SPLITMV (inter),
each macroblock&#8217;s residue record begins with the Y2 component of the
residue, coded using a WHT.  B_PRED and SPLITMV coded macroblocks
omit this WHT and specify the 0th DCT coefficient in each of the 16 Y
subblocks.</p></div>
<div class="paragraph"><p>After the optional Y2 block, the residue record continues with 16 DCTs for the Y subblocks, followed by 4 DCTs for the U subblocks, ending with 4 DCTs for the V subblocks.  The subblocks occur in the usual order.</p></div>
<div class="paragraph"><p>The DCTs and WHT are tree-coded using a 12-element alphabet whose members we call "tokens".  Except for the end-of-block token (which sets the remaining subblock coefficients to zero and is followed by the next block), each token (sometimes augmented with data immediately following the token) specifies the value of the single coefficient at the current (implicit) position and is followed by a token applying to the next (implicit) position.</p></div>
<div class="paragraph"><p>For all the Y and chroma subblocks, the ordering of the coefficients follows a so-called zig-zag order.  DCTs begin at coefficient 1 if Y2 is present, and begin at coefficient 0 if Y2 is absent.  The WHT for a Y2 subblock always begins at coefficient 0.</p></div>
<div class="paragraph"><p>13.1.  Macroblock without Non-Zero Coefficient Values</p></div>
<div class="paragraph"><p>If the flag within macroblock (MB) MODE_INFO indicates that a macroblock does not have any non-zero coefficients, the decoding process of DCT coefficients is skipped for the macroblock.</p></div>
<div class="paragraph"><p>13.2.  Coding of Individual Coefficient Values</p></div>
<div class="paragraph"><p>The coding of coefficient tokens is the same for the DCT and WHT, and for the remainder of this section "DCT" should be taken to mean either DCT or WHT.</p></div>
<div class="paragraph"><p>All tokens (except end-of-block) specify either a single unsigned
value or a range of unsigned values (immediately) followed by a
simple probabilistic encoding of the offset of the value from the
base of that range.</p></div>
<div class="paragraph"><p>Non-zero values (of either type) are then followed by a flag
indicating the sign of the coded value (negative if 1, positive
if 0).</p></div>
<div class="paragraph"><p>Below are the tokens and decoding tree.</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>In general, all DCT coefficients are decoded using the same tree.
However, if the preceding coefficient is a DCT_0, decoding will skip
the first branch, since it is not possible for dct_eob to follow a
DCT_0.</p></div>
<div class="paragraph"><p>The tokens dct_cat1 &#8230; dct_cat6 specify ranges of unsigned values,
the value within the range being formed by adding an unsigned offset
(whose width is 1, 2, 3, 4, 5, or 11 bits, respectively) to the base
of the range, using the following algorithm and fixed probability
tables.</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>If v&#8201;&#8212;&#8201;the unsigned value decoded using the coefficient tree,
possibly augmented by the process above&#8201;&#8212;&#8201;is non-zero, its sign is
set by simply reading a flag:</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>13.3.  Token Probabilities</p></div>
<div class="paragraph"><p>The probability specification for the token tree (unlike that for the
"extra bits" described above) is rather involved.  It uses three
pieces of context to index a large probability table, the contents of
which may be incrementally modified in the frame header.  The full
(non-constant) probability table is laid out as follows.</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>Working from the outside in, the outermost dimension is indexed by
the type of plane being decoded:</p></div>
<div class="paragraph"><p>o  0 - Y beginning at coefficient 1 (i.e., Y after Y2)</p></div>
<div class="paragraph"><p>o  1 - Y2</p></div>
<div class="paragraph"><p>o  2 - U or V</p></div>
<div class="paragraph"><p>o  3 - Y beginning at coefficient 0 (i.e., Y in the absence of Y2).</p></div>
<div class="paragraph"><p>The next dimension is selected by the position of the coefficient
being decoded.  That position, c, steps by ones up to 15, starting
from zero for block types 1, 2, or 3 and starting from one for block
type 0.  The second array index is then</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>Where:</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>int block[16] = { 0 }; /* current 4x4 block coeffs <strong>/
int firstCoeff = 0;
int plane;
int ctx2;
int ctx3 = 0; /</strong> the 3rd context referred to in above description <strong>/
Prob *probTable;
int token;
int sign;
int absValue;
int extraBits;
bool prevCoeffWasZero = false;
bool currentBlockHasCoeffs = false;
/</strong> base coeff abs values per each category, elem #0 is
DCT_VAL_CATEGORY1, * #1 is DCT_VAL_CATEGORY2, etc. */
int categoryBase[6] = { 5, 7, 11, 19, 35, 67 };</p></div>
<div class="paragraph"><p>/* Determine plane to use */
if ( <strong>current_block_is_Y2_block</strong> ) plane = 0;
else if ( <strong>current_block_is_chroma</strong> )plane = 2;
else if ( <strong>current_macroblock_has_Y2</strong> ) plane = 1;
else  plane = 3;</p></div>
<div class="paragraph"><p>/* For luma blocks of a "Y2 macroblock" we skip coeff index #0 */
if ( plane == 1 )
 firstCoeff++;</p></div>
<div class="paragraph"><p>/* Determine whether neighbor 4x4 blocks have coefficients.
This is dependent on the plane we are currently decoding;
i.e., we check only coefficients from the same plane as the
current block. */
if ( <strong>left_neighbor_block_has_coefficients(plane)</strong> )
 ctx3<code>;
if ( <strong>above_neighbor_block_has_coefficients(plane)</strong> )
 ctx3</code>;</p></div>
<div class="paragraph"><p>for( i = firstCoeff; i &lt; 16; ++i )
{
 ctx2 = coeff_bands[i];
 probTable = coeff_probs[plane][ctx2][ctx3];</p></div>
<div class="literalblock">
<div class="content">
<pre><code>/* skip first code (dct_eob) if previous token was DCT_0 */
if ( prevCoeffWasZero )
 token = treed_read ( d, **coeff_tree_without_eob**,
probTable );
else
 token = treed_read ( d, coeff_tree, probTable );</code></pre>
</div></div>
<div class="literalblock">
<div class="content">
<pre><code>if ( token == dct_eob )
 break;</code></pre>
</div></div>
<div class="literalblock">
<div class="content">
<pre><code> if ( token != DCT_0 )
 {
  currentBlockHasCoeffs = true;
  if ( **token_has_extra_bits(token)** )
  {
extraBits = DCTextra( token );
absValue =
 categoryBase[**token_to_cat_index(token)**] +
 extraBits;
  }
  else
  {
absValue = **token_to_abs_value(token)**;
  }</code></pre>
</div></div>
<div class="literalblock">
<div class="content">
<pre><code> sign = read_bool(d, 128);
 block[i] = sign ? -absValue : absValue;
}
else
{
 absValue = 0;
}</code></pre>
</div></div>
<div class="literalblock">
<div class="content">
<pre><code> /* Set contexts and stuff for next coeff */
 if ( absValue == 0 )ctx3 = 0;
 else if ( absValue == 1 )ctx3 = 1;
 elsectx3 = 2;
 prevCoeffWasZero = true;
}</code></pre>
</div></div>
<div class="paragraph"><p>/* Store current block status to decoder internals */
<strong>block_has_coefficients[currentMb][currentBlock]</strong> =
  currentBlockHasCoeffs;</p></div>
<div class="listingblock">
<div class="content">
<pre><code>While we have in fact completely described the coefficient decoding
procedure, the reader will probably find it helpful to consult the
reference implementation, which can be found in the file tokens.c
(Section 20.16).

13.4.  Token Probability Updates

As mentioned above, the token-decoding probabilities may change from
frame to frame.  After detection of a key frame, they are of course
set to their defaults as shown in Section 13.5; this must occur
before decoding the remainder of the header, as both key frames and
interframes may adjust these probabilities.

The layout and semantics of the coefficient probability update record
(Section I of the frame header) are straightforward.  For each
position in the coeff_probs array there occurs a fixed-probability
bool indicating whether or not the corresponding probability should
be updated.  If the bool is true, there follows a P(8) replacing that
probability.  Note that updates are cumulative; that is, a
probability updated on one frame is in effect for all ensuing frames
until the next key frame, or until the probability is explicitly
updated by another frame.

The algorithm to effect the foregoing is simple:

[source,c]</code></pre>
</div></div>
<div class="paragraph"><p>int i = 0;  do {
 int j = 0;  do {
  int k = 0;  do {
int t = 0;  do {</p></div>
<div class="literalblock">
<div class="content">
<pre><code>  if (read_bool(d, coeff_update_probs [i] [j] [k] [t]))
coeff_probs [i] [j] [k] [t] = read_literal(d, 8);</code></pre>
</div></div>
<div class="paragraph"><p>} while (<code>t &lt; num_dct_tokens - 1);
  } while (</code>k &lt; 3);
 } while (<code>j &lt; 8);
} while (</code>i &lt; 4);</p></div>
<div class="listingblock">
<div class="content">
<pre><code>The (constant) update probabilities are as follows:

[source,c]</code></pre>
</div></div>
<div class="paragraph"><p>const Prob coeff_update_probs [4] [8] [3] [num_dct_tokens-1] =
{
 {
  {
{ 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},
{ 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},
{ 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255}
  },
  {
{ 176, 246, 255, 255, 255, 255, 255, 255, 255, 255, 255},
{ 223, 241, 252, 255, 255, 255, 255, 255, 255, 255, 255},
{ 249, 253, 253, 255, 255, 255, 255, 255, 255, 255, 255}
  },
  {
{ 255, 244, 252, 255, 255, 255, 255, 255, 255, 255, 255},
{ 234, 254, 254, 255, 255, 255, 255, 255, 255, 255, 255},
{ 253, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255}
  },
  {
{ 255, 246, 254, 255, 255, 255, 255, 255, 255, 255, 255},
{ 239, 253, 254, 255, 255, 255, 255, 255, 255, 255, 255},
{ 254, 255, 254, 255, 255, 255, 255, 255, 255, 255, 255}
  },
  {
{ 255, 248, 254, 255, 255, 255, 255, 255, 255, 255, 255},
{ 251, 255, 254, 255, 255, 255, 255, 255, 255, 255, 255},
{ 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255}
  },
  {
{ 255, 253, 254, 255, 255, 255, 255, 255, 255, 255, 255},
{ 251, 254, 254, 255, 255, 255, 255, 255, 255, 255, 255},
{ 254, 255, 254, 255, 255, 255, 255, 255, 255, 255, 255}
  },
  {
{ 255, 254, 253, 255, 254, 255, 255, 255, 255, 255, 255},
{ 250, 255, 254, 255, 254, 255, 255, 255, 255, 255, 255},
{ 254, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255}
  },
  {
{ 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},
{ 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},
{ 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255}
  }
 },</p></div>
<div class="literalblock">
<div class="content">
<pre><code> {
  {
{ 217, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},
{ 225, 252, 241, 253, 255, 255, 254, 255, 255, 255, 255},
{ 234, 250, 241, 250, 253, 255, 253, 254, 255, 255, 255}
  },
  {
{ 255, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255},
{ 223, 254, 254, 255, 255, 255, 255, 255, 255, 255, 255},
{ 238, 253, 254, 254, 255, 255, 255, 255, 255, 255, 255}
  },
  {
{ 255, 248, 254, 255, 255, 255, 255, 255, 255, 255, 255},
{ 249, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255},
{ 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255}
  },
  {
{ 255, 253, 255, 255, 255, 255, 255, 255, 255, 255, 255},
{ 247, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255},
{ 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255}
  },
  {
{ 255, 253, 254, 255, 255, 255, 255, 255, 255, 255, 255},
{ 252, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},
{ 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255}
  },
  {
{ 255, 254, 254, 255, 255, 255, 255, 255, 255, 255, 255},
{ 253, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},
{ 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255}
  },
  {
{ 255, 254, 253, 255, 255, 255, 255, 255, 255, 255, 255},
{ 250, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},
{ 254, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255}
  },
  {
{ 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},
{ 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},
{ 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255}
  }
 },
 {
  {
{ 186, 251, 250, 255, 255, 255, 255, 255, 255, 255, 255},
{ 234, 251, 244, 254, 255, 255, 255, 255, 255, 255, 255},
{ 251, 251, 243, 253, 254, 255, 254, 255, 255, 255, 255}
  },</code></pre>
</div></div>
<div class="literalblock">
<div class="content">
<pre><code>  {
{ 255, 253, 254, 255, 255, 255, 255, 255, 255, 255, 255},
{ 236, 253, 254, 255, 255, 255, 255, 255, 255, 255, 255},
{ 251, 253, 253, 254, 254, 255, 255, 255, 255, 255, 255}
  },
  {
{ 255, 254, 254, 255, 255, 255, 255, 255, 255, 255, 255},
{ 254, 254, 254, 255, 255, 255, 255, 255, 255, 255, 255},
{ 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255}
  },
  {
{ 255, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255},
{ 254, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255},
{ 254, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255}
  },
  {
{ 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},
{ 254, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},
{ 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255}
  },
  {
{ 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},
{ 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},
{ 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255}
  },
  {
{ 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},
{ 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},
{ 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255}
  },
  {
{ 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},
{ 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},
{ 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255}
  }
 },
 {
  {
{ 248, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},
{ 250, 254, 252, 254, 255, 255, 255, 255, 255, 255, 255},
{ 248, 254, 249, 253, 255, 255, 255, 255, 255, 255, 255}
  },
  {
{ 255, 253, 253, 255, 255, 255, 255, 255, 255, 255, 255},
{ 246, 253, 253, 255, 255, 255, 255, 255, 255, 255, 255},
{ 252, 254, 251, 254, 254, 255, 255, 255, 255, 255, 255}
  },</code></pre>
</div></div>
<div class="literalblock">
<div class="content">
<pre><code>  {
{ 255, 254, 252, 255, 255, 255, 255, 255, 255, 255, 255},
{ 248, 254, 253, 255, 255, 255, 255, 255, 255, 255, 255},
{ 253, 255, 254, 254, 255, 255, 255, 255, 255, 255, 255}
  },
  {
{ 255, 251, 254, 255, 255, 255, 255, 255, 255, 255, 255},
{ 245, 251, 254, 255, 255, 255, 255, 255, 255, 255, 255},
{ 253, 253, 254, 255, 255, 255, 255, 255, 255, 255, 255}
  },
  {
{ 255, 251, 253, 255, 255, 255, 255, 255, 255, 255, 255},
{ 252, 253, 254, 255, 255, 255, 255, 255, 255, 255, 255},
{ 255, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255}
  },
  {
{ 255, 252, 255, 255, 255, 255, 255, 255, 255, 255, 255},
{ 249, 255, 254, 255, 255, 255, 255, 255, 255, 255, 255},
{ 255, 255, 254, 255, 255, 255, 255, 255, 255, 255, 255}
  },
  {
{ 255, 255, 253, 255, 255, 255, 255, 255, 255, 255, 255},
{ 250, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},
{ 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255}
  },
  {
{ 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},
{ 254, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255},
{ 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255}
  }
 }
};</code></pre>
</div></div>
<div class="listingblock">
<div class="content">
<pre><code>13.5.  Default Token Probability Table

The default token probabilities are as follows.

[source,c]</code></pre>
</div></div>
<div class="paragraph"><p>const Prob default_coeff_probs [4] [8] [3] [num_dct_tokens - 1] =
{
 {
  {
{ 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128},
{ 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128},
{ 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128}
  },
  {
{ 253, 136, 254, 255, 228, 219, 128, 128, 128, 128, 128},
{ 189, 129, 242, 255, 227, 213, 255, 219, 128, 128, 128},
{ 106, 126, 227, 252, 214, 209, 255, 255, 128, 128, 128}
  },
  {
{1,  98, 248, 255, 236, 226, 255, 255, 128, 128, 128},
{ 181, 133, 238, 254, 221, 234, 255, 154, 128, 128, 128},
{  78, 134, 202, 247, 198, 180, 255, 219, 128, 128, 128}
  },
  {
{1, 185, 249, 255, 243, 255, 128, 128, 128, 128, 128},
{ 184, 150, 247, 255, 236, 224, 128, 128, 128, 128, 128},
{  77, 110, 216, 255, 236, 230, 128, 128, 128, 128, 128}
  },
  {
{1, 101, 251, 255, 241, 255, 128, 128, 128, 128, 128},
{ 170, 139, 241, 252, 236, 209, 255, 255, 128, 128, 128},
{  37, 116, 196, 243, 228, 255, 255, 255, 128, 128, 128}
  },
  {
{1, 204, 254, 255, 245, 255, 128, 128, 128, 128, 128},
{ 207, 160, 250, 255, 238, 128, 128, 128, 128, 128, 128},
{ 102, 103, 231, 255, 211, 171, 128, 128, 128, 128, 128}
  },
  {
{1, 152, 252, 255, 240, 255, 128, 128, 128, 128, 128},
{ 177, 135, 243, 255, 234, 225, 128, 128, 128, 128, 128},
{  80, 129, 211, 255, 194, 224, 128, 128, 128, 128, 128}
  },</p></div>
<div class="literalblock">
<div class="content">
<pre><code>  {
{1,1, 255, 128, 128, 128, 128, 128, 128, 128, 128},
{ 246,1, 255, 128, 128, 128, 128, 128, 128, 128, 128},
{ 255, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128}
  }
 },
 {
  {
{ 198,  35, 237, 223, 193, 187, 162, 160, 145, 155,  62},
{ 131,  45, 198, 221, 172, 176, 220, 157, 252, 221,1},
{  68,  47, 146, 208, 149, 167, 221, 162, 255, 223, 128}
  },
  {
{1, 149, 241, 255, 221, 224, 255, 255, 128, 128, 128},
{ 184, 141, 234, 253, 222, 220, 255, 199, 128, 128, 128},
{  81,  99, 181, 242, 176, 190, 249, 202, 255, 255, 128}
  },
  {
{1, 129, 232, 253, 214, 197, 242, 196, 255, 255, 128},
{  99, 121, 210, 250, 201, 198, 255, 202, 128, 128, 128},
{  23,  91, 163, 242, 170, 187, 247, 210, 255, 255, 128}
  },
  {
{1, 200, 246, 255, 234, 255, 128, 128, 128, 128, 128},
{ 109, 178, 241, 255, 231, 245, 255, 255, 128, 128, 128},
{  44, 130, 201, 253, 205, 192, 255, 255, 128, 128, 128}
  },
  {
{1, 132, 239, 251, 219, 209, 255, 165, 128, 128, 128},
{  94, 136, 225, 251, 218, 190, 255, 255, 128, 128, 128},
{  22, 100, 174, 245, 186, 161, 255, 199, 128, 128, 128}
  },
  {
{1, 182, 249, 255, 232, 235, 128, 128, 128, 128, 128},
{ 124, 143, 241, 255, 227, 234, 128, 128, 128, 128, 128},
{  35,  77, 181, 251, 193, 211, 255, 205, 128, 128, 128}
  },
  {
{1, 157, 247, 255, 236, 231, 255, 255, 128, 128, 128},
{ 121, 141, 235, 255, 225, 227, 255, 255, 128, 128, 128},
{  45,  99, 188, 251, 195, 217, 255, 224, 128, 128, 128}
  },
  {
{1,1, 251, 255, 213, 255, 128, 128, 128, 128, 128},
{ 203,1, 248, 255, 255, 128, 128, 128, 128, 128, 128},
{ 137,1, 177, 255, 224, 255, 128, 128, 128, 128, 128}
  }
 },</code></pre>
</div></div>
<div class="literalblock">
<div class="content">
<pre><code> {
  {
{ 253,9, 248, 251, 207, 208, 255, 192, 128, 128, 128},
{ 175,  13, 224, 243, 193, 185, 249, 198, 255, 255, 128},
{  73,  17, 171, 221, 161, 179, 236, 167, 255, 234, 128}
  },
  {
{1,  95, 247, 253, 212, 183, 255, 255, 128, 128, 128},
{ 239,  90, 244, 250, 211, 209, 255, 255, 128, 128, 128},
{ 155,  77, 195, 248, 188, 195, 255, 255, 128, 128, 128}
  },
  {
{1,  24, 239, 251, 218, 219, 255, 205, 128, 128, 128},
{ 201,  51, 219, 255, 196, 186, 128, 128, 128, 128, 128},
{  69,  46, 190, 239, 201, 218, 255, 228, 128, 128, 128}
  },
  {
{1, 191, 251, 255, 255, 128, 128, 128, 128, 128, 128},
{ 223, 165, 249, 255, 213, 255, 128, 128, 128, 128, 128},
{ 141, 124, 248, 255, 255, 128, 128, 128, 128, 128, 128}
  },
  {
{1,  16, 248, 255, 255, 128, 128, 128, 128, 128, 128},
{ 190,  36, 230, 255, 236, 255, 128, 128, 128, 128, 128},
{ 149,1, 255, 128, 128, 128, 128, 128, 128, 128, 128}
  },
  {
{1, 226, 255, 128, 128, 128, 128, 128, 128, 128, 128},
{ 247, 192, 255, 128, 128, 128, 128, 128, 128, 128, 128},
{ 240, 128, 255, 128, 128, 128, 128, 128, 128, 128, 128}
  },
  {
{1, 134, 252, 255, 255, 128, 128, 128, 128, 128, 128},
{ 213,  62, 250, 255, 255, 128, 128, 128, 128, 128, 128},
{  55,  93, 255, 128, 128, 128, 128, 128, 128, 128, 128}
  },
  {
{ 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128},
{ 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128},
{ 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128}
  }
 },
 {
  {
{ 202,  24, 213, 235, 186, 191, 220, 160, 240, 175, 255},
{ 126,  38, 182, 232, 169, 184, 228, 174, 255, 187, 128},
{  61,  46, 138, 219, 151, 178, 240, 170, 255, 216, 128}
  },</code></pre>
</div></div>
<div class="literalblock">
<div class="content">
<pre><code>  {
{1, 112, 230, 250, 199, 191, 247, 159, 255, 255, 128},
{ 166, 109, 228, 252, 211, 215, 255, 174, 128, 128, 128},
{  39,  77, 162, 232, 172, 180, 245, 178, 255, 255, 128}
  },
  {
{1,  52, 220, 246, 198, 199, 249, 220, 255, 255, 128},
{ 124,  74, 191, 243, 183, 193, 250, 221, 255, 255, 128},
{  24,  71, 130, 219, 154, 170, 243, 182, 255, 255, 128}
  },
  {
{1, 182, 225, 249, 219, 240, 255, 224, 128, 128, 128},
{ 149, 150, 226, 252, 216, 205, 255, 171, 128, 128, 128},
{  28, 108, 170, 242, 183, 194, 254, 223, 255, 255, 128}
  },
  {
{1,  81, 230, 252, 204, 203, 255, 192, 128, 128, 128},
{ 123, 102, 209, 247, 188, 196, 255, 233, 128, 128, 128},
{  20,  95, 153, 243, 164, 173, 255, 203, 128, 128, 128}
  },
  {
{1, 222, 248, 255, 216, 213, 128, 128, 128, 128, 128},
{ 168, 175, 246, 252, 235, 205, 255, 255, 128, 128, 128},
{  47, 116, 215, 255, 211, 212, 255, 255, 128, 128, 128}
  },
  {
{1, 121, 236, 253, 212, 214, 255, 255, 128, 128, 128},
{ 141,  84, 213, 252, 201, 202, 255, 219, 128, 128, 128},
{  42,  80, 160, 240, 162, 185, 255, 205, 128, 128, 128}
  },
  {
{1,1, 255, 128, 128, 128, 128, 128, 128, 128, 128},
{ 244,1, 255, 128, 128, 128, 128, 128, 128, 128, 128},
{ 238,1, 255, 128, 128, 128, 128, 128, 128, 128, 128}
  }
 }
};</code></pre>
</div></div>
<div class="listingblock">
<div class="content">
<pre><code>14.  DCT and WHT Inversion and Macroblock Reconstruction

14.1.  Dequantization

After decoding the DCTs/WHTs as described above, each (quantized)
coefficient in each subblock is multiplied by one of six
dequantization factors, the choice of factor depending on the plane
(Y2, Y, or chroma) and position (DC = coefficient zero, AC = any

other coefficient).  If the current macroblock has overridden the
quantizer level (as described in Section 10), then the six factors
are looked up from two dequantization tables with appropriate scaling
and clamping using the single index supplied by the override.
Otherwise, the frame-level dequantization factors (as described in
Section 9.6) are used.  In either case, the multiplies are computed
and stored using 16-bit signed integers.

The two dequantization tables, which may also be found in the
reference decoder file dequant_data.h (Section 20.3), are as follows.

[source,c]</code></pre>
</div></div>
<div class="paragraph"><p>static const int dc_qlookup[QINDEX_RANGE] =
{
 4,5,6,7,8,9,  10,  10,11,  12,  13,  14,  15,
16,  17,  17,  18,  19,  20,  20,  21,21,  22,  22,  23,  23,
24,  25,  25,  26,  27,  28,  29,  30,31,  32,  33,  34,  35,
36,  37,  37,  38,  39,  40,  41,  42,43,  44,  45,  46,  46,
47,  48,  49,  50,  51,  52,  53,  54,55,  56,  57,  58,  59,
60,  61,  62,  63,  64,  65,  66,  67,68,  69,  70,  71,  72,
73,  74,  75,  76,  76,  77,  78,  79,80,  81,  82,  83,  84,
85,  86,  87,  88,  89,  91,  93,  95,96,  98, 100, 101, 102,
104, 106, 108, 110, 112, 114, 116, 118, 122, 124, 126, 128, 130,
132, 134, 136, 138, 140, 143, 145, 148, 151, 154, 157,
};</p></div>
<div class="paragraph"><p>static const int ac_qlookup[QINDEX_RANGE] =
{
 4,5,6,7,8,9,  10,  11,  12,  13,  14,  15,  16,
17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,
30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,
43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
56,  57,  58,  60,  62,  64,  66,  68,  70,  72,  74,  76,  78,
80,  82,  84,  86,  88,  90,  92,  94,  96,  98, 100, 102, 104,
  106, 108, 110, 112, 114, 116, 119, 122, 125, 128, 131, 134, 137,
  140, 143, 146, 149, 152, 155, 158, 161, 164, 167, 170, 173, 177,
  181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229,
  234, 239, 245, 249, 254, 259, 264, 269, 274, 279, 284,
};</p></div>
<div class="listingblock">
<div class="content">
<pre><code>Lookup values from the above two tables are directly used in the DC
and AC coefficients in Y1, respectively.  For Y2 and chroma, values
from the above tables undergo either scaling or clamping before the
multiplies.  Details regarding these scaling and clamping processes
can be found in related lookup functions in dixie.c (Section 20.4).

14.2.  Inverse Transforms

If the Y2 residue block exists (i.e., the macroblock luma mode is not
SPLITMV or B_PRED), it is inverted first (using the inverse WHT) and
the element of the result at row i, column j is used as the 0th
coefficient of the Y subblock at position (i, j), that is, the Y
subblock whose index is (i * 4) + j.  As discussed in Section 13, if
the luma mode is B_PRED or SPLITMV, the 0th Y coefficients are part
of the residue signal for the subblocks themselves.

In either case, the inverse transforms for the sixteen Y subblocks
and eight chroma subblocks are computed next.  All 24 of these
inversions are independent of each other; their results may (at least
conceptually) be stored in 24 separate 4x4 arrays.

As is done by the reference decoder, an implementation may wish to
represent the prediction and residue buffers as macroblock-sized
arrays (that is, a 16x16 Y buffer and two 8x8 chroma buffers).
Regarding the inverse DCT implementation given below, this requires a
simple adjustment to the address calculation for the resulting
residue pixels.

14.3.  Implementation of the WHT Inversion

As previously discussed (see Sections 2 and 13), for macroblocks
encoded using prediction modes other than B_PRED and SPLITMV, the DC
values derived from the DCT transform on the 16 Y blocks are
collected to construct a 25th block of a macroblock (16 Y, 4 U, 4 V
constitute the 24 blocks).  This 25th block is transformed using a
Walsh-Hadamard transform (WHT).

The inputs to the inverse WHT (that is, the dequantized
coefficients), the intermediate "horizontally detransformed" signal,
and the completely detransformed residue signal are all stored as
arrays of 16-bit signed integers.

Following the tradition of specifying bitstream format using the
decoding process, we specify the inverse WHT in the decoding process
using the following C-style source code:

[source,c]</code></pre>
</div></div>
<div class="paragraph"><p>void vp8_short_inv_walsh4x4_c(short *input, short *output)
{
  int i;
  int a1, b1, c1, d1;
  int a2, b2, c2, d2;
  short *ip = input;
  short *op = output;
  int temp1, temp2;</p></div>
<div class="literalblock">
<div class="content">
<pre><code> for(i=0;i&lt;4;i++)
 {
a1 = ip[0] + ip[12];
b1 = ip[4] + ip[8];
c1 = ip[4] - ip[8];
d1 = ip[0] - ip[12];</code></pre>
</div></div>
<div class="literalblock">
<div class="content">
<pre><code>op[0] = a1 + b1;
op[4] = c1 + d1;
op[8] = a1 - b1;
op[12]= d1 - c1;
ip++;
op++;
 }
 ip = output;
 op = output;
 for(i=0;i&lt;4;i++)
 {
a1 = ip[0] + ip[3];
b1 = ip[1] + ip[2];
c1 = ip[1] - ip[2];
d1 = ip[0] - ip[3];</code></pre>
</div></div>
<div class="literalblock">
<div class="content">
<pre><code>a2 = a1 + b1;
b2 = c1 + d1;
c2 = a1 - b1;
d2 = d1 - c1;</code></pre>
</div></div>
<div class="literalblock">
<div class="content">
<pre><code>op[0] = (a2+3)&gt;&gt;3;
op[1] = (b2+3)&gt;&gt;3;
op[2] = (c2+3)&gt;&gt;3;
op[3] = (d2+3)&gt;&gt;3;</code></pre>
</div></div>
<div class="literalblock">
<div class="content">
<pre><code> ip+=4;
 op+=4;
  }
}</code></pre>
</div></div>
<div class="listingblock">
<div class="content">
<pre><code>In the case that there is only one non-zero DC value in input, the
inverse transform can be simplified to the following:

[source,c]</code></pre>
</div></div>
<div class="paragraph"><p>void vp8_short_inv_walsh4x4_1_c(short *input, short *output)
{
  int i;
  int a1;
  short *op=output;</p></div>
<div class="literalblock">
<div class="content">
<pre><code>a1 = ((input[0] + 3)&gt;&gt;3);</code></pre>
</div></div>
<div class="literalblock">
<div class="content">
<pre><code>  for(i=0;i&lt;4;i++)
  {
 op[0] = a1;
 op[1] = a1;
 op[2] = a1;
 op[3] = a1;
 op+=4;
  }
}</code></pre>
</div></div>
<div class="listingblock">
<div class="content">
<pre><code>It should be noted that a conforming decoder should implement the
inverse transform using exactly the same rounding to achieve bit-wise
matching output to the output of the process specified by the above
C source code.

The reference decoder WHT inversion may be found in the file
idct_add.c (Section 20.8).

14.4.  Implementation of the DCT Inversion

All of the DCT inversions are computed in exactly the same way.  In
principle, VP8 uses a classical 2-D inverse discrete cosine
transform, implemented as two passes of 1-D inverse DCT.  The 1-D
inverse DCT was calculated using a similar algorithm to what was
described in [Loeffler].  However, the paper only provided the
8-point and 16-point version of the algorithms, which was adapted by
On2 to perform the 4-point 1-D DCT.

Accurate calculation of 1-D DCT of the above algorithm requires
infinite precision.  VP8 of course can use only a finite-precision
approximation.  Also, the inverse DCT used by VP8 takes care of
normalization of the standard unitary transform; that is, every
dequantized coefficient has roughly double the size of the
corresponding unitary coefficient.  However, at all but the highest
datarates, the discrepancy between transmitted and ideal coefficients
is due almost entirely to (lossy) compression and not to errors
induced by finite-precision arithmetic.

The inputs to the inverse DCT (that is, the dequantized
coefficients), the intermediate "horizontally detransformed" signal,
and the completely detransformed residue signal are all stored as
arrays of 16-bit signed integers.  The details of the computation are
as follows.

It should also be noted that this implementation makes use of the
16-bit fixed-point version of two multiplication constants:

sqrt(2) * cos (pi/8)

sqrt(2) * sin (pi/8)

Because the first constant is bigger than 1, to maintain the same
16-bit fixed-point precision as the second one, we make use of the
fact that

x * a = x + x*(a-1)

therefore

x * sqrt(2) * cos (pi/8) = x + x * (sqrt(2) * cos(pi/8)-1)

[source,c]</code></pre>
</div></div>
<div class="paragraph"><p>/* IDCT implementation */
static const int cospi8sqrt2minus1=20091;
static const int sinpi8sqrt2=35468;
void short_idct4x4llm_c(short *input, short *output, int pitch)
{
  int i;
  int a1, b1, c1, d1;</p></div>
<div class="literalblock">
<div class="content">
<pre><code>short *ip=input;
short *op=output;
int temp1, temp2;
int shortpitch = pitch&gt;&gt;1;</code></pre>
</div></div>
<div class="literalblock">
<div class="content">
<pre><code> for(i=0;i&lt;4;i++)
 {
a1 = ip[0]+ip[8];
b1 = ip[0]-ip[8];</code></pre>
</div></div>
<div class="literalblock">
<div class="content">
<pre><code>temp1 = (ip[4] * sinpi8sqrt2)&gt;&gt;16;
temp2 = ip[12]+((ip[12] * cospi8sqrt2minus1)&gt;&gt;16);
c1 = temp1 - temp2;</code></pre>
</div></div>
<div class="literalblock">
<div class="content">
<pre><code>temp1 = ip[4] + ((ip[4] * cospi8sqrt2minus1)&gt;&gt;16);
temp2 = (ip[12] * sinpi8sqrt2)&gt;&gt;16;
d1 = temp1 + temp2;</code></pre>
</div></div>
<div class="literalblock">
<div class="content">
<pre><code>op[shortpitch*0] = a1+d1;
op[shortpitch*3] = a1-d1;
op[shortpitch*1] = b1+c1;
op[shortpitch*2] = b1-c1;</code></pre>
</div></div>
<div class="literalblock">
<div class="content">
<pre><code>ip++;
op++;
 }
 ip = output;
 op = output;
 for(i=0;i&lt;4;i++)
 {
a1 = ip[0]+ip[2];
b1 = ip[0]-ip[2];</code></pre>
</div></div>
<div class="literalblock">
<div class="content">
<pre><code>temp1 = (ip[1] * sinpi8sqrt2)&gt;&gt;16;
temp2 = ip[3]+((ip[3] * cospi8sqrt2minus1)&gt;&gt;16);
c1 = temp1 - temp2;</code></pre>
</div></div>
<div class="literalblock">
<div class="content">
<pre><code>temp1 = ip[1] + ((ip[1] * cospi8sqrt2minus1)&gt;&gt;16);</code></pre>
</div></div>
<div class="literalblock">
<div class="content">
<pre><code>temp2 = (ip[3] * sinpi8sqrt2)&gt;&gt;16;
d1 = temp1 + temp2;</code></pre>
</div></div>
<div class="literalblock">
<div class="content">
<pre><code>op[0] = (a1+d1+4)&gt;&gt;3;
op[3] = (a1-d1+4)&gt;&gt;3;
op[1] = (b1+c1+4)&gt;&gt;3;
op[2] = (b1-c1+4)&gt;&gt;3;</code></pre>
</div></div>
<div class="literalblock">
<div class="content">
<pre><code> ip+=shortpitch;
 op+=shortpitch;
  }
}</code></pre>
</div></div>
<div class="listingblock">
<div class="content">
<pre><code>The reference decoder DCT inversion may be found in the file
idct_add.c (Section 20.8).

14.5.  Summation of Predictor and Residue

Finally, the prediction and residue signals are summed to form the
reconstructed macroblock, which, except for loop filtering (taken up
next), completes the decoding process.

The summing procedure is fairly straightforward, having only a couple
of details.  The prediction and residue buffers are both arrays of
16-bit signed integers.  Each individual (Y, U, and V pixel) result
is calculated first as a 32-bit sum of the prediction and residue,
and is then saturated to 8-bit unsigned range (using, say, the
clamp255 function defined above) before being stored as an 8-bit
unsigned pixel value.

VP8 also supports a mode where the encoding of a bitstream guarantees
all reconstructed pixel values between 0 and 255; compliant
bitstreams of such requirements have the clamp_type bit in the frame
header set to 1.  In such a case, the clamp255 function is no longer
required.

The summation process is the same, regardless of the (intra or inter)
mode of prediction in effect for the macroblock.  The reference
decoder implementation of reconstruction may be found in the file
idct_add.c.

15.  Loop Filter

Loop filtering is the last stage of frame reconstruction and the
next-to-last stage of the decoding process.  The loop filter is
applied to the entire frame after the summation of predictor and
residue signals, as described in Section 14.

The purpose of the loop filter is to eliminate (or at least reduce)
visually objectionable artifacts associated with the semi-
independence of the coding of macroblocks and their constituent
subblocks.

As was discussed in Section 5, the loop filter is "integral" to
decoding, in that the results of loop filtering are used in the
prediction of subsequent frames.  Consequently, a functional decoder
implementation must perform loop filtering exactly as described here.
This is distinct from any postprocessing that may be applied only to
the image immediately before display; such postprocessing is entirely
at the option of the implementor (and/or user) and has no effect on
decoding per se.

The baseline frame-level parameters controlling the loop filter are
defined in the frame header (Section 9.4) along with a mechanism for
adjustment based on a macroblock's prediction mode and/or reference
frame.  The first is a flag (filter_type) selecting the type of
filter (normal or simple); the other two are numbers
(loop_filter_level and sharpness_level) that adjust the strength or
sensitivity of the filter.  As described in Sections 9.3 and 10,
loop_filter_level may also be overridden on a per-macroblock basis
using segmentation.

Loop filtering is one of the more computationally intensive aspects
of VP8 decoding.  This is the reason for the existence of the
optional, less-demanding simple filter type.

Note carefully that loop filtering must be skipped entirely if
loop_filter_level at either the frame header level or macroblock
override level is 0.  In no case should the loop filter be run with a
value of 0; it should instead be skipped.

We begin by discussing the aspects of loop filtering that are
independent of the controlling parameters and type of filter chosen.

15.1.  Filter Geometry and Overall Procedure

The Y, U, and V planes are processed independently and identically.

The loop filter acts on the edges between adjacent macroblocks and on
the edges between adjacent subblocks of a macroblock.  All such edges
are horizontal or vertical.  For each pixel position on an edge, a
small number (two or three) of pixels adjacent to either side of the
position are examined and possibly modified.  The displacements of
these pixels are at a right angle to the edge orientation; that is,
for a horizontal edge, we treat the pixels immediately above and
below the edge position, and for a vertical edge, we treat the pixels
immediately to the left and right of the edge.

We call this collection of pixels associated to an edge position a
segment; the length of a segment is 2, 4, 6, or 8.  Excepting that
the normal filter uses slightly different algorithms for, and either
filter may apply different control parameters to, the edges between
macroblocks and those between subblocks, the treatment of edges is
quite uniform: All segments straddling an edge are treated
identically; there is no distinction between the treatment of
horizontal and vertical edges, whether between macroblocks or between
subblocks.

As a consequence, adjacent subblock edges within a macroblock may be
concatenated and processed in their entirety.  There is a single
8-pixel-long vertical edge horizontally centered in each of the U and
V blocks (the concatenation of upper and lower 4-pixel edges between
chroma subblocks), and three 16-pixel-long vertical edges at
horizontal positions 1/4, 1/2, and 3/4 the width of the luma
macroblock, each representing the concatenation of four 4-pixel
sub-edges between pairs of Y subblocks.

The macroblocks comprising the frame are processed in the usual
raster-scan order.  Each macroblock is "responsible for" the
inter-macroblock edges immediately above and to the left of it (but
not the edges below and to the right of it), as well as the edges
between its subblocks.

For each macroblock M, there are four filtering steps, which are,
(almost) in order:

1.  If M is not on the leftmost column of macroblocks, filter across
 the left (vertical) inter-macroblock edge of M.

2.  Filter across the vertical subblock edges within M.

3.  If M is not on the topmost row of macroblocks, filter across the
 top (horizontal) inter-macroblock edge of M.

4.  Filter across the horizontal subblock edges within M.

We write MY, MU, and MV for the planar constituents of M, that is,
the 16x16 luma block, 8x8 U block, and 8x8 V block comprising M.

In step 1, for each of the three blocks MY, MU, and MV, we filter
each of the (16 luma or 8 chroma) segments straddling the column
separating the block from the block immediately to the left of it,
using the inter-macroblock filter and controls associated to the
loop_filter_level and sharpness_level.

In step 4, we filter across the (three luma and one each for U and V)
vertical subblock edges described above, this time using the
inter-subblock filter and controls.

Steps 2 and 4 are skipped for macroblocks that satisfy both of the
following two conditions:

1.  Macroblock coding mode is neither B_PRED nor SPLITMV; and

2.  There is no DCT coefficient coded for the whole macroblock.

For these macroblocks, loop filtering for edges between subblocks
internal to a macroblock is effectively skipped.  This skip strategy
significantly reduces VP8 loop-filtering complexity.

Edges between macroblocks and those between subblocks are treated
with different control parameters (and, in the case of the normal
filter, with different algorithms).  Except for pixel addressing,
there is no distinction between the treatment of vertical and
horizontal edges.  Luma edges are always 16 pixels long, chroma edges
are always 8 pixels long, and the segments straddling an edge are
treated identically; this of course facilitates vector processing.

Because many pixels belong to segments straddling two or more edges,
and so will be filtered more than once, the order in which edges are
processed given above must be respected by any implementation.
Within a single edge, however, the segments straddling that edge are
disjoint, and the order in which these segments are processed is
immaterial.

Before taking up the filtering algorithms themselves, we should
emphasize a point already made: Even though the pixel segments
associated to a macroblock are antecedent to the macroblock (that is,
lie within the macroblock or in already-constructed macroblocks), a

macroblock must not be filtered immediately after its
"reconstruction" (described in Section 14).  Rather, the loop filter
applies after all the macroblocks have been "reconstructed" (i.e.,
had their predictor summed with their residue); correct decoding is
predicated on the fact that already-constructed portions of the
current frame referenced via intra-prediction (described in
Section 12) are not yet filtered.

15.2.  Simple Filter

Having described the overall procedure of, and pixels affected by,
the loop filter, we turn our attention to the treatment of individual
segments straddling edges.  We begin by describing the simple filter,
which, as the reader might guess, is somewhat simpler than the normal
filter.

Note that the simple filter only applies to luma edges.  Chroma edges
are left unfiltered.

Roughly speaking, the idea of loop filtering is, within limits, to
reduce the difference between pixels straddling an edge.  Differences
in excess of a threshold (associated to the loop_filter_level) are
assumed to be "natural" and are unmodified; differences below the
threshold are assumed to be artifacts of quantization and the
(partially) separate coding of blocks, and are reduced via the
procedures described below.  While the loop_filter_level is in
principle arbitrary, the levels chosen by a VP8 compressor tend to be
correlated to quantizer levels.

Most of the filtering arithmetic is done using 8-bit signed operands
(having a range of -128 to +127, inclusive), supplemented by 16-bit
temporaries holding results of multiplies.

Sums and other temporaries need to be "clamped" to a valid signed
8-bit range:

[source,c]</code></pre>
</div></div>
<div class="paragraph"><p>int8 c(int v)
{
 return (int8) (v &lt; -128 ? -128 : (v &lt; 128 ? v : 127));
}</p></div>
<div class="listingblock">
<div class="content">
<pre><code>Since pixel values themselves are unsigned 8-bit numbers, we need to
convert between signed and unsigned values:

[source,c]</code></pre>
</div></div>
<div class="paragraph"><p>/* Convert pixel value (0 &#8656; v &#8656; 255) to an 8-bit signed
number. */
int8 u2s(Pixel v) { return (int8) (v - 128);}</p></div>
<div class="paragraph"><p>/* Clamp, then convert signed number back to pixel value. */
Pixel s2u(int v) { return (Pixel) (c(v) + 128);}</p></div>
<div class="listingblock">
<div class="content">
<pre><code>Filtering is often predicated on absolute-value thresholds.  The
following function is the equivalent of the standard library function
abs, whose prototype is found in the standard header file stdlib.h.
For us, the argument v is always the difference between two pixels
and lies in the range -255 &lt;= v &lt;= +255.

[source,c]</code></pre>
</div></div>
<div class="paragraph"><p>int abs(int v) { return v &lt; 0?  -v : v;}</p></div>
<div class="listingblock">
<div class="content">
<pre><code>An actual implementation would of course use inline functions or
macros to accomplish these trivial procedures (which are used by both
the normal and simple loop filters).  An optimal implementation would
probably express them in machine language, perhaps using single
instruction, multiple data (SIMD) vector instructions.  On many SIMD
processors, the saturation accomplished by the above clamping
function is often folded into the arithmetic instructions themselves,
obviating the explicit step taken here.

To simplify the specification of relative pixel positions, we use the
word "before" to mean "immediately above" (for a vertical segment
straddling a horizontal edge) or "immediately to the left of" (for a
horizontal segment straddling a vertical edge), and the word "after"
to mean "immediately below" or "immediately to the right of".

Given an edge, a segment, and a limit value, the simple loop filter
computes a value based on the four pixels that straddle the edge (two
either side).  If that value is below a supplied limit, then, very
roughly speaking, the two pixel values are brought closer to each
other, "shaving off" something like a quarter of the difference.  The

same procedure is used for all segments straddling any type of edge,
regardless of the nature (inter-macroblock, inter-subblock, luma, or
chroma) of the edge; only the limit value depends on the edge type.

The exact procedure (for a single segment) is as follows; the
subroutine common_adjust is used by both the simple filter presented
here and the normal filters discussed in Section 15.3.

[source,c]</code></pre>
</div></div>
<div class="paragraph"><p>int8 common_adjust(
 int use_outer_taps,/* filter is 2 or 4 taps wide <strong>/
 const Pixel *P1, /</strong> pixel before P0 <strong>/
 Pixel *P0, /</strong> pixel before edge <strong>/
 Pixel *Q0, /</strong> pixel after edge <strong>/
 const Pixel *Q1  /</strong> pixel after Q0 <strong>/
) {
 cint8 p1 = u2s(*P1);/</strong> retrieve and convert all 4 pixels */
 cint8 p0 = u2s(*P0);
 cint8 q0 = u2s(*Q0);
 cint8 q1 = u2s(*Q1);</p></div>
<div class="literalblock">
<div class="content">
<pre><code>/* Disregarding clamping, when "use_outer_taps" is false,
"a" is 3*(q0-p0).  Since we are about to divide "a" by
8, in this case we end up multiplying the edge
difference by 5/8.</code></pre>
</div></div>
<div class="literalblock">
<div class="content">
<pre><code>When "use_outer_taps" is true (as for the simple filter),
"a" is p1 - 3*p0 + 3*q0 - q1, which can be thought of as
a refinement of 2*(q0 - p0), and the adjustment is
something like (q0 - p0)/4. */</code></pre>
</div></div>
<div class="literalblock">
<div class="content">
<pre><code>int8 a = c((use_outer_taps? c(p1 - q1) : 0) + 3*(q0 - p0));</code></pre>
</div></div>
<div class="literalblock">
<div class="content">
<pre><code>/* b is used to balance the rounding of a/8 in the case where
the "fractional" part "f" of a/8 is exactly 1/2. */</code></pre>
</div></div>
<div class="literalblock">
<div class="content">
<pre><code>cint8 b = (c(a + 3)) &gt;&gt; 3;</code></pre>
</div></div>
<div class="literalblock">
<div class="content">
<pre><code>/* Divide a by 8, rounding up when f &gt;= 1/2.
Although not strictly part of the C language,
the right shift is assumed to propagate the sign bit. */</code></pre>
</div></div>
<div class="literalblock">
<div class="content">
<pre><code>a = c(a + 4) &gt;&gt; 3;</code></pre>
</div></div>
<div class="literalblock">
<div class="content">
<pre><code>/* Subtract "a" from q0, "bringing it closer" to p0. */</code></pre>
</div></div>
<div class="literalblock">
<div class="content">
<pre><code>*Q0 = s2u(q0 - a);</code></pre>
</div></div>
<div class="literalblock">
<div class="content">
<pre><code>/* Add "a" (with adjustment "b") to p0, "bringing it closer"
to q0.</code></pre>
</div></div>
<div class="literalblock">
<div class="content">
<pre><code>The clamp of "a+b", while present in the reference decoder,
is superfluous; we have -16 &lt;= a &lt;= 15 at this point. */</code></pre>
</div></div>
<div class="literalblock">
<div class="content">
<pre><code>*P0 = s2u(p0 + b);</code></pre>
</div></div>
<div class="literalblock">
<div class="content">
<pre><code> return a;
}</code></pre>
</div></div>
<div class="listingblock">
<div class="content">
<pre><code>[source,c]</code></pre>
</div></div>
<div class="paragraph"><p>void simple_segment(
 uint8 edge_limit,/* do nothing if edge difference
exceeds limit <strong>/
 const Pixel *P1, /</strong> pixel before P0 <strong>/
 Pixel *P0, /</strong> pixel before edge <strong>/
 Pixel *Q0, /</strong> pixel after edge <strong>/
 const Pixel *Q1  /</strong> pixel after Q0 <strong>/
) {
 if abs(*P0 - *Q0)*2 + abs(*P1 - *Q1)/2) &#8656; edge_limit
  common_adjust(1, P1, P0, Q0, Q1);/</strong> use outer taps */
}</p></div>
<div class="listingblock">
<div class="content">
<pre><code>We make a couple of remarks about the rounding procedure above.  When
b is zero (that is, when the "fractional part" of a is not 1/2), we
are (except for clamping) adding the same number to p0 as we are
subtracting from q0.  This preserves the average value of p0 and q0,
but the resulting difference between p0 and q0 is always even; in
particular, the smallest non-zero gradation +-1 is not possible here.

When b is one, the value we add to p0 (again except for clamping) is
one less than the value we are subtracting from q0.  In this case,
the resulting difference is always odd (and the small gradation +-1
is possible), but the average value is reduced by 1/2, yielding, for
instance, a very slight darkening in the luma plane.  (In the very
unlikely event of appreciable darkening after a large number of
interframes, a compressor would of course eventually compensate for
this in the selection of predictor and/or residue.)

The derivation of the edge_limit value used above, which depends on
the loop_filter_level and sharpness_level, as well as the type of
edge being processed, will be taken up after we describe the normal
loop filtering algorithm below.

15.3.  Normal Filter

The normal loop filter is a refinement of the simple loop filter; all
of the general discussion above applies here as well.  In particular,
the functions c, u2s, s2u, abs, and common_adjust are used by both
the normal and simple filters.

As mentioned above, the normal algorithms for inter-macroblock and
inter-subblock edges differ.  Nonetheless, they have a great deal in
common: They use similar threshold algorithms to disable the filter
and to detect high internal edge variance (which influences the
filtering algorithm).  Both algorithms also use, at least
conditionally, the simple filter adjustment procedure described
above.

The common thresholding algorithms are as follows.

[source,c]</code></pre>
</div></div>
<div class="paragraph"><p>/* All functions take (among other things) a segment (of length at most 4 + 4 = 8) symmetrically straddling an edge.</p></div>
<div class="paragraph"><p>The pixel values (or pointers) are always given in order, from the "beforemost" to the "aftermost".  So, for a horizontal edge (written "|"), an 8-pixel segment would be ordered p3 p2 p1 p0 | q0 q1 q2 q3. */</p></div>
<div class="paragraph"><p>/* Filtering is disabled if the difference between any two adjacent "interior" pixels in the 8-pixel segment exceeds the relevant threshold (I).  A more complex thresholding calculation is done for the group of four pixels that straddle the edge, in line with the calculation in simple_segment() above. */</p></div>
<div class="paragraph"><p>int filter_yes(
 uint8 I,  /* limit on interior differences <strong>/
 uint8 E,  /</strong> limit at the edge */</p></div>
<div class="literalblock">
<div class="content">
<pre><code> cint8 p3, cint8 p2, cint8 p1, cint8 p0, /* pixels before
  edge */
 cint8 q0, cint8 q1, cint8 q2, cint8 q3  /* pixels after
  edge */
) {
 return  (abs(p0 - q0)*2 + abs(p1 - q1)/2) &lt;= E
  &amp;&amp;  abs(p3 - p2) &lt;= I  &amp;&amp;  abs(p2 - p1) &lt;= I  &amp;&amp;
 abs(p1 - p0) &lt;= I
  &amp;&amp;  abs(q3 - q2) &lt;= I  &amp;&amp;  abs(q2 - q1) &lt;= I  &amp;&amp;
 abs(q1 - q0) &lt;= I;
}</code></pre>
</div></div>
<div class="listingblock">
<div class="content">
<pre><code>[source,c]</code></pre>
</div></div>
<div class="paragraph"><p>/* Filtering is altered if (at least) one of the differences on either side of the edge exceeds a threshold (we have "high edge variance"). */</p></div>
<div class="paragraph"><p>int hev(
 uint8 threshold,
 cint8 p1, cint8 p0, /* pixels before edge <strong>/
 cint8 q0, cint8 q1  /</strong> pixels after edge */
) {
 return abs(p1 - p0) &gt; threshold  ||  abs(q1 - q0) &gt; threshold;
}</p></div>
<div class="listingblock">
<div class="content">
<pre><code>The subblock filter is a variant of the simple filter.  In fact, if
we have high edge variance, the adjustment is exactly as for the
simple filter.  Otherwise, the simple adjustment (without outer taps)
is applied, and the two pixels one step in from the edge pixels are
adjusted by roughly half the amount by which the two edge pixels are
adjusted; since the edge adjustment here is essentially 3/8 the edge
difference, the inner adjustment is approximately 3/16 the edge
difference.

[source,c]</code></pre>
</div></div>
<div class="paragraph"><p>void subblock_filter(
 uint8 hev_threshold,  /* detect high edge variance <strong>/
 uint8 interior_limit, /</strong> possibly disable filter <strong>/
 uint8 edge_limit,
 cint8 *P3, cint8 *P2, int8 *P1, int8 *P0,/</strong> pixels before
edge <strong>/
 int8 *Q0, int8 *Q1, cint8 *Q2, cint8 *Q3 /</strong> pixels after
edge */
) {
 cint8 p3 = u2s(*P3), p2 = u2s(*P2), p1 = u2s(*P1),
p0 = u2s(*P0);
 cint8 q0 = u2s(*Q0), q1 = u2s(*Q1), q2 = u2s(*Q2),
q3 = u2s(*Q3);</p></div>
<div class="literalblock">
<div class="content">
<pre><code> if (filter_yes(interior_limit, edge_limit, q3, q2, q1, q0,
p0, p1, p2, p3))
 {
  const int hv = hev(hev_threshold, p1, p0, q0, q1);</code></pre>
</div></div>
<div class="literalblock">
<div class="content">
<pre><code>cint8 a = (common_adjust(hv, P1, P0, Q0, Q1) + 1) &gt;&gt; 1;</code></pre>
</div></div>
<div class="literalblock">
<div class="content">
<pre><code>  if (!hv) {
*Q1 = s2u(q1 - a);
*P1 = s2u(p1 + a);
  }
 }
}</code></pre>
</div></div>
<div class="listingblock">
<div class="content">
<pre><code>The inter-macroblock filter has potentially wider scope.  If the edge
variance is high, it performs the simple adjustment (using the outer
taps, just like the simple filter and the corresponding case of the
normal subblock filter).  If the edge variance is low, we begin with
the same basic filter calculation and apply multiples of it to pixel
pairs symmetric about the edge; the magnitude of adjustment decays as
we move away from the edge and six of the pixels in the segment are
affected.

[source,c]</code></pre>
</div></div>
<div class="paragraph"><p>void MBfilter(
 uint8 hev_threshold,  /* detect high edge variance <strong>/
 uint8 interior_limit, /</strong> possibly disable filter <strong>/
 uint8 edge_limit,
 cint8 *P3, int8 *P2, int8 *P1, int8 *P0,  /</strong> pixels before
 edge <strong>/
 int8 *Q0, int8 *Q1, int8 *Q2, cint8 *Q3/</strong> pixels after
 edge */
) {
 cint8 p3 = u2s(*P3), p2 = u2s(*P2), p1 = u2s(*P1),
p0 = u2s(*P0);
 cint8 q0 = u2s(*Q0), q1 = u2s(*Q1), q2 = u2s(*Q2),
q3 = u2s(*Q3);</p></div>
<div class="literalblock">
<div class="content">
<pre><code> if (filter_yes(interior_limit, edge_limit, q3, q2, q1, q0,
p0, p1, p2, p3))
 {
  if (!hev(hev_threshold, p1, p0, q0, q1))
  {
/* Same as the initial calculation in "common_adjust",
w is something like twice the edge difference */</code></pre>
</div></div>
<div class="paragraph"><p>const int8 w = c(c(p1 - q1) + 3*(q0 - p0));</p></div>
<div class="paragraph"><p>/* 9/64 is approximately 9/63 = 1/7, and 1&lt;&lt;7 = 128 =
2*64.  So this a, used to adjust the pixels adjacent
to the edge, is something like 3/7 the edge
difference. */</p></div>
<div class="paragraph"><p>int8 a = c((27*w + 63) &gt;&gt; 7);</p></div>
<div class="paragraph"><p>*Q0 = s2u(q0 - a);  *P0 = s2u(p0 + a);</p></div>
<div class="paragraph"><p>/* Next two are adjusted by 2/7 the edge difference */</p></div>
<div class="paragraph"><p>a = c((18*w + 63) &gt;&gt; 7);</p></div>
<div class="paragraph"><p>*Q1 = s2u(q1 - a);  *P1 = s2u(p1 + a);</p></div>
<div class="paragraph"><p>/* Last two are adjusted by 1/7 the edge difference */</p></div>
<div class="paragraph"><p>a = c((9*w + 63) &gt;&gt; 7);</p></div>
<div class="paragraph"><p>*Q2 = s2u(q2 - a);  *P2 = s2u(p2 + a);</p></div>
<div class="literalblock">
<div class="content">
<pre><code>  } else /* if hev, do simple filter */
common_adjust(1, P1, P0, Q0, Q1);/* using outer
 taps */
 }
}</code></pre>
</div></div>
<div class="listingblock">
<div class="content">
<pre><code>15.4.  Calculation of Control Parameters

We conclude the discussion of loop filtering by showing how the
thresholds supplied to the procedures above are derived from the two
control parameters sharpness_level (an unsigned 3-bit number having
maximum value 7) and loop_filter_level (an unsigned 6-bit number
having maximum value 63).

While the sharpness_level is constant over the frame, individual
macroblocks may override the loop_filter_level with one of four
possibilities supplied in the frame header (as described in
Section 10).

Both the simple and normal filters disable filtering if a value
derived from the four pixels that straddle the edge (2 either side)
exceeds a threshold / limit value.

[source,c]</code></pre>
</div></div>
<div class="paragraph"><p>/* Luma and Chroma use the same inter-macroblock edge limit */
uint8 mbedge_limit = ((loop_filter_level + 2) * 2)<br />
  interior_limit;</p></div>
<div class="paragraph"><p>/* Luma and Chroma use the same inter-subblock edge limit */
uint8 sub_bedge_limit = (loop_filter_level * 2) + interior_limit;</p></div>
<div class="listingblock">
<div class="content">
<pre><code>The remaining thresholds are used only by the normal filters.  The
filter-disabling interior difference limit is the same for all edges
(luma, chroma, inter-subblock, inter-macroblock) and is given by the
following.

[source,c]</code></pre>
</div></div>
<div class="paragraph"><p>uint8 interior_limit = loop_filter_level;</p></div>
<div class="paragraph"><p>if (sharpness_level)
{
 interior_limit  &gt;&gt;=  sharpness_level &gt; 4 ?  2 : 1;
 if (interior_limit &gt; 9 - sharpness_level)
  interior_limit = 9 - sharpness_level;
}
if (!interior_limit)
 interior_limit = 1;</p></div>
<div class="listingblock">
<div class="content">
<pre><code>Finally, we give the derivation of the high edge-variance threshold,
which is also the same for all edge types.

[source,c]</code></pre>
</div></div>
<div class="paragraph"><p>uint8 hev_threshold = 0;</p></div>
<div class="paragraph"><p>if (we_are_decoding_akey_frame)/* current frame is a key frame <strong>/
{
 if (loop_filter_level &gt;= 40)
  hev_threshold = 2;
 else if (loop_filter_level &gt;= 15)
  hev_threshold = 1;
}
else /</strong> current frame is an interframe */
{
 if (loop_filter_level &gt;= 40)
  hev_threshold = 3;
 else if (loop_filter_level &gt;= 20)
  hev_threshold = 2;
 else if (loop_filter_level &gt;= 15)
  hev_threshold = 1;
}</p></div>
<div class="listingblock">
<div class="content">
<pre><code>16.  Interframe Macroblock Prediction Records

We describe the layout and semantics of the prediction records for
macroblocks in an interframe.

After the feature specification (which is described in Section 10 and
is identical for intraframes and interframes), there comes a
Bool(prob_intra), which indicates inter-prediction (i.e., prediction
from prior frames) when true and intra-prediction (i.e., prediction
from already-coded portions of the current frame) when false.  The
zero-probability prob_intra is set by field J of the frame header.

16.1.  Intra-Predicted Macroblocks

For intra-prediction, the layout of the prediction data is
essentially the same as the layout for key frames, although the
contexts used by the decoding process are slightly different.

As discussed in Section 8, the "outer" Y mode here uses a different
tree from that used in key frames, repeated here for convenience.

[source,c]</code></pre>
</div></div>
<div class="paragraph"><p>const tree_index ymode_tree [2 * (num_ymodes - 1)] =
{
 -DC_PRED, 2,  /* root: DC_PRED = "0", "1" subtree <strong>/
  4, 6,  /</strong> "1" subtree has 2 descendant subtrees <strong>/
-V_PRED, -H_PRED, /</strong> "10" subtree:  V_PRED = "100",
H_PRED = "101" <strong>/
-TM_PRED, -B_PRED /</strong> "11" subtree:  TM_PRED = "110",
B_PRED = "111" */
};</p></div>
<div class="listingblock">
<div class="content">
<pre><code>The probability table used to decode this tree is variable.  As
described in Section 11, it (along with the similarly treated UV
table) can be updated by field J of the frame header.  Similar to the
coefficient-decoding probabilities, such updates are cumulative and
affect all ensuing frames until the next key frame or explicit
update.  The default probabilities for the Y and UV tables are:

[source,c]</code></pre>
</div></div>
<div class="paragraph"><p>Prob ymode_prob [num_ymodes - 1] = { 112, 86, 140, 37};
Prob uv_mode_prob [num_uv_modes - 1] = { 162, 101, 204};</p></div>
<div class="listingblock">
<div class="content">
<pre><code>These defaults must be restored after detection of a key frame.

Just as for key frames, if the Y mode is B_PRED, there next comes an
encoding of the intra_bpred mode used by each of the sixteen Y
subblocks.  These encodings use the same tree as does that for key
frames but, in place of the contexts used in key frames, these
encodings use the single fixed probability table.

[source,c]</code></pre>
</div></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>Last comes the chroma mode, again coded using the same tree as that
used for key frames, this time using the dynamic uv_mode_prob table
described above.</p></div>
<div class="paragraph"><p>The calculation of the intra-prediction buffer is identical to that
described for key frames in Section 12.</p></div>
<div class="paragraph"><p>16.2.  Inter-Predicted Macroblocks</p></div>
<div class="paragraph"><p>Otherwise (when the above bool is true), we are using
inter-prediction (which of course only happens for interframes), to
which we now restrict our attention.</p></div>
<div class="paragraph"><p>The next datum is then another bool, B(prob_last), selecting the
reference frame.  If 0, the reference frame is the previous frame
(the last frame); if 1, another bool (prob_gf) selects the reference
frame between the golden frame (0) and the altref frame (1).  The
probabilities prob_last and prob_gf are set in field J of the frame
header.</p></div>
<div class="paragraph"><p>Together with setting the reference frame, the purpose of inter-mode
decoding is to set a motion vector for each of the sixteen Y
subblocks of the current macroblock.  These settings then define the
calculation of the inter-prediction buffer (detailed in Section 18).
While the net effect of inter-mode decoding is straightforward, the
implementation is somewhat complex; the (lossless) compression
achieved by this method justifies the complexity.</p></div>
<div class="paragraph"><p>After the reference frame selector comes the mode (or motion vector
reference) applied to the macroblock as a whole, coded using the
following enumeration and tree.  Setting mv_nearest = num_ymodes is a
convenience that allows a single variable to unambiguously hold an
inter- or intra-prediction mode.</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="literalblock">
<div class="content">
<pre><code> num_mv_refs = mv_split + 1 - mv_nearest
}
mv_ref;</code></pre>
</div></div>
<div class="paragraph"><p>const tree_index mv_ref_tree [2 * (num_mv_refs - 1)] =
{
 -mv_zero, 2, /* zero = "0" <strong>/
  -mv_nearest, 4,/</strong> nearest = "10" <strong>/
-mv_near, 6,  /</strong> near = "110" <strong>/
  -mv_new, -mv_split/</strong> new = "1110", split = "1111" */
};</p></div>
<div class="listingblock">
<div class="content">
<pre><code>16.3.  Mode and Motion Vector Contexts

The probability table used to decode the mv_ref, along with three
reference motion vectors used by the selected mode, is calculated via
a survey of the already-decoded motion vectors in (up to) 3 nearby
macroblocks.

The algorithm generates a sorted list of distinct motion vectors
adjacent to the search site.  The best_mv is the vector with the
highest score.  The mv_nearest is the non-zero vector with the
highest score.  The mv_near is the non-zero vector with the next
highest score.  The number of motion vectors coded using the SPLITMV
mode is scored using the same weighting and is returned with the
scores of the best, nearest, and near vectors.

The three adjacent macroblocks above, left, and above-left are
considered in order.  If the macroblock is intra-coded, no action is
taken.  Otherwise, the motion vector is compared to other previously
found motion vectors to determine if it has been seen before, and if
so contributes its weight to that vector; otherwise, it enters a new
vector in the list.  The above and left vectors have twice the weight
of the above-left vector.

As is the case with many contexts used by VP8, it is possible for
macroblocks near the top or left edges of the image to reference
blocks that are outside the visible image.  VP8 provides a border of
1 macroblock filled with 0x0 motion vectors left of the left edge,
and a border filled with 0,0 motion vectors of 1 macroblocks above
the top edge.

Much of the process is more easily described in C than in English.
The reference code for this can be found in modemv.c (Section 20.11).
The calculation of reference vectors, probability table, and,
finally, the inter-prediction mode itself is implemented as follows.

[source,c]
----typedef union
{
 unsigned int as_int;
 MV  as_mv;
} int_mv;  /* facilitates rapid equality tests */

static void mv_bias(MODE_INFO *x,int refframe, int_mv *mvp,
  int * ref_frame_sign_bias)
{
 MV xmv;
 xmv = x-&gt;mbmi.mv.as_mv;
 if ( ref_frame_sign_bias[x-&gt;mbmi.ref_frame] !=
ref_frame_sign_bias[refframe] )
 {
  xmv.row*=-1;
  xmv.col*=-1;
 }
 mvp-&gt;as_mv = xmv;
}</code></pre>
</div></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="literalblock">
<div class="content">
<pre><code> if ( mv-&gt;row &lt; (xd-&gt;mb_to_top_edge - LEFT_TOP_MARGIN) )
  mv-&gt;row = xd-&gt;mb_to_top_edge - LEFT_TOP_MARGIN;
 else if ( mv-&gt;row &gt; xd-&gt;mb_to_bottom_edge + RIGHT_BOTTOM_MARGIN )
  mv-&gt;row = xd-&gt;mb_to_bottom_edge + RIGHT_BOTTOM_MARGIN;
}</code></pre>
</div></div>
<div class="listingblock">
<div class="content">
<pre><code>In the function vp8_find_near_mvs(), the vectors "nearest" and "near"
are used by the corresponding modes.

The vector best_mv is used as a base for explicitly coded motion
vectors.

The first three entries in the return value cnt are (in order)
weighted census values for "zero", "nearest", and "near" vectors.
The final value indicates the extent to which SPLITMV was used by the
neighboring macroblocks.  The largest possible "weight" value in each
case is 5.

[source,c]
----void vp8_find_near_mvs
(
 MACROBLOCKD *xd,
 const MODE_INFO *here,
 MV *nearest,
 MV *near,
 MV *best_mv,
 int cnt[4],
 int refframe,
 int * ref_frame_sign_bias
)

{
 const MODE_INFO *above = here - xd-&gt;mode_info_stride;
 const MODE_INFO *left = here - 1;
 const MODE_INFO *aboveleft = above - 1;
 int_mvnear_mvs[4];
 int_mv  *mv = near_mvs;
 int *cntx = cnt;
 enum {CNT_ZERO, CNT_NEAREST, CNT_NEAR, CNT_SPLITMV};

 /* Zero accumulators */
 mv[0].as_int = mv[1].as_int = mv[2].as_int = 0;
 cnt[0] = cnt[1] = cnt[2] = cnt[3] = 0;

 /* Process above */
 if (above-&gt;mbmi.ref_frame != INTRA_FRAME) {
  if (above-&gt;mbmi.mv.as_int) {
(++mv)-&gt;as_int = above-&gt;mbmi.mv.as_int;
mv_bias(above, refframe, mv, ref_frame_sign_bias);
++cntx;
  }
  *cntx += 2;
 }

 /* Process left */
 if (left-&gt;mbmi.ref_frame != INTRA_FRAME) {
  if (left-&gt;mbmi.mv.as_int) {
int_mv this_mv;

this_mv.as_int = left-&gt;mbmi.mv.as_int;
mv_bias(left, refframe, &amp;this_mv, ref_frame_sign_bias);

if (this_mv.as_int != mv-&gt;as_int) {
 (++mv)-&gt;as_int = this_mv.as_int;
 ++cntx;
}
*cntx += 2;
  } else
cnt[CNT_ZERO] += 2;
 }

 /* Process above left */
 if (aboveleft-&gt;mbmi.ref_frame != INTRA_FRAME) {
  if (aboveleft-&gt;mbmi.mv.as_int) {
int_mv this_mv;

this_mv.as_int = aboveleft-&gt;mbmi.mv.as_int;
mv_bias(aboveleft, refframe, &amp;this_mv,
  ref_frame_sign_bias);

if (this_mv.as_int != mv-&gt;as_int) {
 (++mv)-&gt;as_int = this_mv.as_int;
 ++cntx;
}
*cntx += 1;
  } else
cnt[CNT_ZERO] += 1;
 }

 /* If we have three distinct MVs ... */
 if (cnt[CNT_SPLITMV]) {
  /* See if above-left MV can be merged with NEAREST */
  if (mv-&gt;as_int == near_mvs[CNT_NEAREST].as_int)
cnt[CNT_NEAREST] += 1;
 }

 cnt[CNT_SPLITMV] = ((above-&gt;mbmi.mode == SPLITMV)
 + (left-&gt;mbmi.mode == SPLITMV)) * 2
+ (aboveleft-&gt;mbmi.mode == SPLITMV);

 /* Swap near and nearest if necessary */
 if (cnt[CNT_NEAR] &gt; cnt[CNT_NEAREST]) {
  int tmp;
  tmp = cnt[CNT_NEAREST];
  cnt[CNT_NEAREST] = cnt[CNT_NEAR];
  cnt[CNT_NEAR] = tmp;
  tmp = near_mvs[CNT_NEAREST].as_int;
  near_mvs[CNT_NEAREST].as_int = near_mvs[CNT_NEAR].as_int;
  near_mvs[CNT_NEAR].as_int = tmp;
 }

 /* Use near_mvs[0] to store the "best" MV */
 if (cnt[CNT_NEAREST] &gt;= cnt[CNT_ZERO])
  near_mvs[CNT_ZERO] = near_mvs[CNT_NEAREST];

 /* Set up return values */
 *best_mv = near_mvs[0].as_mv;
 *nearest = near_mvs[CNT_NEAREST].as_mv;
 *near = near_mvs[CNT_NEAR].as_mv;

 vp8_clamp_mv(nearest, xd);
 vp8_clamp_mv(near, xd);
 vp8_clamp_mv(best_mv, xd); //TODO: Move this up before
the copy
}</code></pre>
</div></div>
<div class="paragraph"><p>The mv_ref probability table (mv_ref_p) is then derived from the
census as follows.</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="listingblock">
<div class="content">
<pre><code>[source,c]
----vp8_prob *vp8_mv_ref_probs(vp8_prob mv_ref_p[VP8_MVREFS-1],
  int cnt[4])
{
 mv_ref_p[0] = vp8_mode_contexts [cnt[0]] [0];
 mv_ref_p[1] = vp8_mode_contexts [cnt[1]] [1];
 mv_ref_p[2] = vp8_mode_contexts [cnt[2]] [2];
 mv_ref_p[3] = vp8_mode_contexts [cnt[3]] [3];
 return p;
}</code></pre>
</div></div>
<div class="paragraph"><p>Once mv_ref_p is established, the mv_ref is decoded as usual.</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="listingblock">
<div class="content">
<pre><code>For the first four inter-coding modes, the same motion vector is used
for all the Y subblocks.  The first three modes use an implicit
motion vector.

+------------+------------------------------------------------------+
| Mode | Instruction|
+------------+------------------------------------------------------+
| mv_nearest | Use the nearest vector returned by |
|| vp8_find_near_mvs.  |
|||
| mv_near | Use the near vector returned by vp8_find_near_mvs.|
|||
| mv_zero | Use a zero vector; that is, predict the current|
|| macroblock from the corresponding macroblock in the  |
|| prediction frame.|
|||
| NEWMV| This mode is followed by an explicitly coded motion  |
|| vector (the format of which is described in the next |
|| section) that is added (component-wise) to the |
|| best_mv reference vector returned by find_near_mvs|
|| and applied to all 16 subblocks.|
+------------+------------------------------------------------------+

16.4.  Split Prediction

The remaining mode (SPLITMV) causes multiple vectors to be applied to
the Y subblocks.  It is immediately followed by a partition
specification that determines how many vectors will be specified and
how they will be assigned to the subblocks.  The possible partitions,
with indicated subdivisions and coding tree, are as follows.

[source,c]
----typedef enum
{
 mv_top_bottom,/* two pieces {0...7} and {8...15} */
 mv_left_right,/* {0,1,4,5,8,9,12,13} and
{2,3,6,7,10,11,14,15} */
 mv_quarters, /* {0,1,4,5}, {2,3,6,7}, {8,9,12,13},
  {10,11,14,15} */
 MV_16, /* every subblock gets its own vector
  {0} ... {15} */

 mv_num_partitions
}
MVpartition;

const tree_index mvpartition_tree [2 * (mvnum_partition - 1)] =
{
 -MV_16, 2, /* MV_16 = "0" */
  -mv_quarters, 4,/* mv_quarters = "10" */
-mv_top_bottom, -mv_left_right/* top_bottom = "110",
left_right = "111" */
};</code></pre>
</div></div>
<div class="paragraph"><p>The partition is decoded using a fixed, constant probability table:</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>After the partition come two (for mv_top_bottom or mv_left_right),
four (for mv_quarters), or sixteen (for MV_16) subblock
inter-prediction modes.  These modes occur in the order indicated by
the partition layouts (given as comments to the MVpartition enum) and
are coded as follows.  (As was done for the macroblock-level modes,
we offset the mode enumeration so that a single variable may
unambiguously hold either an intra- or inter-subblock mode.)</p></div>
<div class="paragraph"><p>Prior to decoding each subblock, a decoding tree context is chosen as
illustrated in the code snippet below.  The context is based on the
immediate left and above subblock neighbors, and whether they are
equal, are zero, or a combination of those.</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>The first two sub-prediction modes simply copy the already-coded
motion vectors used by the blocks above and to the left of the
subblock at the upper left corner of the current subset (i.e.,
collection of subblocks being predicted).  These prediction blocks
need not lie in the current macroblock and, if the current subset
lies at the top or left edges of the frame, need not lie in the
frame.  In this latter case, their motion vectors are taken to be
zero, as are subblock motion vectors within an intra-predicted
macroblock.  Also, to ensure the correctness of prediction within
this macroblock, all subblocks lying in an already-decoded subset of
the current macroblock must have their motion vectors set.</p></div>
<div class="paragraph"><p>ZERO4x4 uses a zero motion vector and predicts the current subset
using the corresponding subset from the prediction frame.</p></div>
<div class="paragraph"><p>NEW4x4 is exactly like NEWMV except that NEW4x4 is applied only to
the current subset.  It is followed by a two-dimensional motion
vector offset (described in the next section) that is added to the
best vector returned by the earlier call to find_near_mvs to form the
motion vector in effect for the subset.</p></div>
<div class="paragraph"><p>Parsing of both inter-prediction modes and motion vectors (described
next) can be found in the reference decoder file modemv.c
(Section 20.11).</p></div>
<div class="olist arabic"><ol class="arabic">
<li>
<p>
Motion Vector Decoding
</p>
</li>
</ol></div>
<div class="paragraph"><p>As discussed above, motion vectors appear in two places in the VP8
datastream: applied to whole macroblocks in NEWMV mode and applied to
subsets of macroblocks in NEW4x4 mode.  The format of the vectors is
identical in both cases.</p></div>
<div class="paragraph"><p>Each vector has two pieces: a vertical component (row) followed by a
horizontal component (column).  The row and column use separate
coding probabilities but are otherwise represented identically.</p></div>
<div class="paragraph"><p>17.1.  Coding of Each Component</p></div>
<div class="paragraph"><p>Each component is a signed integer V representing a vertical or
horizontal luma displacement of V quarter-pixels (and a chroma
displacement of V eighth-pixels).  The absolute value of V, if
non-zero, is followed by a boolean sign.  V may take any value
between -1023 and +1023, inclusive.</p></div>
<div class="paragraph"><p>The absolute value A is coded in one of two different ways according
to its size.  For 0 &#8656; A &#8656; 7, A is tree-coded, and for 8 &#8656; A &#8656;
1023, the bits in the binary expansion of A are coded using
independent boolean probabilities.  The coding of A begins with a
bool specifying which range is in effect.</p></div>
<div class="paragraph"><p>Decoding a motion vector component then requires a 19-position
probability table, whose offsets, along with the procedure used to
decode components, are as follows:</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>17.2.  Probability Updates</p></div>
<div class="paragraph"><p>The decoder should maintain an array of two MV_CONTEXTs for decoding
row and column components, respectively.  These MV_CONTEXTs should be
set to their defaults every key frame.  Each individual probability
may be updated every interframe (by field J of the frame header)
using a constant table of update probabilities.  Each optional update
is of the form B?  P(7), that is, a bool followed by a 7-bit
probability specification if true.</p></div>
<div class="paragraph"><p>As with other dynamic probabilities used by VP8, the updates remain
in effect until the next key frame or until replaced via another
update.</p></div>
<div class="paragraph"><p>In detail, the probabilities should then be managed as follows.</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>This completes the description of the motion-vector decoding
procedure and, with it, the procedure for decoding interframe
macroblock prediction records.</p></div>
<div class="olist arabic"><ol class="arabic">
<li>
<p>
Interframe Prediction
</p>
</li>
</ol></div>
<div class="paragraph"><p>Given an inter-prediction specification for the current macroblock,
that is, a reference frame together with a motion vector for each of
the sixteen Y subblocks, we describe the calculation of the
prediction buffer for the macroblock.  Frame reconstruction is then
completed via the previously described processes of residue summation
(Section 14) and loop filtering (Section 15).</p></div>
<div class="paragraph"><p>The management of inter-predicted subblocks and sub-pixel
interpolation may be found in the reference decoder file predict.c
(Section 20.14).</p></div>
<div class="paragraph"><p>18.1.  Bounds on, and Adjustment of, Motion Vectors</p></div>
<div class="paragraph"><p>Since each motion vector is differentially encoded from a neighboring
block or macroblock and the only clamp is to ensure that the
referenced motion vector represents a valid location inside a
reference frame buffer, it is technically possible within the VP8
format for a block or macroblock to have arbitrarily large motion
vectors, up to the size of the input image plus the extended border
areas.  For practical reasons, VP8 imposes a motion vector size range
limit of -4096 to 4095 full pixels, regardless of image size (VP8
defines 14 raw bits for width and height; 16383x16383 is the maximum
possible image size).  Bitstream-compliant encoders and decoders
shall enforce this limit.</p></div>
<div class="paragraph"><p>Because the motion vectors applied to the chroma subblocks have
1/8-pixel resolution, the synthetic pixel calculation, outlined in
Section 5 and detailed below, uses this resolution for the luma
subblocks as well.  In accordance, the stored luma motion vectors are
all doubled, each component of each luma vector becoming an even
integer in the range -2046 to +2046, inclusive.</p></div>
<div class="paragraph"><p>The vector applied to each chroma subblock is calculated by averaging
the vectors for the 4 luma subblocks occupying the same visible area
as the chroma subblock in the usual correspondence; that is, the
vector for U and V block 0 is the average of the vectors for the Y
subblocks { 0, 1, 4, 5}, chroma block 1 corresponds to Y blocks { 2,
3, 6, 7}, chroma block 2 to Y blocks { 8, 9, 12, 13}, and chroma
block 3 to Y blocks { 10, 11, 14, 15}.</p></div>
<div class="paragraph"><p>In detail, each of the two components of the vectors for each of the
chroma subblocks is calculated from the corresponding luma vector
components as follows:</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>Furthermore, if the version number in the frame tag specifies only
full-pel chroma motion vectors, then the fractional parts of both
components of the vector are truncated to zero, as illustrated in the
following pseudocode (assuming 3 bits of fraction for both luma and
chroma vectors):</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>Earlier in this document we described the vp8_clamp_mv() function to
limit "nearest" and "near" motion vector predictors inside specified
margins within the frame boundaries.  Additional clamping is
performed for NEWMV macroblocks, for which the final motion vector is
clamped again after combining the "best" predictor and the
differential vector decoded from the stream.</p></div>
<div class="paragraph"><p>However, the secondary clamping is not performed for SPLITMV
macroblocks, meaning that any subblock&#8217;s motion vector within the
SPLITMV macroblock may point outside the clamping zone.  These
non-clamped vectors are also used when determining the decoding tree
context for subsequent subblocks' modes in the vp8_mvCont() function.</p></div>
<div class="paragraph"><p>18.2.  Prediction Subblocks</p></div>
<div class="paragraph"><p>The prediction calculation for each subblock is then as follows.
Temporarily disregarding the fractional part of the motion vector
(that is, rounding "up" or "left" by right-shifting each component
3 bits with sign propagation) and adding the origin (upper left
position) of the (16x16 luma or 8x8 chroma) current macroblock gives
us an origin in the Y, U, or V plane of the predictor frame (either
the golden frame or previous frame).</p></div>
<div class="paragraph"><p>Considering that origin to be the upper left corner of a (luma or
chroma) macroblock, we need to specify the relative positions of the
pixels associated to that subblock, that is, any pixels that might be
involved in the sub-pixel interpolation processes for the subblock.</p></div>
<div class="paragraph"><p>18.3.  Sub-Pixel Interpolation</p></div>
<div class="paragraph"><p>The sub-pixel interpolation is effected via two one-dimensional
convolutions.  These convolutions may be thought of as operating on a
two-dimensional array of pixels whose origin is the subblock origin,
that is the origin of the prediction macroblock described above plus
the offset to the subblock.  Because motion vectors are arbitrary, so
are these "prediction subblock origins".</p></div>
<div class="paragraph"><p>The integer part of the motion vector is subsumed in the origin of
the prediction subblock; the 16 (synthetic) pixels we need to
construct are given by 16 offsets from the origin.  The integer part
of each of these offsets is the offset of the corresponding pixel
from the subblock origin (using the vertical stride).  To these
integer parts is added a constant fractional part, which is simply
the difference between the actual motion vector and its integer
truncation used to calculate the origins of the prediction macroblock
and subblock.  Each component of this fractional part is an integer
between 0 and 7, representing a forward displacement in eighths of a
pixel.</p></div>
<div class="paragraph"><p>It is these fractional displacements that determine the filtering
process.  If they both happen to be zero (that is, we had a "whole
pixel" motion vector), the prediction subblock is simply copied into
the corresponding piece of the current macroblock&#8217;s prediction
buffer.  As discussed in Section 14, the layout of the macroblock&#8217;s
prediction buffer can depend on the specifics of the reconstruction
implementation chosen.  Of course, the vertical displacement between
lines of the prediction subblock is given by the stride, as are all
vertical displacements used here.</p></div>
<div class="paragraph"><p>Otherwise, at least one of the fractional displacements is non-zero.
We then synthesize the missing pixels via a horizontal, followed by a
vertical, one-dimensional interpolation.</p></div>
<div class="paragraph"><p>The two interpolations are essentially identical.  Each uses a (at
most) six-tap filter (the choice of which of course depends on the
one-dimensional offset).  Thus, every calculated pixel references at
most three pixels before (above or to the left of) it and at most
three pixels after (below or to the right of) it.  The horizontal
interpolation must calculate two extra rows above and three extra
rows below the 4x4 block, to provide enough samples for the vertical
interpolation to proceed.</p></div>
<div class="paragraph"><p>Depending on the reconstruction filter type given in the version
number field in the frame tag, either a bicubic or a bilinear tap set
is used.</p></div>
<div class="paragraph"><p>The exact implementation of subsampling is as follows.</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>18.4.  Filter Properties</p></div>
<div class="paragraph"><p>We discuss briefly the rationale behind the choice of filters.  Our
approach is necessarily cursory; a genuinely accurate discussion
would require a couple of books.  Readers unfamiliar with signal
processing may or may not wish to skip this.</p></div>
<div class="paragraph"><p>All digital signals are of course sampled in some fashion.  The case
where the inter-sample spacing (say in time for audio samples, or
space for pixels) is uniform, that is, the same at all positions, is
particularly common and amenable to analysis.  Many aspects of the
treatment of such signals are best-understood in the frequency domain
via Fourier Analysis, particularly those aspects of the signal that
are not changed by shifts in position, especially when those
positional shifts are not given by a whole number of samples.</p></div>
<div class="paragraph"><p>Non-integral translates of a sampled signal are a textbook example of
the foregoing.  In our case of non-integral motion vectors, we wish
to say what the underlying image "really is" at these pixels;
although we don&#8217;t have values for them, we feel that it makes sense
to talk about them.  The correctness of this feeling is predicated on
the underlying signal being band-limited, that is, not containing any
energy in spatial frequencies that cannot be faithfully rendered at
the pixel resolution at our disposal.  In one dimension, this range
of "OK" frequencies is called the Nyquist band; in our two-
dimensional case of integer-grid samples, this range might be termed
a Nyquist rectangle.  The finer the grid, the more we know about the
image, and the wider the Nyquist rectangle.</p></div>
<div class="paragraph"><p>It turns out that, for such band-limited signals, there is indeed an
exact mathematical formula to produce the correct sample value at an
arbitrary point.  Unfortunately, this calculation requires the
consideration of every single sample in the image, as well as needing
to operate at infinite precision.  Also, strictly speaking, all band-
limited signals have infinite spatial (or temporal) extent, so
everything we are discussing is really some sort of approximation.</p></div>
<div class="paragraph"><p>It is true that the theoretically correct subsampling procedure, as
well as any approximation thereof, is always given by a translation-
invariant weighted sum (or filter) similar to that used by VP8.  It
is also true that the reconstruction error made by such a filter can
be simply represented as a multiplier in the frequency domain; that
is, such filters simply multiply the Fourier transform of any signal
to which they are applied by a fixed function associated to the
filter.  This fixed function is usually called the frequency response
(or transfer function); the ideal subsampling filter has a frequency
response equal to one in the Nyquist rectangle and zero everywhere
else.</p></div>
<div class="paragraph"><p>Another basic fact about approximations to "truly correct"
subsampling is that the wider the subrectangle (within the Nyquist
rectangle) of spatial frequencies one wishes to "pass" (that is,
correctly render) or, put more accurately, the closer one wishes to
approximate the ideal transfer function, the more samples of the
original signal must be considered by the subsampling, and the wider
the calculation precision necessitated.</p></div>
<div class="paragraph"><p>The filters chosen by VP8 were chosen, within the constraints of 4 or
6 taps and 7-bit precision, to do the best possible job of handling
the low spatial frequencies near the 0th DC frequency along with
introducing no resonances (places where the absolute value of the
frequency response exceeds one).</p></div>
<div class="paragraph"><p>The justification for the foregoing has two parts.  First, resonances
can produce extremely objectionable visible artifacts when, as often
happens in actual compressed video streams, filters are applied
repeatedly.  Second, the vast majority of energy in real-world images
lies near DC and not at the high end.</p></div>
<div class="paragraph"><p>To get slightly more specific, the filters chosen by VP8 are the best
resonance-free 4- or 6-tap filters possible, where "best" describes
the frequency response near the origin: The response at 0 is required
to be 1, and the graph of the response at 0 is as flat as possible.</p></div>
<div class="paragraph"><p>To provide an intuitively more obvious point of reference, the "best"
2-tap filter is given by simple linear interpolation between the
surrounding actual pixels.</p></div>
<div class="paragraph"><p>Finally, it should be noted that, because of the way motion vectors
are calculated, the (shorter) 4-tap filters (used for odd fractional
displacements) are applied in the chroma plane only.  Human color
perception is notoriously poor, especially where higher spatial
frequencies are involved.  The shorter filters are easier to
understand mathematically, and the difference between them and a
theoretically slightly better 6-tap filter is negligible where chroma
is concerned.</p></div>
<div class="olist arabic"><ol class="arabic">
<li>
<p>
Annex A: Bitstream Syntax
</p>
</li>
</ol></div>
<div class="paragraph"><p>This annex presents the bitstream syntax in a tabular form.  All the
information elements have been introduced and explained in the
previous sections but are collected here for a quick reference.  Each
syntax element is briefly described after the tabular representation
along with a reference to the corresponding paragraph in the main
document.  The meaning of each syntax element value is not repeated
here.</p></div>
<div class="paragraph"><p>The top-level hierarchy of the bitstream is introduced in Section 4.</p></div>
<div class="paragraph"><p>Definition of syntax element coding types can be found in Section 8.
The types used in the representation in this annex are:</p></div>
<div class="paragraph"><p>o  f(n), n-bit value from stream (n successive bits, not boolean
encoded)</p></div>
<div class="paragraph"><p>o  L(n), n-bit number encoded as n booleans (with equal probability
of being 0 or 1)</p></div>
<div class="paragraph"><p>o  B(p), bool with probability p of being 0</p></div>
<div class="paragraph"><p>o  T, tree-encoded value</p></div>
<div class="paragraph"><p>19.1.  Uncompressed Data Chunk</p></div>
<div class="paragraph"><p>| Frame Tag  | Type  |
|----------- | ----- |
| frame_tag  | f(24) |
| if (key_frame) { | |
|  start_code| f(24) |
|  horizontal_size_code  | f(16) |
|  vertical_size_code | f(16) |
| } | |</p></div>
<div class="paragraph"><p>The 3-byte frame tag can be parsed as follows:</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>Where:</p></div>
<div class="paragraph"><p>o  key_frame indicates whether the current frame is a key frame
or not.</p></div>
<div class="paragraph"><p>o  version determines the bitstream version.</p></div>
<div class="paragraph"><p>o  show_frame indicates whether the current frame is meant to be
displayed or not.</p></div>
<div class="paragraph"><p>o  first_part_size determines the size of the first partition
(control partition), excluding the uncompressed data chunk.</p></div>
<div class="paragraph"><p>The start_code is a constant 3-byte pattern having value 0x9d012a.
The latter part of the uncompressed chunk (after the start_code) can
be parsed as follows:</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>19.2.  Frame Header</p></div>
<div class="paragraph"><p>| Frame Header  | Type  |
|----------- | ----- |
| if (key_frame) { | |
|color_space | L(1)  |
|clamping_type  | L(1)  |
| } | |
| segmentation_enabled| L(1)  |
| if (segmentation_enabled) | |
|update_segmentation()| |
| filter_type| L(1)  |
| loop_filter_level| L(6)  |
| sharpness_level  | L(3)  |
| mb_lf_adjustments() | |
| log2_nbr_of_dct_partitions| L(2)  |
| quant_indices()  | |
| if (key_frame)| |
|refresh_entropy_probs| L(1)  |
| else {  | |
|refresh_golden_frame | L(1)  |
|refresh_alternate_frame | L(1)  |
|if (!refresh_golden_frame) | |
|  copy_buffer_to_golden | L(2)  |
|if (!refresh_alternate_frame) | |
|  copy_buffer_to_alternate | L(2)  |
|sign_bias_golden  | L(1)  |
|sign_bias_alternate  | L(1)  |
|refresh_entropy_probs| L(1)  |
|refresh_last| L(1)  |
| } | |
| token_prob_update() | |
| mb_no_skip_coeff | L(1)  |
| if (mb_no_skip_coeff)  | |
|prob_skip_false| L(8)  |
| if (!key_frame) {| |
|prob_intra  | L(8)  |
|prob_last| L(8)  |
|prob_gf  | L(8)  |
|intra_16x16_prob_update_flag  | L(1)  |
|if (intra_16x16_prob_update_flag) { | |
|  for (i = 0; i &lt; 4; i<code>)  | |
| intra_16x16_prob | L(8)  |
|}  | |
|intra_chroma prob_update_flag | L(1)  |
|if (intra_chroma_prob_update_flag) {| |
|  for (i = 0; i &lt; 3; i</code>)  | |
| intra_chroma_prob| L(8)  |
|}  | |
|mv_prob_update()  | |
| } | |</p></div>
<div class="paragraph"><p>o  color_space defines the YUV color space of the sequence
(Section 9.2)</p></div>
<div class="paragraph"><p>o  clamping_type specifies if the decoder is required to clamp the
reconstructed pixel values (Section 9.2)</p></div>
<div class="paragraph"><p>o  segmentation_enabled enables the segmentation feature for the
current frame (Section 9.3)</p></div>
<div class="paragraph"><p>o  filter_type determines whether the normal or the simple loop
filter is used (Sections 9.4, 15)</p></div>
<div class="paragraph"><p>o  loop_filter_level controls the deblocking filter
(Sections 9.4, 15)</p></div>
<div class="paragraph"><p>o  sharpness_level controls the deblocking filter (Sections 9.4, 15)</p></div>
<div class="paragraph"><p>o  log2_nbr_of_dct_partitions determines the number of separate
partitions containing the DCT coefficients of the macroblocks
(Section 9.5)</p></div>
<div class="paragraph"><p>o  refresh_entropy_probs determines whether updated token
probabilities are used only for this frame or until further update</p></div>
<div class="paragraph"><p>o  refresh_golden_frame determines if the current decoded frame
refreshes the golden frame (Section 9.7)</p></div>
<div class="paragraph"><p>o  refresh_alternate_frame determines if the current decoded frame
refreshes the alternate reference frame (Section 9.7)</p></div>
<div class="paragraph"><p>o  copy_buffer_to_golden determines if the golden reference is
replaced by another reference (Section 9.7)</p></div>
<div class="paragraph"><p>o  copy_buffer_to_alternate determines if the alternate reference is
replaced by another reference (Section 9.7)</p></div>
<div class="paragraph"><p>o  sign_bias_golden controls the sign of motion vectors when the
golden frame is referenced (Section 9.7)</p></div>
<div class="paragraph"><p>o  sign_bias_alternate controls the sign of motion vectors when the
alternate frame is referenced (Section 9.7)</p></div>
<div class="paragraph"><p>o  refresh_last determines if the current decoded frame refreshes the
last frame reference buffer (Section 9.8)</p></div>
<div class="paragraph"><p>o  mb_no_skip_coeff enables or disables the skipping of macroblocks
containing no non-zero coefficients (Section 9.10)</p></div>
<div class="paragraph"><p>o  prob_skip_false indicates the probability that the macroblock is
not skipped (flag indicating skipped macroblock is false)
(Section 9.10)</p></div>
<div class="paragraph"><p>o  prob_intra indicates the probability of an intra macroblock
(Section 9.10)</p></div>
<div class="paragraph"><p>o  prob_last indicates the probability that the last reference frame
is used for inter-prediction (Section 9.10)</p></div>
<div class="paragraph"><p>o  prob_gf indicates the probability that the golden reference frame
is used for inter-prediction (Section 9.10)</p></div>
<div class="paragraph"><p>o  intra_16x16_prob_update_flag indicates if the branch probabilities
used in the decoding of the luma intra-prediction mode are updated
(Section 9.10)</p></div>
<div class="paragraph"><p>o  intra_16x16_prob indicates the branch probabilities of the luma
intra-prediction mode decoding tree</p></div>
<div class="paragraph"><p>o  intra_chroma_prob_update_flag indicates if the branch
probabilities used in the decoding of the chroma intra-prediction
mode are updated (Section 9.10)</p></div>
<div class="paragraph"><p>o  intra_chroma_prob indicates the branch probabilities of the chroma
intra-prediction mode decoding tree</p></div>
<div class="paragraph"><p>| update_segmentation()  | Type  |
|----------- | ----- |
| update_mb_segmentation_map| L(1)  |
| update_segment_feature_data  | L(1)  |
| if (update_segment_feature_data) { | |
|segment_feature_mode | L(1)  |
|for (i = 0; i &lt; 4; i<code>) {  | |
|  quantizer_update| L(1)  |
|  if (quantizer_update) {  | |
| quantizer_update_value | L(7)  |
| quantizer_update_sign  | L(1)  |
|  }| |
|}  | |
|for (i = 0; i &lt; 4; i</code>) {  | |
|  loop_filter_update | L(1)  |
|  if (loop_filter_update) {| |
| lf_update_value  | L(6)  |
| lf_update_sign| L(1)  |
|  }| |
|}  | |
| } | |
| if (update_mb_segmentation_map) {  | |
|for (i = 0; i &lt; 3; i++) {  | |
|  segment_prob_update| L(1)  |
|  if (segment_prob_update) | |
| segment_prob  | L(8)  |
|}  | |
| } | |</p></div>
<div class="paragraph"><p>o  update_mb_segmentation_map determines if the MB segmentation map
is updated in the current frame (Section 9.3)</p></div>
<div class="paragraph"><p>o  update_segment_feature_data indicates if the segment feature data
is updated in the current frame (Section 9.3)</p></div>
<div class="paragraph"><p>o  segment_feature_mode indicates the feature data update mode, 0 for
delta and 1 for the absolute value (Section 9.3)</p></div>
<div class="paragraph"><p>o  quantizer_update indicates if the quantizer value is updated for
the i^(th) segment (Section 9.3)</p></div>
<div class="paragraph"><p>o  quantizer_update_value indicates the update value for the segment
quantizer (Section 9.3)</p></div>
<div class="paragraph"><p>o  quantizer_update_sign indicates the update sign for the segment
quantizer (Section 9.3)</p></div>
<div class="paragraph"><p>o  loop_filter_update indicates if the loop filter level value is
updated for the i^(th) segment (Section 9.3)</p></div>
<div class="paragraph"><p>o  lf_update_value indicates the update value for the loop filter
level (Section 9.3)</p></div>
<div class="paragraph"><p>o  lf_update_sign indicates the update sign for the loop filter level
(Section 9.3)</p></div>
<div class="paragraph"><p>o  segment_prob_update indicates whether the branch probabilities
used to decode the segment_id in the MB header are decoded from
the stream or use the default value of 255 (Section 9.3)</p></div>
<div class="paragraph"><p>o  segment_prob indicates the branch probabilities of the segment_id
decoding tree (Section 9.3)</p></div>
<div class="paragraph"><p>| mb_lf_adjustments() | Type  |
|----------- | ----- |
| loop_filter_adj_enable | L(1)  |
| if (loop_filter_adj_enable) {| |
|mode_ref_lf_delta_update| L(1)  |
|if (mode_ref_lf_delta_update) {  | |
|  for (i = 0; i &lt; 4; i<code>) {| |
| ref_frame_delta_update_flag  | L(1)  |
| if (ref_frame_delta_update_flag) { | |
|delta_magnitude| L(6)  |
|delta_sign  | L(1)  |
| } | |
|  }| |
|  for (i = 0; i &lt; 4; i</code>) {| |
| mb_mode_delta_update_flag | L(1)  |
| if (mb_mode_delta_update_flag) {| |
|delta_magnitude| L(6)  |
|delta_sign  | L(1)  |
| } | |
|  }| |
|}  | |
| } | |</p></div>
<div class="paragraph"><p>o  loop_filter_adj_enable indicates if the MB-level loop filter
adjustment (based on the used reference frame and coding mode) is
on for the current frame (Section 9.4)</p></div>
<div class="paragraph"><p>o  mode_ref_lf_delta_update indicates if the delta values used in an
adjustment are updated in the current frame (Section 9.4)</p></div>
<div class="paragraph"><p>o  ref_frame_delta_update_flag indicates if the adjustment delta
value corresponding to a certain used reference frame is updated
(Section 9.4)</p></div>
<div class="paragraph"><p>o  delta_magnitude is the absolute value of the delta value</p></div>
<div class="paragraph"><p>o  delta_sign is the sign of the delta value</p></div>
<div class="paragraph"><p>o  mb_mode_delta_update_flag indicates if the adjustment delta value
corresponding to a certain MB prediction mode is updated
(Section 9.4)</p></div>
<div class="paragraph"><p>| quant_indices()  | Type  |
|----------- | ----- |
| y_ac_qi | L(7)  |
| y_dc_delta_present  | L(1)  |
| if (y_dc_delta_present) { | |
|y_dc_delta_magnitude | L(4)  |
|y_dc_delta_sign| L(1)  |
| } | |
| y2_dc_delta_present | L(1)  |
| if (y2_dc_delta_present) {| |
|y2_dc_delta_magnitude| L(4)  |
|y2_dc_delta_sign  | L(1)  |
| } | |
| y2_ac_delta_present | L(1)  |
| if (y2_ac_delta_present) {| |
|y2_ac_delta_magnitude| L(4)  |
|y2_ac_delta_sign  | L(1)  |
| } | |
| uv_dc_delta_present | L(1)  |
| if (uv_dc_delta_present) {| |
|uv_dc_delta_magnitude| L(4)  |
|uv_dc_delta_sign  | L(1)  |
| } | |
| uv_ac_delta_present | L(1)  |
| if (uv_ac_delta_present) {| |
|uv_ac_delta_magnitude| L(4)  |
|uv_ac_delta_sign  | L(1)  |
| } | |</p></div>
<div class="paragraph"><p>o  y_ac_qi is the dequantization table index used for the luma AC
coefficients (and other coefficient groups if no delta value is
present) (Section 9.6)</p></div>
<div class="paragraph"><p>o  y_dc_delta_present indicates if the stream contains a delta value
that is added to the baseline index to obtain the luma DC
coefficient dequantization index (Section 9.6)</p></div>
<div class="paragraph"><p>o  y_dc_delta_magnitude is the magnitude of the delta value
(Section 9.6)</p></div>
<div class="paragraph"><p>o  y_dc_delta_sign is the sign of the delta value (Section 9.6)</p></div>
<div class="paragraph"><p>o  y2_dc_delta_present indicates if the stream contains a delta value
that is added to the baseline index to obtain the Y2 block DC
coefficient dequantization index (Section 9.6)</p></div>
<div class="paragraph"><p>o  y2_ac_delta_present indicates if the stream contains a delta value
that is added to the baseline index to obtain the Y2 block AC
coefficient dequantization index (Section 9.6)</p></div>
<div class="paragraph"><p>o  uv_dc_delta_present indicates if the stream contains a delta value
that is added to the baseline index to obtain the chroma DC
coefficient dequantization index (Section 9.6)</p></div>
<div class="paragraph"><p>o  uv_ac_delta_present indicates if the stream contains a delta value
that is added to the baseline index to obtain the chroma AC
coefficient dequantization index (Section 9.6)</p></div>
<div class="paragraph"><p>| token_prob_update() | Type  |
|----------- | ----- |
| for (i = 0; i &lt; 4; i<code>) { | |
|for (j = 0; j &lt; 8; j</code>) {  | |
|  for (k = 0; k &lt; 3; k<code>) {| |
| for (l = 0; l &lt; 11; l</code>) {| |
|coeff_prob_update_flag  | L(1)  |
|if (coeff_prob_update_flag)| |
|  coeff_prob| L(8)  |
| } | |
|  }| |
|}  | |
| } | |</p></div>
<div class="paragraph"><p>o  coeff_prob_update_flag indicates if the corresponding branch
probability is updated in the current frame (Section 13.4)</p></div>
<div class="paragraph"><p>o  coeff_prob is the new branch probability (Section 13.4)</p></div>
<div class="paragraph"><p>| mv_prob_update() | Type  |
|----------- | ----- |
| for (i = 0; i &lt; 2; i<code>) { | |
|for (j = 0; j &lt; 19; j</code>) { | |
|  mv_prob_update_flag| L(1)  |
|  if (mv_prob_update_flag) | |
| prob | L(7)  |
|}  | |
| } | |</p></div>
<div class="paragraph"><p>o  mv_prob_update_flag indicates if the corresponding MV decoding
probability is updated in the current frame (Section 17.2)</p></div>
<div class="paragraph"><p>o  prob is the updated probability (Section 17.2)</p></div>
<div class="paragraph"><p>19.3.  Macroblock Data</p></div>
<div class="paragraph"><p>| Macroblock Data  | Type  |
|----------- | ----- |
| macroblock_header() | |
| residual_data()  | |</p></div>
<div class="paragraph"><p>| macroblock_header() | Type  |
|----------- | ----- |
| if (update_mb_segmentation_map) | |
|segment_id  | T  |
| if (mb_no_skip_coeff)  | |
|mb_skip_coeff  | B(p)  |
| if (!key_frame)  | |
|is_inter_mb | B(p)  |
| if (is_inter_mb) {  | |
|mb_ref_frame_sel1 | B(p)  |
|if (mb_ref_frame_sel1)  | |
|  mb_ref_frame_sel2  | B(p)  |
|mv_mode  | T  |
|if (mv_mode == SPLITMV) {  | |
|  mv_split_mode| T  |
|  for (i = 0; i &lt; numMvs; i<code>) { | |
| sub_mv_mode| T  |
| if (sub_mv_mode == NEWMV4x4) {  | |
|read_mvcomponent()| |
|read_mvcomponent()| |
| } | |
|  }| |
|} else if (mv_mode == NEWMV) {| |
|  read_mvcomponent() | |
|  read_mvcomponent() | |
|}  | |
| } else { /* intra mb */| |
|intra_y_mode| T  |
|if (intra_y_mode == B_PRED) { | |
|  for (i = 0; i &lt; 16; i</code>) | |
| intra_b_mode  | T  |
|}  | |
|intra_uv_mode  | T  |
| } | |</p></div>
<div class="paragraph"><p>o  segment_id indicates to which segment the macroblock belongs
(Section 10)</p></div>
<div class="paragraph"><p>o  mb_skip_coeff indicates whether the macroblock contains any coded
coefficients or not (Section 11.1)</p></div>
<div class="paragraph"><p>o  is_inter_mb indicates whether the macroblock is intra- or inter-
coded (Section 16)</p></div>
<div class="paragraph"><p>o  mb_ref_frame_sel1 selects the reference frame to be used; last
frame (0), golden/alternate (1) (Section 16.2)</p></div>
<div class="paragraph"><p>o  mb_ref_frame_sel2 selects whether the golden (0) or alternate
reference frame (1) is used (Section 16.2)</p></div>
<div class="paragraph"><p>o  mv_mode determines the macroblock motion vector mode
(Section 16.2)</p></div>
<div class="paragraph"><p>o  mv_split_mode gives the macroblock partitioning specification and
determines the number of motion vectors used (numMvs)
(Section 16.2)</p></div>
<div class="paragraph"><p>o  sub_mv_mode determines the sub-macroblock motion vector mode for
macroblocks coded using the SPLITMV motion vector mode
(Section 16.2)</p></div>
<div class="paragraph"><p>o  intra_y_mode selects the luminance intra-prediction mode
(Section 16.1)</p></div>
<div class="paragraph"><p>o  intra_b_mode selects the sub-macroblock luminance prediction mode
for macroblocks coded using B_PRED mode (Section 16.1)</p></div>
<div class="paragraph"><p>o  intra_uv_mode selects the chrominance intra-prediction mode
(Section 16.1)</p></div>
<div class="paragraph"><p>| residual_data()  | Type  |
|----------- | ----- |
| if (!mb_skip_coeff) {  | |
|if ( (is_inter_mb &amp;&amp; mv_mode != SPLITMV) ||  | |
|  (!is_inter_mb &amp;&amp; intra_y_mode != B_PRED) ) | |
|  residual_block() /* Y2 <strong>/| |
|for (i = 0; i &lt; 24; i<code>)| |
|  residual_block() /</strong> 16 Y, 4 U, 4 V */| |
| } | |
| residual_block() | Type  |
|----------- | ----- |
| for (i = firstCoeff; i &lt; 16; i</code>) {| |
|token | T  |
|if (token == EOB) break;| |
|if (token_has_extra_bits)  | |
|  extra_bits| L(n)  |
|if (coefficient != 0)| |
|  sign| L(1)  |
| } | |</p></div>
<div class="paragraph"><p>o  firstCoeff is 1 for luma blocks of macroblocks containing Y2
subblock; otherwise 0</p></div>
<div class="paragraph"><p>o  token defines the value of the coefficient, the value range of the
coefficient, or the end of block (Section 13.2)</p></div>
<div class="paragraph"><p>o  extra_bits determines the value of the coefficient within the
value range defined by the token (Section 13.2)</p></div>
<div class="paragraph"><p>o  sign indicates the sign of the coefficient (Section 13.2)</p></div>
<div class="olist arabic"><ol class="arabic">
<li>
<p>
Attachment One: Reference Decoder Source Code
</p>
</li>
</ol></div>
<div class="paragraph"><p>20.1.  bit_ops.h</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>20.2.  bool_decoder.h</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>20.3.  dequant_data.h</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>20.4.  dixie.c</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>20.5.  dixie.h</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>20.6.  dixie_loopfilter.c</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>20.7.  dixie_loopfilter.h</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>20.8.  idct_add.c</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>20.9.  idct_add.h</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>20.10.  mem.h</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>20.11.  modemv.c</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>20.12.  modemv.h</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>20.13.  modemv_data.h</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>20.14.  predict.c</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>20.15.  predict.h</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>20.16.  tokens.c</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>20.17.  tokens.h</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>20.18.  vp8_prob_data.h</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>20.19.  vpx_codec_internal.h</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>20.20.  vpx_decoder.h</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>20.21.  vpx_decoder_compat.h</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>20.22.  vpx_image.c</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>20.23.  vpx_image.h</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>20.24.  vpx_integer.h</p></div>
<div class="listingblock">
<div class="content"></div></div>
<div class="paragraph"><p>20.25.  AUTHORS File</p></div>
<div class="paragraph"><p>Aaron Watry &lt;<a href="mailto:awatry@gmail.com">awatry@gmail.com</a>&gt;</p></div>
<div class="paragraph"><p>Adrian Grange &lt;<a href="mailto:agrange@google.com">agrange@google.com</a>&gt;</p></div>
<div class="paragraph"><p>Alex Converse &lt;<a href="mailto:alex.converse@gmail.com">alex.converse@gmail.com</a>&gt;</p></div>
<div class="paragraph"><p>Andoni Morales Alastruey &lt;<a href="mailto:ylatuya@gmail.com">ylatuya@gmail.com</a>&gt;</p></div>
<div class="paragraph"><p>Andres Mejia &lt;<a href="mailto:mcitadel@gmail.com">mcitadel@gmail.com</a>&gt;</p></div>
<div class="paragraph"><p>Attila Nagy &lt;<a href="mailto:attilanagy@google.com">attilanagy@google.com</a>&gt;</p></div>
<div class="paragraph"><p>Fabio Pedretti &lt;<a href="mailto:fabio.ped@libero.it">fabio.ped@libero.it</a>&gt;</p></div>
<div class="paragraph"><p>Frank Galligan &lt;<a href="mailto:fgalligan@google.com">fgalligan@google.com</a>&gt;</p></div>
<div class="paragraph"><p>Fredrik Soederquist &lt;<a href="mailto:fs@opera.com">fs@opera.com</a>&gt;</p></div>
<div class="paragraph"><p>Fritz Koenig &lt;<a href="mailto:frkoenig@google.com">frkoenig@google.com</a>&gt;</p></div>
<div class="paragraph"><p>Gaute Strokkenes &lt;<a href="mailto:gaute.strokkenes@broadcom.com">gaute.strokkenes@broadcom.com</a>&gt;</p></div>
<div class="paragraph"><p>Giuseppe Scrivano &lt;<a href="mailto:gscrivano@gnu.org">gscrivano@gnu.org</a>&gt;</p></div>
<div class="paragraph"><p>Guillermo Ballester Valor &lt;<a href="mailto:gbvalor@gmail.com">gbvalor@gmail.com</a>&gt;</p></div>
<div class="paragraph"><p>Henrik Lundin &lt;<a href="mailto:hlundin@google.com">hlundin@google.com</a>&gt;</p></div>
<div class="paragraph"><p>James Berry &lt;<a href="mailto:jamesberry@google.com">jamesberry@google.com</a>&gt;</p></div>
<div class="paragraph"><p>James Zern &lt;<a href="mailto:jzern@google.com">jzern@google.com</a>&gt;</p></div>
<div class="paragraph"><p>Jan Kratochvil &lt;<a href="mailto:jan.kratochvil@redhat.com">jan.kratochvil@redhat.com</a>&gt;</p></div>
<div class="paragraph"><p>Jeff Muizelaar &lt;<a href="mailto:jmuizelaar@mozilla.com">jmuizelaar@mozilla.com</a>&gt;</p></div>
<div class="paragraph"><p>Jim Bankoski &lt;<a href="mailto:jimbankoski@google.com">jimbankoski@google.com</a>&gt;</p></div>
<div class="paragraph"><p>Johann Koenig &lt;<a href="mailto:johannkoenig@google.com">johannkoenig@google.com</a>&gt;</p></div>
<div class="paragraph"><p>John Koleszar &lt;<a href="mailto:jkoleszar@google.com">jkoleszar@google.com</a>&gt;</p></div>
<div class="paragraph"><p>Justin Clift &lt;<a href="mailto:justin@salasaga.org">justin@salasaga.org</a>&gt;</p></div>
<div class="paragraph"><p>Justin Lebar &lt;<a href="mailto:justin.lebar@gmail.com">justin.lebar@gmail.com</a>&gt;</p></div>
<div class="paragraph"><p>Luca Barbato &lt;<a href="mailto:lu_zero@gentoo.org">lu_zero@gentoo.org</a>&gt;</p></div>
<div class="paragraph"><p>Makoto Kato &lt;<a href="mailto:makoto.kt@gmail.com">makoto.kt@gmail.com</a>&gt;</p></div>
<div class="paragraph"><p>Martin Ettl &lt;<a href="mailto:ettl.martin78@googlemail.com">ettl.martin78@googlemail.com</a>&gt;</p></div>
<div class="paragraph"><p>Michael Kohler &lt;<a href="mailto:michaelkohler@live.com">michaelkohler@live.com</a>&gt;</p></div>
<div class="paragraph"><p>Mikhal Shemer &lt;<a href="mailto:mikhal@google.com">mikhal@google.com</a>&gt;</p></div>
<div class="paragraph"><p>Pascal Massimino &lt;<a href="mailto:pascal.massimino@gmail.com">pascal.massimino@gmail.com</a>&gt;</p></div>
<div class="paragraph"><p>Patrik Westin &lt;<a href="mailto:patrik.westin@gmail.com">patrik.westin@gmail.com</a>&gt;</p></div>
<div class="paragraph"><p>Paul Wilkins &lt;<a href="mailto:paulwilkins@google.com">paulwilkins@google.com</a>&gt;</p></div>
<div class="paragraph"><p>Pavol Rusnak &lt;<a href="mailto:stick@gk2.sk">stick@gk2.sk</a>&gt;</p></div>
<div class="paragraph"><p>Philip Jaegenstedt &lt;<a href="mailto:philipj@opera.com">philipj@opera.com</a>&gt;</p></div>
<div class="paragraph"><p>Scott LaVarnway &lt;<a href="mailto:slavarnway@google.com">slavarnway@google.com</a>&gt;</p></div>
<div class="paragraph"><p>Tero Rintaluoma &lt;<a href="mailto:teror@google.com">teror@google.com</a>&gt;</p></div>
<div class="paragraph"><p>Timothy B. Terriberry &lt;<a href="mailto:tterribe@xiph.org">tterribe@xiph.org</a>&gt;</p></div>
<div class="paragraph"><p>Tom Finegan &lt;<a href="mailto:tomfinegan@google.com">tomfinegan@google.com</a>&gt;</p></div>
<div class="paragraph"><p>Yaowu Xu &lt;<a href="mailto:yaowu@google.com">yaowu@google.com</a>&gt;</p></div>
<div class="paragraph"><p>Yunqing Wang &lt;<a href="mailto:yunqingwang@google.com">yunqingwang@google.com</a>&gt;</p></div>
<div class="paragraph"><p>Google Inc.</p></div>
<div class="paragraph"><p>The Mozilla Foundation</p></div>
<div class="paragraph"><p>The Xiph.Org Foundation</p></div>
<div class="paragraph"><p>20.26.  LICENSE</p></div>
<div class="paragraph"><p>Copyright (c) 2010, 2011, Google Inc.  All rights reserved.</p></div>
<div class="paragraph"><p>Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions
are met:</p></div>
<div class="paragraph"><p>o  Redistributions of source code must retain the above copyright
notice, this list of conditions and the following disclaimer.</p></div>
<div class="paragraph"><p>o  Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in
the documentation and/or other materials provided with the
distribution.</p></div>
<div class="paragraph"><p>o  Neither the name of Google nor the names of its contributors may
be used to endorse or promote products derived from this software
without specific prior written permission.</p></div>
<div class="paragraph"><p>THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
A PARTICULAR PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT
HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS
OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED
AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY
WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
POSSIBILITY OF SUCH DAMAGE.</p></div>
<div class="paragraph"><p>20.27.  PATENTS</p></div>
<div class="paragraph"><p>Additional IP Rights Grant (Patents)</p></div>
<div class="paragraph"><p>"This implementation" means the copyrightable works distributed by
Google as part of the WebM Project.</p></div>
<div class="paragraph"><p>Google hereby grants to you a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, transfer, and otherwise run, modify and propagate the contents of this implementation of VP8, where such license applies only to those patent claims, both currently owned by Google and acquired in the future, licensable by Google that are necessarily infringed by this implementation of VP8.  This grant does not include claims that would be infringed only as a consequence of further modification of this implementation.  If you or your agent or exclusive licensee institute or order or agree to the institution of patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that this implementation of VP8 or any code incorporated within this implementation of VP8 constitutes direct or contributory patent infringement, or inducement of patent infringement, then any patent rights granted to you under this License for this implementation of VP8 shall terminate as of the date such litigation is filed.</p></div>
<div class="olist arabic"><ol class="arabic">
<li>
<p>
Security Considerations
</p>
</li>
</ol></div>
<div class="paragraph"><p>A VP8 decoder should take appropriate security considerations into account, as outlined in [RFC4732] and [RFC3552].  It is extremely important that a decoder be robust against malicious payloads. Malicious payloads must not cause the decoder to overrun its allocated memory or to consume inordinate resources.  Although encoder issues are typically rarer, the same applies to an encoder. Malicious stream data must not cause the encoder to misbehave, as this might allow an attacker access to transcoding gateways.</p></div>
<div class="olist arabic"><ol class="arabic">
<li>
<p>
References
</p>
</li>
</ol></div>
<div class="paragraph"><p>22.1.  Normative Reference</p></div>
<div class="paragraph"><p>[RFC2119]Bradner, S., "Key words for use in RFCs to Indicate
Requirement Levels", BCP 14, RFC 2119, March 1997.</p></div>
<div class="paragraph"><p>22.2.  Informative References</p></div>
<div class="paragraph"><p>[Bell]Bell, T., Cleary, J., and I. Witten, "Text Compression",
1990.</p></div>
<div class="paragraph"><p>[ISO-C99]International Organization for Standardization,
"Information technology&#8201;&#8212;&#8201; Programming languages&#8201;&#8212;&#8201;C",
ISO/IEC 9899:1999, 1999.</p></div>
<div class="paragraph"><p>International Telecommunication Union, "ITU BT.601-7:
Studio encoding parameters of digital television for
standard 4:3 and wide screen 16:9 aspect ratios",
March 2011.</p></div>
<div class="paragraph"><p>[Kernighan] Kernighan, B. and D. Ritchie, "The C Programming Language
(2nd edition)", April 1988.</p></div>
<div class="paragraph"><p>[Loeffler]  Loeffler, C., Ligtenberg , A., and G. Moschytz,
"Practical Fast 1-D DCT Algorithms with 11
Multiplications", May 1989.</p></div>
<div class="paragraph"><p>[RFC3552]Rescorla, E. and B. Korver, "Guidelines for Writing RFC
Text on Security Considerations", BCP 72, RFC 3552,
July 2003.</p></div>
<div class="paragraph"><p>[RFC4732]Handley, M., Ed., Rescorla, E., Ed., and IAB, "Internet
Denial-of-Service Considerations", RFC 4732,
December 2006.</p></div>
<div class="paragraph"><p>[Shannon]Shannon, C., "A Mathematical Theory of Communication",
Bell System Technical Journal Vol. 27, pp. 379-423 and
623-656, July and October 1948.</p></div>
<div class="paragraph"><p>Bankoski, et al.  Informational [Page 303]
RFC 6386  VP8 Data Format and Decoding GuideNovember 2011</p></div>
<div class="paragraph"><p>Authors' Addresses</p></div>
<div class="paragraph"><p>James Bankoski
Google Inc.</p></div>
<div class="paragraph"><p>EMail: <a href="mailto:jimbankoski@google.com">jimbankoski@google.com</a></p></div>
<div class="paragraph"><p>John Koleszar
Google Inc.</p></div>
<div class="paragraph"><p>EMail: <a href="mailto:jkoleszar@google.com">jkoleszar@google.com</a></p></div>
<div class="paragraph"><p>Lou Quillio
Google Inc.</p></div>
<div class="paragraph"><p>EMail: <a href="mailto:louquillio@google.com">louquillio@google.com</a></p></div>
<div class="paragraph"><p>Janne Salonen
Google Inc.</p></div>
<div class="paragraph"><p>EMail: <a href="mailto:jsalonen@google.com">jsalonen@google.com</a></p></div>
<div class="paragraph"><p>Paul Wilkins
Google Inc.</p></div>
<div class="paragraph"><p>EMail: <a href="mailto:paulwilkins@google.com">paulwilkins@google.com</a></p></div>
<div class="paragraph"><p>Yaowu Xu
Google Inc.
EMail: <a href="mailto:yaowu@google.com">yaowu@google.com</a></p></div>
</div>
</div>
</div>
<div id="footnotes"><hr /></div>
<div id="footer">
<div id="footer-text">
Last updated
 2020-03-03 05:03:57 EET
</div>
</div>
</body>
</html>
